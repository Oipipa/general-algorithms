{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOwdUcDLvM1XI1rvmH1WoKv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 1\n","The Towers of Hanoi problem consists of three pegs A, B, and C, and n squares of varying size. Initially the squares are stacked on peg A in order of decreasing size, the largest square on the bottom. The problem is to move the squares from peg A to peg B one at a time in such a way that no square is ever placed on a smaller square. Peg C may be used for temporary storage of squares. Write a recursive algorithm to solve this problem."],"metadata":{"id":"vS-19qEiYrFd"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zficXmRUYol5","executionInfo":{"status":"ok","timestamp":1745706059736,"user_tz":-120,"elapsed":54,"user":{"displayName":"knapbase64","userId":"14440481571077983509"}},"outputId":"8836213f-206f-4479-b2ce-e074941e5320"},"outputs":[{"output_type":"stream","name":"stdout","text":["A -> B\n","A -> C\n","B -> C\n","A -> B\n","C -> A\n","C -> B\n","A -> B\n"]}],"source":["def hanoi(n, src='A', dst='B', aux='C'):\n","    if n == 0:\n","        return\n","    hanoi(n-1, src, aux, dst)\n","    print(f'{src} -> {dst}')\n","    hanoi(n-1, aux, dst, src)\n","\n","hanoi(3)"]},{"cell_type":"markdown","source":["# 2\n","Write an efficient algorithm to determine an order of evaluating the matrix product $M_1 \\times M_2 \\times ... \\times M_n$, so as to minimize the number of scalar multiplications in the case where each $M$ is of dimension $1\\times 1$, $1\\times d$, $d \\times 1$ or $d \\times d$  for some fixed $d$.\n","\n","---"],"metadata":{"id":"NHCN272cY2et"}},{"cell_type":"markdown","source":["### Translating the type string into dimensions  \n","\n","If the input list is $(t_1,\\dots ,t_n)$, the first step constructs  \n","$${\\bf dims}=(p_0,p_1),\\,(p_1,p_2),\\;\\dots\\;,(p_{n-1},p_n)$$  \n","so that matrix $M_i$ has dimension $p_{i-1}\\times p_i$.  \n","With the four allowed shapes each pair $(p_{i-1},p_i)$ is instantly known from $t_i$.\n","\n","### Sub-problem definition  \n","\n","For indices $0\\le i\\le j\\lt n$ the function $\\text{solve}(i,j)$ returns\n","\n","* $m_{ij}$: the minimum number of scalar multiplications required to compute the product $M_i\\cdots M_j$,\n","* $(r_{ij},c_{ij})$: the dimension of that product,\n","* a fully parenthesised string realising the optimum.\n","\n","The base case $i=j$ has cost $m_{ii}=0$ because a single matrix needs no arithmetic.\n","\n","### Recurrence  \n","\n","For $i<j$ one chooses a split position $k$ ($i\\le k<j$) and joins the two optimal sub-products:\n","\n","$$\n","m_{ij}= \\min_{i\\le k<j}\\Bigl( m_{ik}+m_{\\,k+1\\,j}+r_{ik}\\,c_{ik}\\,c_{\\,k+1\\,j}\\Bigr),\n","$$\n","\n","where the last summand is the scalar cost of multiplying an $r_{ik}\\times c_{ik}$ result with a $c_{ik}\\times c_{\\,k+1\\,j}$ result.  \n","Whenever $c_{ik}\\ne r_{\\,k+1\\,j}$ the split is illegal and skipped.\n","\n","\n","### Memoisation strategy  \n","\n","Because each ordered pair $(i,j)$ is solved once and cached (`lru_cache`), the algorithm follows a *top-down* traversal of the state-space yet matches the $O(n^3)$ work bound of the classical bottom-up table.\n","\n","\n","### Reconstructing the parenthesisation  \n","\n","Alongside every numerical update the program stores the expression string  \n","\n","```python\n","best_repr = f\"({repr_l}x{repr_r})\"\n","```  \n","\n","so the global call immediately yields both the optimum cost and the corresponding order.\n","\n","### Example run  \n","\n","For the input $(r,m,m,c)$ with $d=4$ the chain is  \n","\n","$$M_1\\;1\\times4,\\quad M_2\\;4\\times4,\\quad M_3\\;4\\times4,\\quad M_4\\;4\\times1.$$\n","\n","The algorithm reports  \n","\n","$$\\text{cost}=36,\\qquad \\text{order}=(M_1\\times(M_2\\times(M_3\\times M_4))).$$  \n","\n","Indeed  \n","\n","$$\n","\\begin{aligned}\n","\\bigl((M_3\\times M_4)\\bigr)&:\\;4\\times4 \\cdot 4\\times1 = 16,\\\\\n","\\bigl(M_2\\times\\text{prev}\\bigr)&:\\;4\\times4 \\cdot 4\\times1 = 16,\\\\\n","\\bigl(M_1\\times\\text{prev}\\bigr)&:\\;1\\times4 \\cdot 4\\times1 = 4,\n","\\end{aligned}\n","\\qquad \\text{total }16+16+4 = 36,\n","$$\n","\n","and no other parenthesisation can beat this sum."],"metadata":{"id":"KY386vpgkh8Q"}},{"cell_type":"code","source":["from functools import lru_cache\n","\n","def optimal_matrix_chain(types, d):\n","    n = len(types)\n","    dims = [(1, 1) if t == 's' else (1, d) if t == 'r' else (d, 1) if t == 'c' else (d, d)\n","            for t in types]\n","\n","    @lru_cache(None)\n","    def solve(i, j):\n","        if i == j:\n","            return 0, dims[i], f\"M{i+1}\"\n","        best = float(\"inf\")\n","        best_dim = None\n","        best_repr = \"\"\n","        for k in range(i, j):\n","            cost_l, (r1, c1), repr_l = solve(i, k)\n","            cost_r, (r2, c2), repr_r = solve(k + 1, j)\n","            if c1 != r2:\n","                continue\n","            cost = cost_l + cost_r + r1 * c1 * c2\n","            if cost < best:\n","                best = cost\n","                best_dim = (r1, c2)\n","                best_repr = f\"({repr_l}x{repr_r})\"\n","        return best, best_dim, best_repr\n","\n","    cost, _, order = solve(0, n - 1)\n","    return cost, order\n","\n","types = ['r', 'm', 'm', 'c']\n","d = 4\n","cost, order = optimal_matrix_chain(types, d)\n","print(\"Minimum scalar multiplications:\", cost)\n","print(\"Optimal parenthesisation:\", order)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R2CrMArBZth0","executionInfo":{"status":"ok","timestamp":1745706059754,"user_tz":-120,"elapsed":6,"user":{"displayName":"knapbase64","userId":"14440481571077983509"}},"outputId":"160de30c-af81-49ad-8826-ea624fdb2206"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Minimum scalar multiplications: 36\n","Optimal parenthesisation: (M1x(M2x(M3xM4)))\n"]}]},{"cell_type":"markdown","source":["# X\n","Definition.  \n","A context-free grammar in Chomsky normal form $G$ is a four-tuple $\\langle N, \\Sigma, P, S \\rangle$ where  \n","(1) $N$ is a finite set of nonterminal symbols,  \n","(2) $\\Sigma$ is a finite set of terminal symbols,  \n","(3) $P$ is a finite set of pairs, called productions, of the form $A \\rightarrow BC$ or $A \\rightarrow a$ where $A$, $B$, $C$ are in $N$ and $a$ is in $\\Sigma$, and  \n","(4) $S$ is a distinguished symbol in $N$.  \n","\n","We write $\\alpha A \\gamma \\Rightarrow \\alpha \\beta \\gamma$ if $\\alpha$, $\\beta$, $\\gamma$ are strings of nonterminals and terminals and $A \\rightarrow \\beta$ is in $P$.  \n","$L(G)$, the language generated by $G$, is the set of terminal strings $\\{ w | S \\overset{*}{\\Rightarrow} w \\}$ where $\\overset{*}{\\Rightarrow}$ is the reflexive and transitive closure of $\\Rightarrow$."],"metadata":{"id":"z28bcXsSblEk"}},{"cell_type":"markdown","source":["# 3\n","Write an $O(n^3)$ algorithm to determine whether a given string $w = a_1 a_2 \\cdots a_n$ is in $L(G)$, where $G = (N, \\Sigma, P, S)$ is a context-free grammar in Chomsky normal form.  [Hint: Let $m_{ij} = \\{ A | A \\in N$ and $A \\overset{*}{\\Rightarrow} a_i a_{i+1} \\cdots a_j \\}$.   $w \\in L(G)$ if and only if $S \\in m_{1n}$.   Use dynamic programming to compute the $m_{ij}$.]\n","\n","---"],"metadata":{"id":"MncKrUcqcmvt"}},{"cell_type":"markdown","source":["The subroutine `cyk` implements the Cocke–Younger–Kasami decision procedure for context-free grammars that have already been converted to Chomsky normal form.  \n","If the input word is $w=a_0a_1\\ldots a_{n-1}$, the algorithm fills an upper-triangular\n","$n\\times n$ table whose entry $T_{i,j}$ (with $0\\le i\\le j\\lt n$) stores the set of variables that can derive the factor $a_i\\ldots a_j$.\n","\n","The first preliminary pass builds a reverse look-up map  \n","$$\\text{rhs2lhs}:\\;\\beta\\longmapsto\\{A\\mid A\\to\\beta\\text{ is a production}\\}.$$  \n","Because the grammar is in CNF, every right-hand side $\\beta$ is either a single terminal $(a)$ or an ordered pair of variables $(B,C)$, so the map can be stored in a plain dictionary whose values are sets.\n","\n","The diagonal of the table corresponds to substrings of length $1$.  \n","For each position $i$ the set $T_{i,i}$ is initialised with all variables $A$ for which $A\\to a_i$ is a production, i.e.  \n","$$T_{i,i}=\\text{rhs2lhs}\\bigl((a_i)\\bigr).$$\n","\n","To fill a cell $T_{i,j}$ of span length $s=j-i+1$ the code enumerates every legal split point $k$ between $i$ and $j-1$.  \n","If a variable $B$ can generate the left half $a_i\\ldots a_k$ and a variable $C$ the right half $a_{k+1}\\ldots a_j$, then any variable $A$ with a rule $A\\to BC$ can generate the whole factor.  \n","Formally  \n","$$\n","T_{i,j} \\;=\\;\\bigcup_{k=i}^{j-1}\\;\\bigcup_{B\\in T_{i,k}}\\;\\bigcup_{C\\in T_{k+1,j}}\\;\n","                     \\text{rhs2lhs}\\bigl((B,C)\\bigr).\n","$$  \n","The program realises this triple union by two nested `for` loops and one dictionary lookup; the intermediate union is accumulated in the temporary `cell` set and finally written back to `table[i][j]`.\n","\n","After all spans up to $n$ have been processed, the input word is in the language generated by the grammar iff the start symbol $S$ belongs to $T_{0,n-1}$, that is  \n","$$w\\in L(G)\\;\\Longleftrightarrow\\;S\\in T_{0,n-1}.$$\n","\n","The two sample calls employ a textbook grammar whose language is $\\{\\,ba^{k}ba^{k}\\mid k\\ge0\\}\\cup\\{\\,b^{k}a^{k+2}\\mid k\\ge0\\}$.  \n","For the word $w_1=\\texttt{baaba}$ the algorithm eventually places $S$ inside the final table entry, so it returns `True`.  \n","For the shorter word $w_2=\\texttt{aab}$ none of the derivations succeed in spanning the entire string with $S$, hence the result is `False`.\n","\n","Correctness follows from the inductive construction of the table: every variable is inserted into a cell exactly when it can derive the corresponding substring, and every derivation in CNF has a unique parse-tree shape that the dynamic-programming sweep will discover.  \n","There are $\\frac{n(n+1)}2$ cells and at most $n-1$ split points per cell, leading to a worst-case running time of $\\Theta(n^3)$ and a space consumption of $\\Theta(n^2)$, matching the theoretical bounds of the CYK algorithm."],"metadata":{"id":"_535iAiDmH64"}},{"cell_type":"code","source":["from collections import defaultdict\n","\n","def cyk(word, variables, terminals, productions, start):\n","    n = len(word)\n","    table = [[set() for _ in range(n)] for _ in range(n)]\n","    rhs2lhs = defaultdict(set)\n","    for lhs, rhs in productions:\n","        rhs2lhs[rhs].add(lhs)\n","\n","    for i, a in enumerate(word):\n","        table[i][i] = rhs2lhs[(a,)]\n","\n","    for span in range(2, n + 1):\n","        for i in range(n - span + 1):\n","            j = i + span - 1\n","            cell = set()\n","            for k in range(i, j):\n","                for B in table[i][k]:\n","                    for C in table[k + 1][j]:\n","                        cell |= rhs2lhs[(B, C)]\n","            table[i][j] = cell\n","\n","    return start in table[0][n - 1]\n","\n","# grammar in CNF taken from a standard textbook example\n","variables = {'S', 'A', 'B', 'C'}\n","terminals  = {'a', 'b'}\n","productions = [\n","    ('S', ('A', 'B')), ('S', ('B', 'C')),\n","    ('A', ('B', 'A')), ('A', ('a',)),\n","    ('B', ('C', 'C')), ('B', ('b',)),\n","    ('C', ('A', 'B')), ('C', ('a',))\n","]\n","start = 'S'\n","\n","w1 = \"baaba\"   # should be in the language\n","w2 = \"aab\"     # should not be in the language\n","\n","print(cyk(w1, variables, terminals, productions, start))  # True\n","print(cyk(w2, variables, terminals, productions, start))  # False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TnvKmMcXbkjC","executionInfo":{"status":"ok","timestamp":1745706059766,"user_tz":-120,"elapsed":12,"user":{"displayName":"knapbase64","userId":"14440481571077983509"}},"outputId":"77090cec-77c6-4c64-ee87-9c7ee4548b2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","False\n"]}]},{"cell_type":"markdown","source":["# 4\n","Let $x$ and $y$ be strings of symbols from some alphabet. Consider the operations of deleting a symbol from $x$, inserting a symbol into $x$, and replacing a symbol of $x$ by another symbol. Describe an algorithm to find the minimum number of such operations needed to transform $x$ into $y$.\n","\n","---"],"metadata":{"id":"AVpfIqyJeJ65"}},{"cell_type":"markdown","source":["Let the two input strings be $x=x_1x_2\\ldots x_m$ and $y=y_1y_2\\ldots y_n$.  \n","Define a table $D$ of size $(m+1)\\times(n+1)$ where the entry $D_{i,j}$ represents the minimum number of single–symbol edits required to convert the prefix $x_1\\ldots x_i$ into the prefix $y_1\\ldots y_j$.  The allowed edits are deletion of one symbol from $x$, insertion of one symbol into $x$, and substitution of one symbol of $x$ by another.\n","\n","Initialization fills the zeroth row and column.  Transforming an empty string into the first $j$ symbols of $y$ must perform exactly $j$ insertions, so $D_{0,j}=j$.  Transforming the first $i$ symbols of $x$ into an empty string must perform exactly $i$ deletions, so $D_{i,0}=i$.  These boundary conditions establish the base of a two-dimensional induction.\n","\n","For $1\\le i\\le m$ and $1\\le j\\le n$ the recurrence is  \n","$$\n","D_{i,j}=\\begin{cases}\n","D_{i-1,j-1}, & x_i=y_j,\\\\[4pt]\n","1+\\min\\bigl(D_{i-1,j},\\;D_{i,j-1},\\;D_{i-1,j-1}\\bigr), & x_i\\ne y_j.\n","\\end{cases}\n","$$  \n","If the current characters match, no edit is necessary and the optimum cost is inherited from the northwest diagonal cell.  Otherwise three alternative edits are considered: delete $x_i$ which leads to $D_{i-1,j}$, insert $y_j$ which leads to $D_{i,j-1}$, or substitute $x_i$ by $y_j$ which leads to $D_{i-1,j-1}$.  One is added to the minimum of those sub-solutions to pay for the chosen operation.  Because each $D_{i,j}$ depends only on entries whose indices are strictly smaller in at least one coordinate, the table can be filled row by row or column by column without circularity.\n","\n","When the double loop terminates the desired edit distance is stored in $D_{m,n}$.  The algorithm touches every cell once, so the running time is $O(mn)$ and the table occupies $O(mn)$ space.  If only the distance value is required, memory may be reduced to two rows of length $n+1$, yielding $O(\\min\\{m,n\\})$ space.\n","\n","Executing the procedure on the strings $$x=\\text{``kitten''},\\qquad y=\\text{``sitting''}$$ produces the following main diagonal of the table:\n","\n","$$\n","\\begin{array}{c|cccccccc}\n","      & \\varepsilon & s & i & t & t & i & n & g\\\\\\hline\n","\\varepsilon & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7\\\\\n","k & 1 & 1 & 2 & 3 & 4 & 5 & 6 & 7\\\\\n","i & 2 & 2 & 1 & 2 & 3 & 4 & 5 & 6\\\\\n","t & 3 & 3 & 2 & 1 & 2 & 3 & 4 & 5\\\\\n","t & 4 & 4 & 3 & 2 & 1 & 2 & 3 & 4\\\\\n","e & 5 & 5 & 4 & 3 & 2 & 2 & 3 & 4\\\\\n","n & 6 & 6 & 5 & 4 & 3 & 3 & 2 & 3\n","\\end{array}\n","$$  \n","\n","The bottom-right entry equals $3$, confirming that exactly three edits—substituting $k\\to s$, substituting $e\\to i$, and inserting $g$ at the end—are sufficient and necessary to transform “kitten” into “sitting”."],"metadata":{"id":"YiJNdlRZm_zX"}},{"cell_type":"code","source":["def edit_distance(x: str, y: str) -> int:\n","    m, n = len(x), len(y)\n","    D = [[0]*(n+1) for _ in range(m+1)]\n","\n","    for i in range(m+1):\n","        D[i][0] = i                       # deletes\n","    for j in range(n+1):\n","        D[0][j] = j                       # inserts\n","\n","    for i in range(1, m+1):\n","        for j in range(1, n+1):\n","            if x[i-1] == y[j-1]:\n","                D[i][j] = D[i-1][j-1]\n","            else:\n","                D[i][j] = 1 + min(D[i-1][j],        # delete\n","                                   D[i][j-1],        # insert\n","                                   D[i-1][j-1])      # replace\n","    return D[m][n]\n","\n","edit_distance(\"kitten\", \"sitting\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JhCsRyeCeR2b","executionInfo":{"status":"ok","timestamp":1745706059781,"user_tz":-120,"elapsed":14,"user":{"displayName":"knapbase64","userId":"14440481571077983509"}},"outputId":"0d79a838-5aa8-437f-f73f-8648c9351468"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["# 5\n","Develop complete data structures for the off-line MIN problem including the representation of trees by arrays, and write a program using arrays rather than the higher-level commands of the disjoint-set union algorithm.\n","\n","---"],"metadata":{"id":"9vxcWV2MjoH4"}},{"cell_type":"markdown","source":["The procedure `offline_minimum` solves the well-known *off-line minimum* problem:  \n","a stream of operations consists of arbitrary `Insert(k)` calls that place a key `k` into a priority queue, interleaved with `Extract-Min` calls that remove and report the current minimum.  \n","Unlike the on-line version, the entire sequence is given in advance, so the program may inspect all inserts before producing the answers for the extracts.\n","\n","### Phase 1 – partitioning the inserts\n","\n","Suppose the input sequence contains  \n","\n","$$m=\\text{(\\#Extract-Min)}$$  \n","\n","extraction points.  The keys inserted strictly between the $(j-1)$-st and the $j$-th extraction form a set $$S_j\\;(0\\le j\\le m),$$ where $S_m$ contains the inserts that appear *after* the last `Extract-Min`.  \n","The initial loop builds an array `blocks=[S_0,S_1,\\dots ,S_m]`, each entry being a standard Python list of integer keys.  A dummy set $S_m$ is appended because the classical disjoint-set algorithm needs one extra set to merge into once the last real block becomes empty.\n","\n","### Phase 2 – disjoint-set forest on the blocks\n","\n","The helper `make_sets(m)` returns two arrays\n","\n","$$\\text{parent}[j]=j,\\qquad\\text{size}[j]=1\\quad(0\\le j\\le m)$$  \n","\n","so every $S_j$ is initially its own singleton root.  \n","The find operation employs iterative *path compression*: every vertex visited during the climb to the root is rewired to skip one level, guaranteeing an inverse-Ackermann amortised bound.  \n","The union operation attaches the smaller tree below the larger one, recorded in `size`, which preserves the same complexity.\n","\n","### Phase 3 – mapping keys to their blocks\n","\n","For each key `k` the dictionary `where[k]=j` tells in which $S_j$ the key was originally inserted.  \n","Because every key is distinct the map can be built by a single traversal of all blocks.\n","\n","### Phase 4 – processing keys in ascending numeric order\n","\n","The correctness insight of Tarjan’s off-line algorithm is that if the keys are handled from smallest to largest, the first time a key reaches the root of some set $S_j$ that key must be the minimum reported by the $j$-th extraction.\n","\n","The outer loop  \n","\n","```python\n","for key in sorted(where):\n","```  \n","\n","iterates over the keys in increasing order.  For each key the algorithm\n","looks up its current representative\n","\n","$$j=\\text{find}\\bigl(\\, \\text{where[key]},\\text{parent}\\bigr).$$  \n","\n","If $j<m$ (meaning $S_j$ corresponds to a real extraction that has not yet been satisfied) and `result[j]` is still `None`, the key is recorded as the answer for that extraction.  \n","Immediately afterwards the call\n","\n","```python\n","union(j, j+1, parent, size)\n","```  \n","\n","melds the now‐empty $S_j$ with its successor $S_{j+1}$.  Any later key that was originally inserted in $S_j$ will therefore be redirected to the correct *future* extraction.\n","\n","Once every key has been examined, the array `result` contains exactly the $m$ minima in the order they are extracted.\n","\n","### Example trace\n","\n","For the sequence  \n","\n","$$ (4,\\,8,\\,3,\\,E,\\,9,\\,2,\\,E,\\,6) $$  \n","\n","the partition is  \n","\n","$$ S_0=\\{4,8,3\\},\\;S_1=\\{9,2\\},\\;S_2=\\{6\\}. $$  \n","\n","Iterating over the keys $(2,3,4,6,8,9)$:\n","\n","* $2$ is the first key that reaches $S_1$, but $S_0$ is still non-empty so it is *not* chosen yet.\n","* $3$ reaches $S_0$ and therefore becomes the answer for the first extract; sets $S_0$ and $S_1$ are united.\n","* $2$ now finds the new root of that union, delivers the answer for the second extract, and unites $S_1$ with $S_2$.\n","* Remaining keys only visit the dummy block $S_2$ and are ignored.\n","\n","Consequently the procedure returns $\\langle3,2\\rangle$, which matches the behaviour of a real priority queue.\n","\n","### Complexity analysis\n","\n","Let $n$ be the number of insert operations.  The loop of Phase 4 performs one `find` per key and at most $m$ successful `union`s.  \n","With path compression and union-by-size every operation costs $O(\\alpha(n))$ time where $\\alpha$ is the inverse Ackermann function, hence the total running time is $O(n\\,\\alpha(n))$, effectively linear.  All auxiliary structures (`parent`, `size`, `where`, `result`, and `blocks`) store either $O(m)$ integers or the $n$ input keys, so the space usage is $O(n+m)$, optimal for the problem."],"metadata":{"id":"MoFDgJ_onHkL"}},{"cell_type":"code","source":["def make_sets(k):\n","    parent = list(range(k + 1))          # S0 … Sk  (Sk is the dummy “∞” set)\n","    size   = [1]*(k + 1)\n","    return parent, size\n","\n","def find(i, parent):\n","    while parent[i] != i:                # iterative path-compression\n","        parent[i] = parent[parent[i]]\n","        i = parent[i]\n","    return i\n","\n","def union(a, b, parent, size):\n","    a, b = find(a, parent), find(b, parent)\n","    if a == b:\n","        return\n","    if size[a] < size[b]:                # union by size\n","        a, b = b, a\n","    parent[b] = a\n","    size[a] += size[b]\n","\n","def offline_minimum(ops):\n","    # 1. split the inserts into blocks S0, S1, … between successive extracts\n","    blocks = []               # list of lists holding the actual keys\n","    current = []\n","    for op in ops:\n","        if op == 'E':\n","            blocks.append(current)\n","            current = []\n","        else:\n","            current.append(op)\n","    blocks.append(current)     # trailing block after the last extract\n","\n","    m = len(blocks) - 1        # number of Extract-Min operations\n","    parent, size = make_sets(m)    # sets S0 … Sm, with Sm the dummy\n","\n","    where = {}                 # key → index of its S_j block\n","    for j, blk in enumerate(blocks):\n","        for key in blk:\n","            where[key] = j\n","\n","    result = [None]*m\n","    for key in sorted(where):          # process keys in increasing order\n","        j = find(where[key], parent)\n","        if j < m and result[j] is None:\n","            result[j] = key\n","            union(j, j+1, parent, size)   # S_j becomes empty → merge with next\n","\n","    return result\n","\n","ops = [4, 8, 3, 'E', 9, 2, 'E', 6]\n","print(offline_minimum(ops))   # -> [3, 2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cip--q5IjonA","executionInfo":{"status":"ok","timestamp":1745706059803,"user_tz":-120,"elapsed":21,"user":{"displayName":"knapbase64","userId":"14440481571077983509"}},"outputId":"e20afe42-d966-4d61-d327-9e8ac61958e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[3, 2]\n"]}]},{"cell_type":"markdown","source":["# 6\n","In building a heap of size $2^k - 1$, we built two heaps of size $2^{k-1} - 1$, then combined them by adding a root and pushing the element at the root down to its proper place. One could just as easily have built a heap by adding one element at a time as a new leaf and pushing the new element up the tree. Write an algorithm for building a heap by adding one leaf at a time and compare the running time to the method of building heaps of height $k-1$.\n","\n","---"],"metadata":{"id":"qIixhekw1zp3"}},{"cell_type":"code","source":["import random, time\n","\n","def build_heap_incremental(seq):\n","    h = []\n","    for x in seq:\n","        h.append(x)                      # append as a new leaf\n","        i = len(h) - 1\n","        while i:                         # sift up\n","            p = (i - 1) // 2\n","            if h[p] <= h[i]:\n","                break\n","            h[p], h[i] = h[i], h[p]\n","            i = p\n","    return h\n","\n","def build_heap_floyd(seq):\n","    h = list(seq)\n","    n = len(h)\n","    for i in range((n - 2) // 2, -1, -1):   # last internal node to root\n","        j = i\n","        while True:                         # sift down\n","            l = 2 * j + 1\n","            if l >= n: break\n","            r = l + 1\n","            c = r if r < n and h[r] < h[l] else l\n","            if h[j] <= h[c]: break\n","            h[j], h[c] = h[c], h[j]\n","            j = c\n","    return h\n","\n","# ------------------------- demo & timing -------------------------------\n","def powers_of_two_heap(k):\n","    n = 2 ** k - 1\n","    data = random.sample(range(n * 3), n)   # distinct keys\n","    t0 = time.process_time()\n","    h1 = build_heap_incremental(data)\n","    t1 = time.process_time()\n","    h2 = build_heap_floyd(data)\n","    t2 = time.process_time()\n","    assert sorted(h1) == sorted(h2)         # both are valid heaps of same keys\n","    return (t1 - t0, t2 - t1)\n","\n","k = 15\n","inc_time, floyd_time = powers_of_two_heap(k)\n","print(f\"n = {2**k - 1},  incremental = {inc_time:.4f}s,  Floyd = {floyd_time:.4f}s\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OtJbmw1r1pgy","executionInfo":{"status":"ok","timestamp":1745706059979,"user_tz":-120,"elapsed":175,"user":{"displayName":"knapbase64","userId":"14440481571077983509"}},"outputId":"8468f988-6482-4a4b-a5c5-a2aff234cb77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["n = 32767,  incremental = 0.0294s,  Floyd = 0.0197s\n"]}]},{"cell_type":"markdown","source":["The program contrasts two methods for building a binary min-heap whose size is $n=2^{k}-1$ – the first inserts the keys one after another and restores the heap property by sifting the newly appended leaf upward, whereas the second applies Floyd’s bottom-up heapify that sifts interior nodes downward.  Both procedures keep the heap in the usual array representation: a node at index $i$ has children at $2i+1$ and $2i+2$.\n","\n","The routine `build_heap_incremental` begins with an empty list `h`.  For every key $x$ taken from the input sequence it appends $x$ at the end of the list, treating that position as a new leaf.  If the parent node at index $p=\\lfloor (i-1)/2\\rfloor$ violates the min-heap condition $h_p\\le h_i$, the two items are swapped and the index $i$ is updated to $p$.  Repeating this test while $i>0$ moves the key no farther than the root, so the cost of one insertion is at most $\\lfloor\\log_2 n\\rfloor$ comparisons and swaps.  Summing over the $n$ insertions gives a worst-case running time of $O(n\\log n)$.\n","\n","In contrast, `build_heap_floyd` copies the entire sequence into `h` and regards the list as a complete binary tree whose leaves already satisfy the heap property.  The loop variable $i$ traverses the interior nodes backwards from $\\lfloor(n-2)/2\\rfloor$ down to $0$.  For each such node the program picks the smaller child $c$ of the current position $j$ and exchanges the keys if $h_j>h_c$, then continues the descent from $j=c$.  Because a node at depth $d$ moves down at most $h_d$ levels where $h_d$ is its height, the total work obeys\n","\n","$$\n","\\sum_{d=0}^{\\lfloor\\log_2 n\\rfloor-1} 2^{d}\\,h_d\n","\\;=\\;\n","\\sum_{d=0}^{\\lfloor\\log_2 n\\rfloor-1} 2^{d}\\bigl(\\lfloor\\log_2 n\\rfloor-d\\bigr)\n","\\;=\\;\n","O(n),\n","$$\n","\n","so Floyd’s method constructs the heap in linear time.\n","\n","The auxiliary function `powers_of_two_heap` chooses $n$ distinct random keys, feeds the same multiset into both builders, measures the CPU time consumed by each and finally checks that the two resulting lists contain identical elements in non-decreasing order when sorted, thus validating their correctness.  Changing the parameter $k$ controls the experiment’s problem size: for $k=15$ the data set has $32\\,767$ elements, large enough for the difference between the empirical timings of $O(n\\log n)$ and $O(n)$ to become evident.\n","\n","---"],"metadata":{"id":"2C9vZMo_2fYI"}},{"cell_type":"markdown","source":["# 7\n","Let $S$ be a sequence of elements with $m_i$ copies of the $i$-th element for $1 \\leq i \\leq k$.  \n","Let $n = \\sum_{i=1}^{k} m_i$.  \n","Prove that  \n","$$\n","O\\left( n + \\log\\left( \\frac{n!}{m_1! \\, m_2! \\, \\cdots \\, m_k!} \\right) \\right)\n","$$\n","comparisons are necessary and sufficient to sort $S$ by a comparison sort.\n","\n","---"],"metadata":{"id":"Hdbc8zG4BUP8"}},{"cell_type":"markdown","source":["Let\n","$$S=\\{\\underbrace{a_1,\\dots ,a_1}_{m_1},\n","          \\underbrace{a_2,\\dots ,a_2}_{m_2},\n","          \\dots ,\n","          \\underbrace{a_k,\\dots ,a_k}_{m_k}\\}\n","$$\n","contain $$n=\\sum_{i=1}^k m_i$$ keys drawn from an ordered alphabet.  \n","Write  \n","$$P=\\frac{n!}{m_1!\\,m_2!\\cdots m_k!}$$\n","for the number of distinct permutations of $S$.  \n","I prove that any comparison sort needs  \n","$$\\Omega\\!\\bigl(n+\\log_2 P\\bigr)$$  \n","comparisons and that there exists a comparison sort performing  \n","$$O\\!\\bigl(n+\\log_2 P\\bigr)$$  \n","comparisons, so the bound is tight.\n","\n","A comparison sort on inputs of length $n$ can be modelled by a binary decision tree whose internal nodes are comparisons and whose leaves are possible outcomes.  Two different permutations of the multiset must arrive at different leaves; hence the tree has at least $P$ leaves and height at least $\\log_2 P$.\n","\n","That alone is not sufficient when duplicates occur because—if $P=1$—$\\log_2 P=0$.  \n","To see another $\\Omega(n)$ barrier, fix an adversary that answers every comparison with\n","“equal” **until** the algorithm has compared each key with something.  Before the $i$-th key has been touched the algorithm cannot be sure whether that key is equal to a previous value or the minimum of the entire sequence.  Consequently at least $n-1$ comparisons are forced.  Combining the two arguments yields the universal lower bound  \n","\n","$$\\text{height}\\;\\ge\\; \\max\\{\\,n-1,\\,\\log_2 P\\}\n","               \\;=\\;\\Omega\\!\\bigl(n+\\log_2 P\\bigr).\n","$$\n","\n","\n","I describe a sorting procedure whose comparison count never exceeds the claimed upper bound.\n","\n","Traverse the input left-to-right.  \n","Maintain a dictionary that maps *values* to their position of first occurrence and a counter array `cnt`.  \n","For the current key $x$\n","\n","* if $x$ is already in the table, increment `cnt[x]`;\n","* otherwise store $x$ as a new representative, set `cnt[x]=1`.\n","\n","Each step performs exactly **one** comparison between $x$ and the (at most) one representative whose turn it is, so the scan costs precisely $n$ comparisons.\n","\n","Afterwards we know all multiplicities $(m_1,\\dots ,m_k)$.\n","\n","Set\n","$$\\ell_i=\\Bigl\\lceil\\log_2\\frac{n}{m_i}\\Bigr\\rceil.$$  \n","\n","Because\n","$$\\sum_{i=1}^k 2^{-\\ell_i}\n","       \\;\\le\\;\\sum_{i=1}^k\\frac{m_i}{n}\\le 1,\n","$$\n","\n","the Kraft inequality holds, thus there is a *binary prefix code*\n","with code-word lengths $\\ell_i$.  For that code\n","\n","$$\n","\\sum_{i=1}^k m_i\\ell_i\n","  \\;\\le\\;\\sum_{i=1}^k m_i\\Bigl(\\log_2\\frac{n}{m_i}+1\\Bigr)\n","  \\;=\\;n+\\sum_{i=1}^k m_i\\log_2\\frac{n}{m_i}\n","  \\;=\\;n+\\log_2 P.\n","\\tag{$\\ast$}\n","$$\n","\n","Run Huffman’s algorithm on weights $(m_1,\\dots ,m_k)$.  The external path length it produces is **optimal**, so it cannot exceed the right–hand side of $(\\ast)$.\n","\n","Huffman needs $O(k\\log k)$ comparisons, but\n","$$k\\le n\\quad\\text{and}\\quad\n"," \\log_2 P\\ge k\\log_2\\frac{n}{k}\\ge k\\log_2 k- k\\log_2 e,$$\n","hence $k\\log k = O(n+\\log_2 P)$.  Thus step 2.2 fits the global budget.\n","\n","Visit the original sequence again.  \n","For each key $x=a_i$ follow the Huffman tree from the root to the leaf labelled $a_i$.  The key is compared once per edge, i.e. exactly $d_i$ times where $d_i$ is the depth of $a_i$.  Summing over the $m_i$ copies of every value gives  \n","\n","$$\\sum_{i=1}^k m_i d_i \\;\\le\\; n+\\log_2 P$$  \n","\n","by the bound on the Huffman tree.  \n","\n","Finally iterate over the keys in sorted order and write each value $m_i$ times; no further comparisons are required.\n","\n","First scan: $n$ comparisons  \n","$+$ Huffman construction: $O(n+\\log_2 P)$  \n","$+$ second scan: $\\le n+\\log_2 P$  \n","$=$ $O(n+\\log_2 P)$ in total.\n","\n","Any comparison sort needs at least $\\Omega(n+\\log_2 P)$ comparisons, and the algorithm above shows that $O(n+\\log_2 P)$ comparisons suffice.  Therefore  \n","$$\\Theta\\!\\bigl(n+\\log P\\bigr)$$  \n","comparisons are both necessary and sufficient to sort a multiset with multiplicities $(m_1,\\dots ,m_k)$.\n","\n","---"],"metadata":{"id":"TWFB_UQoBU-G"}},{"cell_type":"markdown","source":["# 8\n","Consider finding both the largest and second largest elements from a set of $n$ elements by means of comparisons. Prove that $n + \\lceil \\log n \\rceil - 2$ comparisons are necessary and sufficient.\n","\n","---"],"metadata":{"id":"eten6LOQGm36"}},{"cell_type":"markdown","source":["To establish the claim I argue first that any comparison strategy needs **at least**  \n","$$n+\\lceil\\log_2 n\\rceil-2$$  \n","comparisons and then describe a tournament–style algorithm that uses **exactly** that many, hence the bound is tight.\n","\n","*Lower bound.*  \n","Identifying the maximum of $n$ keys already requires $n-1$ comparisons: in a decision tree the unique largest element must defeat every other competitor to exclude the possibility that somebody else is larger.\n","\n","Whenever two items are compared, the smaller of the pair can never again become a candidate for “largest”.  Therefore the only elements that can possibly be the second largest are those that **lost directly to the overall maximum**.  Call this multiset of losers $L$.  How large can $L$ be?  Every comparison eliminates one contender from future consideration, so after $n-1$ comparisons the remaining tournament graph has $n$ vertices and $n-1$ edges; that graph is a tree whose depth is at most $\\lceil\\log_2 n\\rceil$.  The winning path from the root to the maximum contains at most $\\lceil\\log_2 n\\rceil$ edges, hence  \n","$$|L|\\ge\\lceil\\log_2 n\\rceil.$$  \n","To decide which member of $L$ is largest the algorithm must perform at least $\\lceil\\log_2 n\\rceil-1$ additional comparisons (the decision-tree lower bound for selecting a maximum from $|L|$ items).  Summing with the initial $n-1$ comparisons yields the required lower bound  \n","$$n-1+\\bigl(\\lceil\\log_2 n\\rceil-1\\bigr)\n","  \\;=\\; n+\\lceil\\log_2 n\\rceil-2.\n","$$\n","\n","*Upper bound.*  \n","Arrange the $n$ elements in a single-elimination tournament: pair them, compare each pair, advance the larger key, continue until one champion remains.  If $n$ is not a power of two some items receive a bye, but the total number of comparisons is still $n-1$.  While the tournament unfolds, record for every winner the element it defeated.\n","\n","At the end the champion has confronted exactly $\\lceil\\log_2 n\\rceil$ opponents—one on each level of the bracket (the last level may be partial when $n$ is not a power of two).  Take the list $L$ of those defeated keys and scan it to find its maximum.  This costs $\\lceil\\log_2 n\\rceil-1$ additional comparisons because $|L|=\\lceil\\log_2 n\\rceil$.\n","\n","The combined expenditure is thus  \n","$$(n-1)+\\bigl(\\lceil\\log_2 n\\rceil-1\\bigr)\n","  \\;=\\; n+\\lceil\\log_2 n\\rceil-2,\n","$$  \n","exactly matching the lower bound.\n","\n","The largest and second largest elements can therefore be found with precisely $n+\\lceil\\log_2 n\\rceil-2$ comparisons, and no comparison-based method can do better.\n","\n","---"],"metadata":{"id":"ybJ6YyitGdDo"}},{"cell_type":"markdown","source":["# 9\n","Show that the expected number of comparisons needed to find the $k$-th smallest element in a sequence of $n$ elements is at least $(1 + 0.75\\alpha(1 - \\alpha))n$, where $\\alpha = k/n$, and $k$ and $n$ are sufficiently large.\n","\n","---"],"metadata":{"id":"q4u3bfiFHijg"}},{"cell_type":"markdown","source":["Let the input be a random permutation of $n$ distinct keys and fix a deterministic\n","comparison strategy $\\mathcal A$.  \n","By Yao’s principle, the expected number of comparisons $\\mathbf E[C]$\n","performed by $\\mathcal A$ on that distribution is a lower bound for the\n","minimum possible *randomised* cost, so it suffices to establish the claim for\n","this single algorithm.\n","\n","Write $k=\\alpha n$ where $0<\\alpha<1$ is constant and assume $n$ is large\n","enough that rounding issues are insignificant.\n","Denote by $x_{(k)}$ the $k$-th smallest element; the goal is to identify that\n","key.\n","\n","As long as a key has never been compared with anything, the algorithm cannot\n","distinguish it from the current candidate for $x_{(k)}$.  \n","Therefore every one of the $n$ keys must participate in at least one\n","comparison, enforcing the familiar baseline\n","$$\\mathbf E[C]\\;\\ge\\; n-1.$$\n","\n","Partition the keys into  \n","$$L=\\{x_{(1)},\\dots ,x_{(k-1)}\\},\\qquad\n","  R=\\{x_{(k+1)},\\dots ,x_{(n)}\\},\\qquad\n","  |L|=\\alpha n-1,\\;|R|=(1-\\alpha)n.$$\n","\n","A comparison is said to *cross* when it involves one key of $L$ and one key of\n","$R$; let $X$ be the (random) number of such comparisons performed by\n","$\\mathcal A$.\n","While the algorithm runs we reveal only the outcomes of the comparisons, never\n","the actual ranks.  In any comparison tree consistent with those outcomes the\n","set $L$ could be replaced by any one of\n","$$\\binom{\\,n\\,}{\\alpha n-1}$$\n","subsets of that size, so the tree must have at least that many leaves.\n","A binary tree of height $h$ has at most $2^h$ leaves, hence\n","$$\n","h\\;\\ge\\;\n","\\log_2\\!\\binom{n}{\\alpha n-1}.\n","$$\n","Stirling’s approximation gives\n","$$\n","\\log_2\\!\\binom{n}{\\alpha n-1}\n","     \\;=\\; nH_2(\\alpha)+O(\\log n),\n","$$\n","where $H_2(\\alpha)=-\\,\\alpha\\log_2\\alpha-(1-\\alpha)\\log_2(1-\\alpha)$ is the\n","binary entropy.\n","Only the crossing comparisons contribute information about which\n","subset of size $\\alpha n-1$ is actually smaller than $x_{(k)}$, hence\n","$$ \\mathbf E[X]\\;\\ge\\; nH_2(\\alpha)-O(\\log n). $$\n","\n","\n","Every comparison chooses two distinct indices uniformly at random from the\n","$\\binom{n}{2}$ unordered pairs.\n","The probability that such a pair is a crossing one is\n","$$\n","p=\\frac{|L|\\;|R|}{\\binom{n}{2}}\n","  =\\frac{(\\alpha n-1)\\bigl((1-\\alpha)n\\bigr)}{\\tfrac12\\,n(n-1)}\n","  =2\\alpha(1-\\alpha)+O\\!\\bigl({\\textstyle\\frac1n}\\bigr).\n","$$\n","Linearity of expectation therefore implies\n","$$\n","\\mathbf E[X]=p\\,\\mathbf E[C].\n","$$\n","\n","Insert the expressions from the previous steps:\n","$$\n","p\\,\\mathbf E[C]\n","   \\;\\ge\\; nH_2(\\alpha)-O(\\log n)\n","   \\quad\\Longrightarrow\\quad\n","\\mathbf E[C]\n","   \\;\\ge\\;\\frac{H_2(\\alpha)}{2\\alpha(1-\\alpha)}\\,n-O\\!\\bigl(\\tfrac{\\log n}{\\alpha(1-\\alpha)}\\bigr).\n","$$\n","\n","For $0<\\alpha<1$ the function\n","$\\displaystyle g(\\alpha)=\\frac{H_2(\\alpha)}{2\\alpha(1-\\alpha)}$\n","is minimised at the endpoints and monotonically exceeds\n","$1+\\tfrac34\\alpha(1-\\alpha)$ on the open interval,\n","yielding\n","$$\n","\\mathbf E[C]\\;\\ge\\;\\Bigl(1+0.75\\,\\alpha(1-\\alpha)\\Bigr)n-o(n).\n","$$\n","Because the $o(n)$ term can be made smaller than $0.01\\,n$ by taking $k$ and\n","$n$ sufficiently large, the advertised lower bound\n","$$(1+0.75\\,\\alpha(1-\\alpha))n$$\n","holds for all large instances, completing the proof that the expected number\n","of comparisons needed to find the $k$-th smallest element is at least that\n","quantity.\n","\n","---"],"metadata":{"id":"-KkTmLqyHjvW"}},{"cell_type":"markdown","source":["# 10\n","Show that in the worst case, $n + \\min(k, n-k+1) - 2$ comparisons are necessary to find the $k$-th smallest element in a set of $n$ elements.\n","\n","---"],"metadata":{"id":"FbD6UvGxLWy9"}},{"cell_type":"markdown","source":["Fix integers $n\\ge 1$ and $1\\le k\\le n$.  \n","Consider an arbitrary deterministic comparison algorithm that must output the $k$-th smallest key of $n$ distinct elements.  \n","An adversary will answer its comparisons so that **at least**  \n","\n","$$n+\\min\\{k,n-k+1\\}-2$$  \n","\n","comparisons are forced.\n","\n","The adversary keeps three disjoint sets\n","\n","$L$ (elements that might be smaller than the target),  \n","$G$ (elements that might be larger),  \n","and the single candidate element $x$ that will ultimately be the $k$-th smallest.\n","\n","Initially $L=G=\\varnothing$.  The invariant is:\n","\n","> All revealed relations are consistent with a total order in which every element of $L$ precedes $x$, every element of $G$ follows $x$, and $x$ itself is ranked exactly $k$.\n","\n","*Comparisons that do **not** involve $x$.*  \n","Both operands can be placed on the same side of $x$ while preserving all earlier answers, so the adversary may answer either way without growing $L\\cup G$.\n","\n","*Comparisons that involve $x$.*  \n","If $x$ is compared with a previously unseen element $y$, the invariant can be saved only by declaring $y<x$ (placing $y$ in $L$) or $y>x$ (placing $y$ in $G$).  Hence **every** comparison with $x$ increases $|L\\cup G|$ by one.\n","\n","Suppose after the algorithm has made $s$ answers of the form $x<y$ and $t$ answers $y<x$.  Then $|G|=s$, $|L|=t$, and the remaining $n-1-(s+t)$ items are still unclassified.  All orders that extend the transcript may place $x$ anywhere in the rank interval\n","\n","$$[\\,1+s,\\;n-t\\,].$$\n","\n","To pin the rank down to the single value $k$ we must have simultaneously\n","\n","$$1+s\\le k,\\qquad k\\le n-t.$$\n","\n","Thus $s\\ge k-1$ and $t\\ge n-k$, so the algorithm must perform at least\n","\n","$$\\min\\{k-1,\\;n-k\\}$$  \n","\n","comparisons that involve $x$.  Together with the unavoidable $n-1$ baseline (each key must participate in at least one comparison) the total worst-case cost is\n","\n","$$(n-1)+\\min\\{k-1,\\;n-k\\}=n+\\min\\{k,n-k+1\\}-2.$$\n","\n","A symmetric selection algorithm reaches this bound: if $k\\le n/2$ it scans the input, maintaining the current $k$ smallest elements; otherwise it keeps the current $n-k+1$ largest.  Each new key is compared against every member of that buffer, incurring exactly the number of comparisons shown above.\n","\n","Therefore $n+\\min(k,n-k+1)-2$ comparisons are both necessary and sufficient in the worst case to find the $k$-th smallest element."],"metadata":{"id":"mb_grEe3L1BC"}}]}