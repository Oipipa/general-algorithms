<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[general-algorithms]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib/media/favicon.png</url><title>general-algorithms</title><link></link></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Fri, 18 Jul 2025 10:14:41 GMT</lastBuildDate><atom:link href="lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Fri, 18 Jul 2025 10:04:52 GMT</pubDate><ttl>60</ttl><dc:creator></dc:creator><item><title><![CDATA[Appendix-I]]></title><description><![CDATA[ 
 <br><br>Cantor’s diagonal argument is a template for escaping any purportedly complete list.  Complexity theory adapts that template to escape lists of algorithms, but unlike Cantor we must honour explicit resource budgets. <br>We begin with an effective enumeration of Turing machines. Fix a binary <a class="internal-link" data-href="Appendix-II" href="appendix-ii.html" target="_self" rel="noopener nofollow">Gödel coding</a><br><br>that maps every finite description of a single‐tape DTM to a unique code word .  <br>Decoding is computable, so the machines can be listed in lexicographic order<br><br>with the convention that machine  is the one whose code is .<br><br>Let  be a time-constructible function: there exists a DTM that, given , writes  in binary and halts in strictly fewer than  steps.   Typical examples include , , , .<br>Time-constructibility is essential: the diagonalising machine will need to stop precisely at step , so it must be able to count that high inside the same bound.<br><br>Define a new machine  that, on input  of length , executes the following macro-procedure:<br>
<br>Parse  as a Gödel Code.  If  is not a valid code, reject immediately; its behaviour is irrelevant to the diagonal argument.
<br>Initialise a step counter with the binary value .  On a single tape this requires  cells.
<br>Simulate machine  on input  for at most  steps: after each simulated step, decrement the counter by one bit-level subtraction.  The decrement itself costs  real steps because it may ripple through every bit of the counter.
<br>Flip the result if the simulation halts in time:<br>
– if  accepts, then  rejects;<br>
– if  rejects,  accepts.
<br>Timeout: if the counter reaches zero before  halts,  accepts (the particular flip is arbitrary—any fixed choice works).
<br><br>Each simulated step consumes<br>
<br>1 real step to copy the simulated head move and state update, plus  
<br> real steps to decrement the binary counter.
<br>Hence the total running time of  obeys<br><br>Because  is constructible, this upper bound is itself time-constructible (a product of constructibles remains constructible).<br><br>Assume for contradiction that  belongs to . Then there exists an index  such that .<br>Feed  to :<br>
<br> simulates itself on its own code for at most  steps.  
<br>By design it will flip the outcome relative to that simulation.
<br>Therefore  disagrees with  on input , a contradiction because they are the same machine.   So  is not in , yet its running-time analysis places it in .<br>We obtain the deterministic time hierarchy theorem:<br><br>provided both  and  are constructible.<br><br>On a -tape machine, the binary counter can live on its own tape while the simulator streams the work of  on the others. Decrementing now takes constant time because the head revisits the counter tape only where bits actually change.   This removes the  overhead, yielding the tighter condition<br><br>The argument for space is even cleaner: the step counter occupies  cells, but those cells overwrite themselves, so the simulator’s extra space is constant; hence  already implies a proper inclusion.<br><br>Diagonalisation extends to probabilistic time, alternating time, or any model where<br>
<br>machines can be effectively enumerated, and  
<br>resource use can be easily tracked during simulation.
<br>The difficulty grows with nondeterminism because each existential branch can fork into many simulations.  For alternating machines the diagonal must flip who makes the next move, yielding the polynomial hierarchy, whose collapses remain unproved.<br>Cantor’s original insight—that lookup on the diagonal plus one strategic flip always evades a list—thus powers the most fundamental separations in resource-bounded computation. The only added hurdle is accounting for the cost of the bookkeeping itself, and that hurdle is exactly where the  factors and constructibility requirements arise.<br><br>Setting.<br>
Let the time budget be  <br>which is clearly time-constructible: given  a machine can write  in unary in  steps.<br>We restrict attention to very small Turing machines whose transition tables are encoded in two bits—enough to give the diagonal idea but small enough to show every detail on paper.<br><br>
Any other binary string is deemed “not a code’’ and causes the diagonal<br>
machine to reject without simulation.<br>
(This keeps the example finite.)
<br><br>D_t(x):       # x is the binary input string, length n
  if x ∉ {"00","01","10","11"}:
       reject                             # invalid code
  counter ← n+1                           # this is t(n)
  simulate M_x on input x:
       after each simulated step:
            decrement counter
            if counter = 0: goto TIMEOUT
  if M_x accepted: reject                 # flip result
  else           : accept
TIMEOUT:
  accept                                   # arbitrary but fixed
<br>Resource accounting<br>
Each simulated step of any M_w costs one real step to copy the move plus the cost to decrement the unary counter. Decrementing a unary string costs one real step, so the total running time is at most<br><br>Thus D_t actually fits inside the same budget it challenges.<br><br><br>In every row D_t disagrees with the machine it simulates. Because our example list contained all machines that run within the budget, D_t cannot itself be one of them.<br><br>Suppose we raise the budget to     and enumerate all machines that halt within that bigger window.  Our previous D_t already satisfies the new limit, so it now does belong  to . To diagonalise again we build a new machine   whose counter starts at  and which flips the answers of every -time machine. Iterating in this way produces an infinite ladder of strictly stronger time classes<br><br>mirroring the general hierarchy theorem proved with arbitrary constructible bounds.]]></description><link>appendix-i.html</link><guid isPermaLink="false">Appendix-I.md</guid><pubDate>Fri, 13 Jun 2025 09:12:57 GMT</pubDate></item><item><title><![CDATA[Appendix-II]]></title><description><![CDATA[ 
 <br><br>That act of naming—assigning each syntactic object a unique natural number—is called Gödel numbering, after Kurt Gödel’s 1931 incompleteness proof.<br><br>Formally, a Gödel numbering for a set  of finite strings is a total, computable, bijective map   whose inverse  is also computable.  <br>In practice  is the set of programs, formulas, or Turing‐machine descriptions under some fixed grammar.<br>The twin requirements “computable both ways’’ make sure that from a number we can reconstruct its program, and from a program we can compute its number, all within finite time on a Turing machine.  Without those properties the diagonal construction would stall at the very first step.<br><br>Gödel’s original scheme used the fundamental theorem of arithmetic.  Let a finite sequence of positive integers  represent the symbols of a formula.  Map it to  <br><br>where  is the -th prime.  Unique prime factorisation makes the map injective; divisibility tests recover each exponent, making the inverse computable.<br>The prime trick is conceptually elegant but arithmetically unwieldy for complexity theory: factoring large integers costs super-polynomial time (as far as we know).  Modern treatments therefore prefer string encodings.<br><br>Fix an alphabet for Turing‐machine instructions, say  <br>{L, R, 0, 1, B, q0, q1, …}
<br>Turn each symbol into an 8-bit code (ASCII or any injective map). Concatenate the codes to get a binary string. Finally interpret that string as the binary expansion of a natural number. Lexicographic order or the numeric value itself serves as the Gödel number.<br>Because conversion between strings and their binary numerals is linear-time, this encoding is polynomially bounded and well suited to resource-sensitive arguments.<br><br>
<br>Surjective onto programs – every integer labels some syntactically valid<br>
machine (we may pad unused integers with a trivial “loop forever’’ program).
<br>Prefix-free variants – sometimes we insist that no code is a prefix of another; Kraft’s inequality lets us design such “self-delimiting’’ encodings, essential in Kolmogorov complexity.
<br>Self-reference – given a program  we can build a new program that knows  and inserts it into its own source.  This is the Recursion (or --) theorem in computability.
<br><br>With an effective enumeration in hand we speak of “machine ” where<br><br>Cantor’s diagonal machine  receives an input , interprets  as , simulates  on , and flips the outcome.  <br>Two facts are critical:<br>
<br>Lookup: computing  from  is feasible within the stated resource<br>
(time or space); otherwise  would overshoot its budget before even<br>
beginning the simulation.
<br>Padding: infinitely many integers encode equivalent machines, so we<br>
can stretch a program’s Gödel number without changing its behaviour—<br>
a trick often used in proof-length and Kolmogorov arguments.
<br><br><br>Imagine we want a single interpreter to run every program drawn from an assembly.  <br>For that we must turn each program into ordinary data so the interpreter can<br>
load it, parse it, and simulate it.  <br>Gödel numbering supplies exactly that bridge from code to data.<br><br><br>A program is a finite string over the alphabet  {P0,P1,POP,HALT}.  We agree to concatenate the 2-bit codes and interpret the resulting bit-string as a binary integer.  That integer is the Gödel number.<br>Example program  <br>P1 P1 POP HALT
<br>becomes the bit-string  <br>01 01 10 11 → 01011011₂ → 0b01011011 = 91₁₀ .
<br>So 91 is the Gödel number for “push 1, push 1, pop, halt”.<br>Decoding works in reverse: write the integer in binary, pad to a multiple of two bits, slice into pairs, look each pair up in the code table.<br><br>A universal stack-machine U does:<br>
<br>Read an input tape of the form ⟨g⟩ # ⟨x⟩<br>
(# is a separator, g the Gödel number, x the program’s input data).
<br>Decode g back into its instruction list by repeated<br>
div 2, mod 2 operations to peel off the lowest two bits.
<br>Simulate the decoded instructions on an internal stack, feeding x as<br>
initial input.
<br>Because encoding/decoding is linear in the bit-length of g, the overhead is at worst a constant factor on RAMs or a logarithmic factor on one-tape Turing machines.  <br>This “self-hosting” capability—programs manipulating programs—is how modern compilers, virtual machines, and sandboxers operate at scale.<br><br>With an effective Gödel numbering in place we can refer to “the program whose number equals its own input”.  Consider the language  <br><br>Suppose for contradiction that some finite program H decides L.<br>Encode H as the integer h.  <br>Now run H on its own code:<br>input = h  
program = H (whose number is h)  
output = H(h) ∈ {HALT, LOOP}
<br>Flip the answer (halt if H loops, loop if H halts) to build a new program K.   By construction, K and H disagree on the single input h, yet both are ordinary programs: contradiction.  Therefore no program decides L.  <br><br>Define the description length<br><br>where  is the bit-length of the Gödel number and U is the<br>
universal interpreter above.  <br> measures how compressible a string is—core to randomness tests and incompressibility arguments in data structures.  Without a computable code-to-integer map the very definition of  would collapse.<br><br>Suppose you are writing an embedded control network in which each node is too<br>
small to host a full file-system.  <br>Instead of transferring “files”, you stream a single integer whose binary digits are interpreted as the node’s byte-code.  <br>The sender encodes a short program into an integer; the receiver decodes and executes it.<br>Below is 40 lines of ordinary Python that do exactly that.<br># ---------- shared miniature ISA ----------
OPCODES = {
    0b000: "PUSH0",   # push constant 0
    0b001: "PUSH1",   # push constant 1
    0b010: "ADD",     # pop x,y; push x+y
    0b011: "SUB",     # pop x,y; push x-y
    0b100: "DUP",     # duplicate top
    0b101: "POP",     # discard top
    0b110: "PRINT",   # output top (leave it)
    0b111: "HALT",    # stop
}
BITS = 3                       # each opcode fits in 3 bits
MASK = (1 &lt;&lt; BITS) - 1

# ---------- ❶ encode a program to a Gödel number ----------
def encode(instrs):
    """instrs = list of mnemonic strings -&gt; single integer code"""
    code = 0
    for op in reversed(instrs):       # least-significant bits hold first instr
        code = (code &lt;&lt; BITS) | inv[op]
    return code

# ---------- ❷ decode back to a list of mnemonics ----------
def decode(code):
    instrs = []
    while code:
        instrs.append(OPCODES[code &amp; MASK])
        code &gt;&gt;= BITS
    instrs.reverse()
    return instrs

# ---------- ❸ universal interpreter ----------
def run(code):
    tape = []                         # operand stack
    pc   = 0                          # program counter in decoded list
    prog = decode(code)
    while pc &lt; len(prog):
        op = prog[pc]
        pc += 1
        if   op == "PUSH0":  tape.append(0)
        elif op == "PUSH1":  tape.append(1)
        elif op == "ADD":    tape.append(tape.pop() + tape.pop())
        elif op == "SUB":    tape.append(tape.pop() - tape.pop())
        elif op == "DUP":    tape.append(tape[-1])
        elif op == "POP":    tape.pop()
        elif op == "PRINT":  print(tape[-1])
        elif op == "HALT":   break
    return tape[-1] if tape else None

# ---------- demo ----------
inv = {m: b for b, m in OPCODES.items()}

program = ["PUSH1", "PUSH1", "ADD", "PRINT", "HALT"]   # computes 1+1
godel   = encode(program)                              # -&gt; 0b111010001 = 465
print("Gödel number sent over wire:", godel)
run(godel)                                             # receiver runs it
<br>What happens in practice<br>
<br>Development laptop — assembles ["PUSH1","PUSH1","ADD","PRINT","HALT"] into the single integer 465, sends the ASCII string "465\n" over TCP.
<br>Constrained node — reads the integer, calls decode(465), obtains the five instructions, and executes them with run(465).  The program prints 2 and halts.  No file system, no parsing of textual source, just 3 bits per opcode.
<br>Why count as Gödel numbers?

<br>bijective: every finite instruction list maps to exactly one integer;
<br>computable: encode/decode run in time linear in program length;
<br>self-reference ready: the program could PUSH its own Gödel number and transmit it elsewhere, enabling mobile-code patterns.


<br><br><br>A device engineer writes a five-line script in a stack-based DSL:<br>; avg-fan.scmpl – keep fan off unless 10-sample mean &gt; 30°C
PUSH0        ; total = 0
PUSH0        ; i = 0
LOOP:
  DUP        ; copy i
  LOAD       ; read temp[i]
  ADD        ; total += temp[i]
  PUSH1
  ADD        ; i++
  DUP
  PUSH10
  LT         ; i &lt; 10 ?
  JZ END
  JMP LOOP
END:
PUSH10
DIV          ; mean = total / 10
PUSH30
GT           ; mean &gt; 30 ?
JZ HALT
FAN_ON
HALT
<br>The assembler maps each mnemonic to a 4-bit opcode (nybble):<br><br>The assembler resolves label distances (k) and emits a nybble stream<br>0 0 2 3 4 1 4 2 A 5 8 3 9 B 0 7 1 E 6 8 1 F
<br>(Here A = 10 decimal, B = 11; the two-nybble operands 8 3 and 9 B encode JZ +3 and JMP –11.)<br>Concatenate:  00234...F → "00234...F" (22 nybbles, 88 bits).<br><br>Interpret the hex string as one big unsigned integer:<br>bytecode_hex = "002342147A58 9B07 1E68 1F".replace(" ", "")
godel        = int(bytecode_hex, 16)
# suppose this equals 142_230_265_139_359_871
<br>That 64-bit number is the plug-in. Because the map&nbsp;“hex stream → integer” is bijective and the inverse (repeated mod 16, div 16) is trivial,  this is a valid Gödel numbering.<br><br>Headquarters produces the update packet:<br>&lt;ASCII decimal of godel&gt;\n
&lt;device-class code&gt;\n
&lt;signature bytes&gt;\n
<br>
<br>device-class helps the node choose the right interpreter version.
<br>signature = Sign(priv_key, SHA-256(godel || device-class)).
<br>ASCII avoids control-byte leakage through old gateways; the integer’s shortest-base-10<br>
form saves 1/3 over hex.<br><br>
<br>Reception – UART driver collects ASCII until newline, converts to a 64-bit uint64_t.
<br>Signature check – on-board ECDSA verifies the signature with a 32-kB ROM public key.
<br>Deduplication – node compares godel against last-known value to skip redundant flashes.
<br>Flash staging – the 64-bit number plus 2-byte metadata use only 10 bytes of flash.
<br><br>uint8_t bytecode[N_MAX];   // N_MAX = 32 nybbles
size_t  n = 0;

while (godel) {            // strip nybbles LSB first
    bytecode[n++] = godel &amp; 0xF;
    godel       &gt;&gt;= 4;
}
reverse(bytecode, n);      // restore original order
<br>Cost:<br>
<br>shifting godel right by 4 → one cycle on Cortex-M0
<br>loop repeats n times; space is n bytes plus uint64_t godel.
<br>For our 22-nybble program, 22 iterations ≈ 50 µs at 16 MHz.<br><br>A loop:<br>for (pc = 0; ; ++pc) {
    switch (bytecode[pc]) {
        case 0x0: push(0);           break;       // PUSH0
        case 0x1: push(1);           break;       // PUSH1
        case 0x2: dup();             break;       // DUP
        case 0x3: a = pop(); push(load(a)); break;// LOAD
        ...
        case 0x8: k = bytecode[++pc]; if (!pop()) pc += k; break; // JZ
        case 0xF: goto halt;
    }
}
<br>The interpreter occupies 820 bytes of flash, 96 bytes of RAM for stack and   sensors—well within the node’s 32 kB / 2 kB budget.<br><br>The node periodically sends<br>STATUS 142230265139359871 OK
<br>The backend instantly knows which plug-in binary is running—no hashing needed.<br>]]></description><link>appendix-ii.html</link><guid isPermaLink="false">Appendix-II.md</guid><pubDate>Fri, 13 Jun 2025 16:31:53 GMT</pubDate></item><item><title><![CDATA[Appendix-III]]></title><description><![CDATA[ 
 <br><br>Type theory is a formal system in which every term carries a type, and computation and logic are unified through the discipline of typing. Unlike traditional set‐theoretic foundations, where the focus is on membership, type theory centers on classification and construction. In this introduction we develop the core ideas step by step—starting from simple types, moving through polymorphism, and touching on dependent constructs—without invoking any particular variant such as Martin‐Löf’s.<br>At the base lies the simply‐typed lambda calculus. We have a collection of basic types (often written ) and build more complex types via function arrows:<br><br>where  ranges over atomic type symbols. Terms  are variables, abstractions, and applications:<br><br>Typing is governed by judgments of the form<br><br>meaning “under context  (a list of assumptions ), term  has type .” Two fundamental rules are:<br>
<br>Variable  


<br>Abstraction  


<br>Application  


<br>These rules enforce type safety: well‐typed terms cannot “go wrong” at run time.<br>Beyond simply‐typed calculi, polymorphic type theories like System F introduce universal quantification over types. Types now include<br><br>and one writes  to abstract over a type. The typing rules are<br>
<br>
Type Abstraction  


<br>
Type Application  

<br><br>System F captures parametric polymorphism: functions like the identity<br><br>have type , meaning they truly work for any type .<br>Another central idea is sum and product types. Given types  and , we form<br>
<br>
Product , with constructors

 Typing rules ensure  and so on.

<br>
Sum , with injections

and elimination by case analysis:


<br>These constructions mirror logical conjunction and disjunction under the Curry–Howard correspondence, which relates<br>
<br> ↔ “ and ”  
<br> ↔ “ or ”  
<br>and more generally sees proofs as programs and propositions as types.<br>A critical structural insight is the principal typing property and type inference in languages like ML or Haskell. Under the Hindley–Milner system, even without explicit type annotations, terms admit a most general type , and every other type instance follows by substituting types for type variables in . This makes polymorphism practical: the compiler infers the type of<br><br>without burdening the programmer.<br>Finally, one can introduce limited dependent features without full-blown dependently‐typed theories. For instance, indexed types allow us to track simple invariants:<br>data Vec (A : Type) : Nat → Type where
  []  : Vec A 0
  (::) : A → Vec A n → Vec A (n+1)
<br>Here Vec A n is the type of lists of length n, giving the compiler enough information to prevent out‐of‐bounds errors in fixed‐length contexts.<br><br>Martin-Löf’s intensional dependent type theory (MLTT) provides the logical bedrock on which modern structural recursion is formulated. Its syntax, rules, and metatheorems are arranged around five ingredients:<br>
<br>judgements (the metalanguage),
<br>structural rules on contexts,
<br>type formers that build new types,
<br>elimination rules ensuring recursion/induction,
<br>definitional equality governing computation.
<br><br>The primitive judgements are<br><br>A context <br><br>lists typed variables in order; each  may depend on the preceding .  Context extension and weakening are governed by structural rules:<br>
<br>Empty context .  
<br>Extension  


<br><br>MLTT is generated by a minimal set of primitive type constructors; all others are encoded via inductive definitions.<br><br>Each constructor comes with introduction, elimination, and computation (β/η) rules. For instance, -reduction for :<br><br><br>The well-founded (W) type captures all strictly positive inductive definitions.<br>Formation<br><br>Intuitively, a term of  is a tree whose nodes are labelled by  and whose immediate sub-trees are indexed by elements of .<br>Introduction<br><br>Elimination (structural recursion)<br>
Given a motive  <br><br>and a handler  <br><br>one obtains  <br><br>with -rule  <br><br>All strictly positive inductive types in Coq/Agda—lists, trees, vectors, finite sets—are definable as suitable -types; their eliminators are derived instances of .<br><br>For any strictly positive polynomial endofunctor , the type<br><br>with  induces an algebra .   The eliminator  realises the unique morphism to any other -algebra, proving initiality. Therefore structural recursion<br><br>is not ad-hoc code but the unique catamorphism demanded by category theory.<br>MLTT, with W-types, universes, and strict positivity, thus supplies the precise metalogic in which structural recursion is both definable and semantically justified.  Every recursive program extracted from such a theory comes with a machine-checkable proof of termination and a categorical guarantee of uniqueness.<br><br><br>Structural recursion is most elegantly captured by the initial-algebra semantics of inductive data. Fix a cartesian closed category  that is locally finitely presentable (for programming languages one usually takes  or a presheaf topos).<br><br>Inductive data and their -algebras live inside the mathematical setting of category theory.<br>
Before we speak of algebras, limits, or functors we must fix the foundational vocabulary.<br><br>A category  consists of<br>
<br>
a class  of objects ,

<br>
for each ordered pair  a set  of morphisms (or arrows) ,

<br>
a binary operation composition


<br>
and for every object  an identity morphism<br>
,

<br>subject to the axioms<br>
<br>Associativity  whenever the<br>
compositions are defined.
<br>Unit laws  for all .
<br>Many categories encountered in computer science are locally small: each hom-set<br>
 is an actual (not proper-class-sized) set.<br><br><br>Throughout, we write  for a singleton set,  for the empty set, and ,  for categorical product and coproduct whenever they exist.<br><br>
<br>A terminal object  is one with a unique arrow  from every .
<br>Dually an initial object  has a unique arrow  into every object.
<br>A binary product of  is an object  equipped with projections  satisfying the universal property<br>

<br>A binary coproduct  dually satisfies the universal property on maps<br>
out of  and .
<br>These notions generalise ordered pairs and tagged unions; they are crucial because polynomial functors  are constructed from products and coproducts.<br><br>A category is cartesian closed if it has<br>
<br>
all finite products (including a terminal object), and

<br>
for every  an exponential object  with evaluation<br>
morphism <br>
satisfying the currying isomorphism


<br>, , and the category of Cartesian closed categories themselves are CCCs. Typed -calculus is sound and complete for CCCs; this underpins the Curry–Howard correspondence between simply typed programs and proofs.<br><br>An object  is finitely presentable if  preserves directed colimits.  is locally finitely presentable (lfp) if<br>
<br>it is cocomplete, and
<br>every object is a directed colimit of finitely presentable ones.
<br>Polynomial endofunctors on an lfp category admit initial algebras, ensuring inductive types exist in settings more general than —e.g. presheaf categories modelling syntax with binding.<br><br>Structural recursion is ultimately defined with respect to endofunctors, so we need a precise and self-contained treatment of functors at large, their algebraic laws, and the special case where the source and target category coincide.<br><br>A (covariant) functor between categories  <br><br>is a structure-preserving map consisting of two components  <br>
<br>object function   
<br>arrow function: for every pair of objects   a function on hom-sets<br>
It's subject to the functorial laws  
<br><br>for all composable arrows  <br><br><br>A contravariant functor  <br><br>reverses arrows: it maps  to  while still preserving identities and (now reversed) composition.  <br>For brevity all subsequent references to “functor’’ will be covariant unless explicitly marked.<br><br>
<br>The identity functor  acts as  on objects and arrows.  
<br>If  and , their composition  is defined point-wise.  
<br>Identity and composition make functors themselves into the objects of a category , whose arrows are natural transformations.
<br><br>An endofunctor is a functor whose domain and codomain coincide:  <br><br>Denote by  the category whose objects are endofunctors  and whose arrows are natural transformations  <br><br>
<br>Identity endofunctor  is initial and terminal in .  
<br>Monoidal structure.  Composition of endofunctors  

makes  a strict monoidal category with unit . This monoidal viewpoint is essential when speaking of monads and comonads (which are monoids and comonoids in ).
<br><br>Let  be a category with finite products and coproducts. A polynomial endofunctor has the shape  <br><br>where each  is an object of  (often a parameter) and . Polynomial functors are finitary (they preserve filtered colimits) and covariant by construction. Every strictly positive algebraic data type in programming corresponds to an initial algebra of some polynomial endofunctor.<br><br>An inductive type is specified by a polynomial endofunctor<br><br>built from constants, coproducts, products, and the identity functor, but never the contravariant hom functor. For a single-sorted datatype the general form is<br><br>where the -th summand corresponds to one constructor,  is a parameter object, and  is the number of recursive positions in that constructor. Strict positivity of the original syntax translates to the requirement that  is covariant in .<br><br>An -algebra is a pair  consisting of an object  of  and a structure morphism<br><br>A morphism between two -algebras  and  is an arrow  in  such that<br><br>Thus -algebras and their homomorphisms form a category .<br><br>An -algebra  is initial if for every other -algebra  there exists a unique homomorphism<br><br>Initiality endows  with two fundamental properties:<br>
<br>Recursion (existence).<br>
The morphism  is the structurally recursive function whose clauses are encoded in .
<br>Uniqueness.<br>
Any two arrows from  to  that respect  are equal, giving a canonical semantics to recursive definitions.
<br>A classical theorem due to Lambek states that  is an isomorphism, hence  is, up to isomorphism, the fixed point of  that is least with respect to the subobject ordering.<br><br>For a given  the unique homomorphism is written<br><br>It satisfies the fold equation<br><br>This equation unpacks to exactly one rewriting rule per constructor in the original inductive specification and is the categorical heart of structural recursion.<br><br>If  is any morphism with<br><br>then by initiality <br>Hence every function defined by case analysis must obey the fold equation, preventing ambiguous or ill-founded recursive clauses.]]></description><link>appendix-iii.html</link><guid isPermaLink="false">Appendix-III.md</guid><pubDate>Sat, 14 Jun 2025 16:53:28 GMT</pubDate></item><item><title><![CDATA[Appendix-IV]]></title><description><![CDATA[ 
 <br><br><br>A ring  is a set equipped with two operations, addition and multiplication, that satisfy familiar algebraic axioms.  Under addition,  becomes an abelian group with identity ; under multiplication, it is an associative monoid with identity ; and multiplication distributes over addition.  Though the integers  and polynomial rings  are the classical examples, rings arise in many contexts: as endomorphism algebras of abelian groups, coordinate rings of geometric varieties, or quotients  by ideals .  <br>Mathematically, a ring is a tuple  satisfying the following axioms:<br>
<br>
Additive group<br>
 is an abelian group:

<br>Closure: for all , .
<br>Associativity: .
<br>Identity: there exists  such that  for all .
<br>Inverse: for each  there is  with .
<br>Commutativity: .


<br>
Multiplicative monoid<br>
 is a monoid:

<br>Closure: for all , .
<br>Associativity: .
<br>Identity: there exists  such that  for all .


<br>
Distributivity<br>
Multiplication distributes over addition:

 for all .

<br>A ring satisfying all of the above is called a unital ring or ring with unity.  If one omits the requirement of a multiplicative identity , one obtains a rng (pronounced “rung”).<br><br>An ideal  is an additive subgroup satisfying  and  for every .  Given an ideal , one forms the quotient ring , whose elements are cosets  and whose operations are defined by  <br><br>The First Isomorphism Theorem asserts that any surjective ring homomorphism  with kernel  induces an isomorphism .  Two special classes of ideals play a central role: a maximal ideal  produces a field , while a prime ideal  yields an integral domain .  In particular, the ideal  is prime—and maximal—whenever  is a prime integer, giving rise to the finite field .<br><br>When  is any positive integer, the quotient ring  captures arithmetic modulo .  The Chinese Remainder Theorem states that if  <br><br>is the prime‐power factorization of , then there is an isomorphism of rings  <br><br>Within , the subgroup of units  <br><br>forms a finite abelian group of order Euler’s totient function .  By the Structure Theorem for finite abelian groups,  decomposes as a product of cyclic factors, a fact that underlies many algorithms in computational number theory.<br><br>When  is prime, the ring  is not only an integral domain but a field, commonly denoted .  In , the map  <br><br>is the Frobenius endomorphism, which in fact acts as the identity on  itself.  From the group‐theoretic perspective, the multiplicative group  has order , and Lagrange’s theorem immediately implies that for any ,  <br><br>Rewriting this congruence in terms of integers yields the celebrated Fermat’s Little Theorem.<br><br>Fermat’s Little Theorem states that for any integer ,  <br><br>If in addition , one may cancel  to obtain  <br><br>This confirms that every nonzero residue class modulo  has order dividing .  To measure how far the congruence  fails when lifted to mod , one defines the Fermat quotient  <br><br>Although  vanishes modulo , it need not vanish mod , and  records this discrepancy.  One finds striking congruences such as  <br><br>and primes  for which —the Wieferich primes—have deep connections to unsolved problems in Diophantine analysis.<br><br>When a Fermat number  <br><br>is prime (so far known only for ), the ring  is a field of order .  Since , this field contains a cyclic subgroup of roots of unity of order exactly .  Choosing a primitive root  of order , one defines the Fermat Number Transform (FNT) of length  (with ) by<br><br>Here  are the input samples and  the transform coefficients.  The inverse transform uses :<br><br>where  is the multiplicative inverse of  mod .<br>This construction mirrors the complex‐valued Discrete Fourier Transform but avoids round‐off errors by working entirely in a finite field.  It supports fast “butterfly” algorithms in  time whenever  is a power of two dividing .  In particular, convolution of two length- sequences  can be carried out by<br>
<br>computing their FNTs ,
<br>pointwise multiplying ,
<br>applying the inverse FNT to .
<br>Since Fermat primes grow doubly exponentially, practical implementations use the smallest  that accommodates the needed transform length.  For example, with  one can perform convolutions of length up to  without wraparound, making the Fermat Number Transform a powerful tool in exact integer arithmetic and applications such as large‐integer multiplication and error‐free signal processing.]]></description><link>appendix-iv.html</link><guid isPermaLink="false">Appendix-IV.md</guid><pubDate>Thu, 12 Jun 2025 21:17:15 GMT</pubDate></item><item><title><![CDATA[Appendix-V]]></title><description><![CDATA[ 
 <br>An analytic–combinatorial sampler<br>We start by encoding discrete objects with generating functions, then turn to the Riemann zeta function and Bernoulli numbers to see how the same algebraic and analytic ideas resurface in number theory.<br><br>A generating function encodes a sequence  as a formal power series.  The most common variant is the ordinary generating function (OGF)  <br><br>viewed initially as an algebraic object in the ring  of formal power series over a field .  One also encounters the exponential generating function (EGF)  <br><br>which is natural when  counts labeled combinatorial objects.  In either case, operations on sequences—termwise addition, Cauchy (convolution) product, shifts—translate into algebraic operations on their generating functions:<br>
<br>Addition:   
<br>Convolution:   
<br>Shift: 
<br>When treated analytically, one studies the radius of convergence  of  via the Cauchy–Hadamard formula  <br><br>and uses analytic continuation and singularity analysis to extract asymptotics of .<br>A powerful use of OGFs is to solve linear recurrences with constant coefficients.  For example, if  <br><br>then multiplying by  and summing gives a rational generating function  <br><br>Partial‐fraction expansion then yields a closed‐form for .  More generally, combinatorial specifications (unions, products, sequences, sets, cycles) translate into functional equations for EGFs or OGFs which one solves to enumerate complex structures.<br>In analytic combinatorics, one studies the singularities of : if  has a simple pole at , then  <br><br>for some constant .  If  has a branch‐point singularity of the form  <br><br>near , then  <br><br>For example, the Catalan numbers satisfy  <br><br>which has a square‐root singularity at , yielding  <br><br>Through these algebraic and analytic lenses, generating functions become a unifying tool for solving recurrences, performing combinatorial enumeration, and deriving precise asymptotic estimates.  <br><br>For , the Riemann zeta function is defined by the absolutely convergent Dirichlet series  <br><br>the latter identity known as the Euler product, which encodes the fundamental theorem of arithmetic.  To extend  to a meromorphic function on the whole complex plane, one uses the relation with the Dirichlet eta function  <br><br>which converges for  and hence provides an analytic continuation of  to  apart from the simple pole at  with residue .  A more symmetric extension comes from the Mellin transform of the Jacobi theta function, leading to the completed zeta  <br><br>which is an entire function satisfying the functional equation  <br><br>This symmetry about the critical line  underlies much of the deep structure of .<br>The trivial zeros of  occur at the negative even integers  arising from the poles of  in the functional equation.  The nontrivial zeros lie in the critical strip , and the celebrated Riemann Hypothesis asserts that all of them in fact satisfy .  The distribution of these zeros governs the fine‐scale fluctuations of the prime‐counting function .  Through the explicit formula one writes, for a smooth test function  with compact support on ,  <br><br>where the sum over  runs over nontrivial zeros of  and  is a Mellin‐type transform of .  In particular, one obtains the Prime Number Theorem in the form  <br><br>where  and the error term is tightly controlled by the location of the zeros.  <br><br>The Bernoulli numbers  form a sequence of rational numbers defined by the exponential generating function  <br><br>From this definition one derives the recursive relation  <br><br>which, coupled with , determines all .  A remarkable consequence is that  for all , while the even‐indexed Bernoulli numbers alternate in sign:  <br><br>Their denominators satisfy the von Staudt–Clausen theorem: for  the fractional part of  is  <br><br>where the sum runs over primes  with .  Analytically, Bernoulli numbers encode special values of the Riemann zeta function via  <br><br>linking them to deep properties of  at negative integers.<br>Beyond the primary generating function, the Bernoulli polynomials  arise from  <br><br>with .  A celebrated application is Faulhaber’s formula for power sums: for integer ,  <br><br>In numerical analysis, Bernoulli numbers appear in the Euler–Maclaurin summation formula, which bridges sums and integrals: for smooth ,  <br><br>where  is a remainder term involving .  Through these roles—in zeta‐function theory, polynomial sums, and asymptotic analysis—Bernoulli numbers stand as a central pillar in classical and modern mathematics.  ]]></description><link>appendix-v.html</link><guid isPermaLink="false">Appendix-V.md</guid><pubDate>Mon, 16 Jun 2025 13:32:13 GMT</pubDate></item><item><title><![CDATA[Appendix-VI]]></title><description><![CDATA[ 
 <br><br><br><br>
<br>
Monte Carlo algorithm.<br>
A randomized algorithm that runs in bounded time but may return an incorrect result.  

<br>Error probability: for input ,<br>
  
<br>Amplification: By independent repetition and majority vote, one can reduce  exponentially.<br>
If each run errs with prob.\ , then after  runs the error is<br>
  


<br>
Las Vegas algorithm.<br>
Always returns the correct answer, but its running time is a random variable .  

<br>One measures , or high-probability bounds like .  
<br>You can often convert between Las Vegas and Monte Carlo via time-outs and restart.


<br><br>
<br>Additive vs. Multiplicative Error.<br>
For an optimization problem with optimum value  and algorithm’s output :  

<br>Additive error :  


<br>  <br>
<br>Multiplicative error :  
<br><br>
<br>
-approximation.<br>
Typically means a polynomial-time algorithm producing  with<br>
 for minimization (or<br>
 for maximization).

<br>
Fully Polynomial Time Approximation Scheme (FPTAS).<br>
An algorithm that, given , runs in time  and achieves a -approximation.

<br>
Fully Polynomial Randomized Approximation Scheme (FPRAS).<br>
A randomized algorithm which, with probability at least  (or any constant ), computes a -approximation in time . Error probability can be amplified to  by repeating  times.

<br><br><br>
<br>
Machine epsilon : the smallest positive floating-point number such that  

<br>


<br>
Rounding model.<br>
For any real  and exact arithmetic operation ,<br>


<br><br>
<br>
Absolute error.<br>
If  approximates , then<br>


<br>
Relative error.<br>
when .

<br><br>
<br>
Forward error of algorithm  on input :<br>


<br>
Backward error.<br>
The smallest perturbation  such that . Formally,<br>


<br>An algorithm is backward stable if<br>
<br><br>
<br>
Condition number  of a problem :<br>


<br>
Forward/Backward error relation.<br>
For a backward-stable algorithm,<br>


<br><br>
<br>
Summation (pairwise).<br>
Adding  numbers  in floating-point via the standard linear scan incurs a relative error bounded by<br>


<br>
Kahan’s compensated summation.<br>
A simple technique that reduces error to<br>
i.e. essentially independent of .

<br><br>To describe how errors behave as problem parameters grow (e.g.\ input size , condition number , step size , etc.), we use Landau (big-O) and related notations. These allow us to suppress lower-order terms and focus on the dominant scaling of an error term.<br><br><br><br><br>Algorithms turn inputs of length  into running-time or space figures—functions  that grow without bound.<br>
To compare those growth rates while ignoring the distraction of machine-dependent constants, we wrap them in asymptotic notation.<br>A function  is said to be big-O of , written , if there exist constants  and  such that  <br><br><br><br>and if the ratio stays trapped between two positive constants then .<br>Consequences: <br>
<br>Constant factors vanish. Multiplying  by any fixed  leaves the class unchanged; hence hardware speedups do not alter an algorithm’s order.
<br>Addition is ruled by the larger term. If  and  then .
<br>Bases of logarithms are irrelevant. Since , every  differs from  by just a constant factor.
<br>These notations also apply as  in numerical methods, e.g.<br><br><br>When expanding a smooth function  around , we write<br><br>Here the “” term indicates that the remainder is bounded by a constant times  for  near .<br><br>When errors are random variables , we refine Landau notation to capture probabilistic behavior:<br>
<br>
In probability (, ).  


Example: the sampling error in Monte Carlo integration satisfies<br>
, meaning it is on the order of  in probability.

<br>
With high probability (w.h.p.).<br>
A sequence of events  holds with high probability if<br>
.<br>
We may say “error  w.h.p.” to mean the bound holds with probability tending to 1.

<br>
Almost sure ( a.s.).  


<br><br>For expectations or higher moments of an error random variable :<br><br>This “in mean” notation is common when analyzing bias and variance trade-offs.]]></description><link>appendix-vi.html</link><guid isPermaLink="false">Appendix-VI.md</guid><pubDate>Fri, 20 Jun 2025 09:26:44 GMT</pubDate></item><item><title><![CDATA[Appendix-VII]]></title><description><![CDATA[ 
 <br><br><br>def american_flag_sort(a, base=10):
    if len(a) &lt;= 1:
        return a
    off = min(a)
    if off &lt; 0:
        for i in range(len(a)):
            a[i] -= off
    m = max(a)
    exp = 1
    while m // exp &gt;= base:
        exp *= base
    def sort(lo, hi, exp):
        if hi - lo &lt;= 1 or exp == 0:
            return
        cnt = [0] * base
        for i in range(lo, hi):
            cnt[(a[i] // exp) % base] += 1
        pos = [lo]
        for c in cnt[:-1]:
            pos.append(pos[-1] + c)
        nxt = pos[:]
        i = lo
        while i &lt; hi:
            d = (a[i] // exp) % base
            if pos[d] &lt;= i &lt; nxt[d]:
                i += 1
            else:
                j = nxt[d]
                a[i], a[j] = a[j], a[i]
                nxt[d] += 1
        for b in range(base):
            s = pos[b]
            e = pos[b + 1] if b + 1 &lt; base else hi
            sort(s, e, exp // base)
    sort(0, len(a), exp)
    if off &lt; 0:
        for i in range(len(a)):
            a[i] += off
    return a
<br><br>def bead_sort(arr):
    if not arr:
        return arr
    max_beads = max(arr)
    beads = [[0]*max_beads for _ in arr]
    for i, num in enumerate(arr):
        beads[i][:num] = [1]*num
    for j in range(max_beads):
        sum_beads = 0
        for i in range(len(arr)):
            sum_beads += beads[i][j]
            beads[i][j] = 0
        for i in range(len(arr)-sum_beads, len(arr)):
            beads[i][j] = 1
    result = [row.count(1) for row in beads]
    return result
<br><br>def binary_insertion_sort(arr):
    for i in range(1, len(arr)):
        key = arr[i]
        lo, hi = 0, i
        while lo &lt; hi:
            mid = (lo + hi)//2
            if arr[mid] &lt; key:
                lo = mid + 1
            else:
                hi = mid
        for j in range(i, lo, -1):
            arr[j] = arr[j-1]
        arr[lo] = key
    return arr
<br><br>def bitonic_sort(arr, up=True):
    def bitonic_merge(a, low, cnt, direction):
        if cnt &gt; 1:
            k = cnt // 2
            for i in range(low, low+k):
                if (direction == (a[i] &gt; a[i+k])):
                    a[i], a[i+k] = a[i+k], a[i]
            bitonic_merge(a, low, k, direction)
            bitonic_merge(a, low+k, k, direction)

    def sort(a, low, cnt, direction):
        if cnt &gt; 1:
            k = cnt // 2
            sort(a, low, k, True)
            sort(a, low+k, k, False)
            bitonic_merge(a, low, cnt, direction)

    n = 1
    while n &lt; len(arr):
        n &lt;&lt;= 1
    arr.extend([float('inf')] * (n - len(arr)))
    sort(arr, 0, n, up)
    while float('inf') in arr:
        arr.remove(float('inf'))
    return arr
<br><br>import math, heapq

def block_sort(a, block_size=None):
    n=len(a)
    if n&lt;2:
        return
    if not block_size or block_size&lt;1:
        block_size=max(1,math.isqrt(n))
    blocks=[a[i:i+block_size] for i in range(0,n,block_size)]
    for b in blocks:
        b.sort()
    h=[(b[0],i,0) for i,b in enumerate(blocks)]
    heapq.heapify(h)
    p=0
    while h:
        v,bi,idx=heapq.heappop(h)
        a[p]=v
        p+=1
        idx+=1
        if idx&lt;len(blocks[bi]):
            heapq.heappush(h,(blocks[bi][idx],bi,idx))
<br><br>def bogo_sort(arr):
    import random
    while any(arr[i] &gt; arr[i+1] for i in range(len(arr)-1)):
        random.shuffle(arr)
    return arr
<br><br>def bozo_sort(arr):
    import random
    while any(arr[i] &gt; arr[i+1] for i in range(len(arr)-1)):
        i, j = random.sample(range(len(arr)), 2)
        arr[i], arr[j] = arr[j], arr[i]
    return arr
<br><br>def bubble_sort(arr):
    n=len(arr)
    for i in range(n):
        for j in range(0,n-i-1):
            if arr[j]&gt;arr[j+1]:
                arr[j],arr[j+1]=arr[j+1],arr[j]
    return arr
<br><br>def bucket_sort(arr):
    if not arr:
        return arr
    bucket_count=len(arr)
    min_val,max_val=min(arr),max(arr)
    buckets=[[] for _ in range(bucket_count)]
    for num in arr:
        idx=int((num-min_val)/(max_val-min_val+1e-9)* (bucket_count-1))
        buckets[idx].append(num)
    res=[]
    for b in buckets:
        res.extend(sorted(b))
    return res
<br><br>def merge_sort(a):
    if len(a) &lt;= 1:
        return a
    m = len(a) // 2
    l = merge_sort(a[:m])
    r = merge_sort(a[m:])
    i = j = 0
    o = []
    while i &lt; len(l) and j &lt; len(r):
        if l[i] &lt;= r[j]:
            o.append(l[i])
            i += 1
        else:
            o.append(r[j])
            j += 1
    o.extend(l[i:])
    o.extend(r[j:])
    return o
<br><br>class _T(dict):
    __slots__ = ("b",)

    def __init__(self):
        super().__init__()
        self.b = []


def burst_sort(s, t=32):
    r = _T()
    for w in s:
        n = r
        i = 0
        while True:
            if i == len(w):
                n.b.append(w)
                break
            c = w[i]
            nxt = n.get(c)
            if nxt is None:
                n[c] = _T()
                n[c].b.append(w)
                break
            if len(nxt.b) &lt; t:
                nxt.b.append(w)
                break
            n = nxt
            i += 1
    o = []

    def collect(nd):
        nd.b.sort()
        o.extend(nd.b)
        for k in sorted(nd):
            collect(nd[k])

    collect(r)
    return o
<br><br>def cocktail_shaker_sort(arr):
    n=len(arr)
    start=0
    end=n-1
    swapped=True
    while swapped:
        swapped=False
        for i in range(start,end):
            if arr[i]&gt;arr[i+1]:
                arr[i],arr[i+1]=arr[i+1],arr[i]
                swapped=True
        if not swapped:
            break
        swapped=False
        end-=1
        for i in range(end-1,start-1,-1):
            if arr[i]&gt;arr[i+1]:
                arr[i],arr[i+1]=arr[i+1],arr[i]
                swapped=True
        start+=1
    return arr

<br><br>def comb_sort(arr):
    gap=len(arr)
    shrink=1.3
    sorted_flag=False
    while not sorted_flag:
        gap=int(gap/shrink)
        if gap&lt;=1:
            gap=1
            sorted_flag=True
        i=0
        while i+gap &lt; len(arr):
            if arr[i]&gt;arr[i+gap]:
                arr[i],arr[i+gap]=arr[i+gap],arr[i]
                sorted_flag=False
            i+=1
    return arr

<br><br>def counting_sort(arr):
    if not arr:
        return arr
    min_val,max_val=min(arr),max(arr)
    count=[0]*(max_val-min_val+1)
    for num in arr:
        count[num-min_val]+=1
    idx=0
    for i,c in enumerate(count):
        while c&gt;0:
            arr[idx]=i+min_val
            idx+=1
            c-=1
    return arr

<br><br>def cycle_sort(arr):
    n = len(arr)
    for cycle_start in range(0, n - 1):
        item = arr[cycle_start]
        pos = cycle_start
        for i in range(cycle_start + 1, n):
            if arr[i] &lt; item:
                pos += 1

        if pos == cycle_start: 
            continue
        while item == arr[pos]:
            pos += 1
        arr[pos], item = item, arr[pos]
        while pos != cycle_start:
            pos = cycle_start
            for i in range(cycle_start + 1, n):
                if arr[i] &lt; item:
                    pos += 1
            while item == arr[pos]:
                pos += 1
            arr[pos], item = item, arr[pos]
    return arr
<br><br>def dual_pivot_quick_sort(arr):
    def sort(a,l,r):
        if l&gt;=r:
            return
        if a[l]&gt;a[r]:
            a[l],a[r]=a[r],a[l]
        p,q=a[l],a[r]
        i=l+1
        lt=l+1
        gt=r-1
        while i&lt;=gt:
            if a[i]&lt;p:
                a[i],a[lt]=a[lt],a[i]
                lt+=1
            elif a[i]&gt;q:
                while a[gt]&gt;q and i&lt;gt:
                    gt-=1
                a[i],a[gt]=a[gt],a[i]
                gt-=1
                if a[i]&lt;p:
                    a[i],a[lt]=a[lt],a[i]
                    lt+=1
            i+=1
        lt-=1
        gt+=1
        a[l],a[lt]=a[lt],a[l]
        a[r],a[gt]=a[gt],a[r]
        sort(a,l,lt-1)
        sort(a,lt+1,gt-1)
        sort(a,gt+1,r)
    sort(arr,0,len(arr)-1)
    return arr
<br><br>def flash_sort(arr):
    n = len(arr)
    if n &lt;= 1:
        return arr

    m = int(0.43 * n) + 1  
    min_val, max_val = min(arr), max(arr)
    if min_val == max_val:
        return arr
    c = (m - 1) / (max_val - min_val)
    L = [0] * m
    for x in arr:
        L[int(c * (x - min_val))] += 1
    for i in range(1, m):
        L[i] += L[i - 1]
    moves = 0
    j = 0
    k = m - 1
    while moves &lt; n:
        while j &gt;= L[k]:
            j += 1
            if j &gt;= n:
                break
            k = int(c * (arr[j] - min_val))
        flash = arr[j]
        while j &lt; L[k]:
            k = int(c * (flash - min_val))
            dest = L[k] - 1
            arr[dest], flash = flash, arr[dest]
            L[k] -= 1
            moves += 1
    for i in range(1, n):
        key = arr[i]
        j = i - 1
        while j &gt;= 0 and arr[j] &gt; key:
            arr[j + 1] = arr[j]
            j -= 1
        arr[j + 1] = key

    return arr
<br><br>def gnome_sort(arr):
    i=0
    while i&lt;len(arr):
        if i==0 or arr[i]&gt;=arr[i-1]:
            i+=1
        else:
            arr[i],arr[i-1]=arr[i-1],arr[i]
            i-=1
    return arr
<br><br>def heap_sort(arr):
    import heapq
    h = arr[:]
    heapq.heapify(h) 
    return [heapq.heappop(h) for _ in range(len(h))]
<br><br>def in_place_merge_sort(arr):
    def merge(a, l, m, r):
        start2 = m + 1
        if a[m] &lt;= a[start2]:
            return
        while l &lt;= m and start2 &lt;= r:
            if a[l] &lt;= a[start2]:
                l += 1
            else:
                value = a[start2]
                idx = start2
                while idx != l:
                    a[idx] = a[idx - 1]
                    idx -= 1
                a[l] = value
                l += 1
                m += 1
                start2 += 1

    def sort(a, l, r):
        if l &lt; r:
            m = (l + r) // 2
            sort(a, l, m)
            sort(a, m + 1, r)
            merge(a, l, m, r)

    sort(arr, 0, len(arr) - 1)
    return arr
]]></description><link>appendix-vii.html</link><guid isPermaLink="false">Appendix-VII.md</guid><pubDate>Fri, 20 Jun 2025 11:26:08 GMT</pubDate></item><item><title><![CDATA[CH01-Complexity]]></title><description><![CDATA[ 
 <br><br>The symbol “” predates computer science.  <br>In the late 19ᵗʰ century analytic number theorists—most notably Paul Bachmann and Edmund Landau—used it to bound error terms in formulas such as<br><br>where  meant “some constant multiple of  as .”  <br>By discarding constants, they could study the shape of growth without clutter.<br>When programmable computers arrived in the 1940s, engineers needed a machine-agnostic way to compare programs.  Counting raw instructions was too hardware-specific; Landau’s notation, already familiar to mathematicians, fit perfectly because it emphasized the dominant term and ignored clock speeds, word sizes, and compilers.<br>Donald Knuth’s 1968 Art of Computer Programming made Big-O standard in algorithm analysis.  <br>Knuth counted a primitive operation—say, a comparison—then expressed the total in Big-O form:<br><br>cleanly revealing that mergesort beats quadratic algorithms.<br>As complexity theory emerged, Hartmanis and Stearns (1965) measured time and space on Turing machines.  Big-O migrated intact: “” now bounded the number of state transitions rather than values of .  This led to machine-independent classes such as<br>
<br> (log-space)  
<br> (polynomial time)
<br>and ultimately to questions like .<br>Hiding constants is pragmatic—clock rates vary—yet sometimes dangerous: two “linear-time” programs can differ by 1000 ×.  Modern practice balances asymptotic clarity with empirical timing and, where necessary, refined notations such as  (suppressing poly-log factors) or explicit leading constants.<br>Despite its Victorian origin, Big-O endures because it makes performance portable: quadratic time on one reasonable model is quadratic on any other up to a constant factor.  That universality keeps Bachmann and Landau’s notation at the heart of both theoretical results and day-to-day engineering.<br><br>Algorithms turn inputs of length  into running-time or space figures—functions  that grow without bound.<br>
To compare those growth rates while ignoring the distraction of machine-dependent constants, we wrap them in asymptotic notation.<br>A function  is said to be big-O of , written , if there exist constants  and  such that  <br><br><br><br>and if the ratio stays trapped between two positive constants then .<br>Consequences: <br>
<br>Constant factors vanish. Multiplying  by any fixed  leaves the class unchanged; hence hardware speedups do not alter an algorithm’s order.
<br>Addition is ruled by the larger term. If  and  then .
<br>Bases of logarithms are irrelevant. Since , every  differs from  by just a constant factor.
<br><br>Let  denote the number of key-comparisons performed when merge-sorting an<br>
array of length .<br>
<br>Divide – splitting into two halves costs only .  
<br>Conquer – recursively sort each half, contributing .  
<br>Combine – merging the two sorted halves makes at most  comparisons,<br>
i.e. .
<br>function mergeSort(arr)
    if size of arr ≤ 1
        return arr
    split arr into two halves: left and right
    leftSorted = mergeSort(left)
    rightSorted = mergeSort(right)
    return merge(leftSorted, rightSorted)

function merge(left, right)
    result = empty list
    while both left and right are not empty
        if first element of left &lt; first element of right
            move first element of left to result
        else
            move first element of right to result
    add any remaining elements from left to result
    add any remaining elements from right to result
    return result
<br>Hence  <br><br>A recursion-tree analysis shows every level costs  comparisons:<br><br>There are  levels, so  <br><br>If merging took  comparisons for a constant , every row of the tree would cost  and the total would be —still inside .  <br><br>Time hierarchy: If  is constructible and  then  <br><br>Space hierarchy: Similarly, if  and  is space-constructible,  <br><br>The phrase “hierarchy theorem’’ first appears in Hartmanis &amp; Stearns’ 1965 paper On the Computational Complexity of Algorithms.  They asked a deceptively simple question: if a Turing machine is allowed more of some resource—say, time—does it necessarily gain power?  Power in this case meaning  the set of languages (decision problems) a Turing-machine model can decide.  Equivalently, it is the collection of partial functions it can compute or the yes/no questions it can always answer correctly.<br>The answer is “yes’’ for every reasonable resource, but the proof is not automatic; it hinges on two ideas:<br>
<br>Diagonalisation, <a class="internal-link" data-href="Appendix-I" href="appendix-i.html" target="_self" rel="noopener nofollow">Cantor’s trick</a> adapted to machines.  
<br>Constructibility, a promise that the bound we impose can itself be met.
<br><br>A function  is time-constructible if the mapping  can be computed in strictly less than  steps on some Turing machine.  Intuitively the machine can “count up’’ to its own limit and then halt; typical examples are , , , .  <br>We need constructibility because diagonalisation keeps a table of all machines that obey the lower bound—if  itself were uncomputable, the table could not be laid out in time.<br>There is an analogous notion of space-constructible: write  in binary using at most  tape cells, then halt.<br><br>Let  be time-constructible. We create a machine  that, on input string  of length , does the following:<br>
<br>Interpret  as the Gödel number of some Turing machine .  
<br>Simulate  on  for at most  steps.<br>
If the simulation halts within that budget, do the opposite:<br>
accept if  rejects, reject if  accepts.  
<br>If the simulation overruns the budget, simply accept.
<br>The simulation overhead is one step per simulated step plus bookkeeping to<br>
decrease a counter from  to .  That counter can be maintained in<br><br>time per real step, because each decrement touches only  bits.<br>Thus the total running time of  is bounded by<br><br>Call that new bound .<br>
By construction,  disagrees with every machine that halts within  steps, so the language<br><br>lives outside  but inside .<br>
This yields the classic time hierarchy theorem:<br>
If  and both are time-constructible,<br>

<br>Notice the sneaky  overhead.  It cannot be avoided for single-tape machines, but on multitape models a tighter simulation shaves it off, giving<br><br><br>Space is kinder.  <br>A simulator can reuse its work tape by overwriting, so counting the remaining<br>
budget costs only constant extra space. Consequently<br>
If  and both are space-constructible,<br>

<br>No  factor penalty appears.<br><br>
<br>They show each extra polynomial exponent gives more power:<br>

<br>They separate deterministic logarithmic-space from deterministic linear-space, legitimising the class .
<br>They do not settle  versus .<br>
Diagonalisation fails against nondeterminism because the universal<br>
simulation can hide an exponential blow-up inside those existential guesses.
<br>They leave room for speed-up and gap theorems:<br>
– for any  there is a problem whose best deterministic algorithm runs in  and no  time (Blum),<br>
– there are vast stretches of integers where  collapses (Borodin).
<br><br>Hartmanis–Stearns diagonalisation extends if we let the simulator flip answers after each alternation of existential and universal guesses.  The resulting infinite ladder<br><br>is called the polynomial hierarchy.  Nobody knows whether any of those inclusions collapse.  <br>If they did, whole swaths of modern cryptography would crumble.<br><br>Choosing the two clocks<br>
<br>Lower clock  . Any machine that halts in at most one sweep of its -cell input is considered “fast.”
<br>Higher clock . Our goal: a language inside this window but outside the lower one.
<br>Why the extra ? A single simulation step will cost us an unavoidable  factor (binary-counter maintenance) and we want slack for bookkeeping.<br><br>How we encode machines in binary<br>A Turing machine  is described by a finite table of quintuple entries  where .  <br>We write:<br>
<br> in unary, followed by 01 as a marker.  
<br>For each state  (in numerical order) and tape symbol  (also ordered) we append  

<br>the next-state number in unary + 0  
<br>the symbol to write (two bits for ) + 0  
<br>the move (00 for −1, 01 for 0, 11 for +1).  


<br>Finish with 00 to mark “no more transitions.”
<br>Because unary pieces dominate, the code length  is .   Crucially, this length is linear in the size of the table, letting us parse in one left-to-right scan.<br>A diagonaliser you could etch onto relay logic<br>Input: a binary word  of length .<br>
Output: accept / reject.<br>
<br>
Decode  as the machine .<br>
We never leave the first  cells: every symbol is read exactly once. Cost:  moves.

<br>
Prep a down-counter initialised to .<br>
The obvious place is after the input. We walk right, write the binary digits least-significant first, then return. Two full sweeps →  moves plus  to lay the digits.

<br>
Simulate  for at most  steps. Each simulated step entails:

<br>Copy symbol under head to a scratch cell (1 move).  
<br>Consult a pre-computed jump table (held in place right of the counter).<br>
We encode one line per state-symbol pair in fixed length so we can jump with a single multiplication-by-shift trick:<br>
.  
<br>Overwrite tape cell, move head, update state.  
<br>Decrement the binary counter.<br>
– read bit 0 (LSB); if 1 → flip to 0 and stop;<br>
– if 0 → flip to 1 and carry; continue.<br>
Worst case touches every bit →  moves.<br>
Average case touches two bits (half of all numbers are odd), but we book the worst to stay safe.

Grand total per simulated step:<br>
 tape moves for table look-ups +  for the counter.
After  steps the simulation has consumed<br>
 real moves.

<br>
Flip or accept.<br>
If the simulated  halted early, we invert its answer; otherwise we accept.<br>
Cost: negligible.

<br><br>Why no linear-time single-tape machine can match that answer<br>Assume, for contradiction, that some TM  recognises the same language and halts in  moves.<br>
Feed its own code  as input to .<br>
<br>The decoder recovers  correctly.  
<br>The simulator gives  exactly  steps, which is plenty.  
<br>Since  does halt in time,  flips the outcome.  
<br>So —contradiction.  <br>The only escape for  would be to overrun the budget, but then it is no longer “linear-time.”<br>A microscopic look at that binary counter<br>The binary decrement is where the  comes from:<br>... 1 0 0 0 0 tape-head here (LSB on left)  
flip -&gt; 0 (carry)  
^ move left  
flip -&gt; 1 (carry resolved)  
back to LSB cell
<br>Worst-case distance travelled: length of the counter = .  <br>On a two-tape machine the counter could sit in unary, one mark per tick; each decrement touches one cell, and the entire overhead collapses to .  <br>That physical fact—how many squares the head must cross—explains why the hierarchy theorem for multitape TMs needs no extra .]]></description><link>ch01-complexity.html</link><guid isPermaLink="false">CH01-Complexity.md</guid><pubDate>Fri, 18 Jul 2025 09:39:22 GMT</pubDate></item><item><title><![CDATA[CH02-Cost-Measures]]></title><description><![CDATA[ 
 <br>The idea of <a class="internal-link" data-href="CH01-Complexity.md" href="ch01-complexity.html" target="_self" rel="noopener nofollow">asymptotic notation</a> is assumed. <br><br><br>Definition (Random Access Machine (RAM))<br>
A RAM consists of:<br>
<br>Registers , each storing an arbitrary nonnegative integer.  
<br>Memory cells  of the same type.  
<br>A finite program of instructions:
<br>    LOAD   R_i &lt;- M[R_j]
    STORE  M[R_j] &lt;- R_i
    ADD    R_i &lt;- R_j + R_k
    SUB    R_i &lt;- max(R_j - R_k, 0)
    MUL    R_i &lt;- R_j * R_k
    DIV    R_i &lt;- floor(R_j / R_k)
    JZ, JNZ, JGT, …, HALT
<br>On input  (bit-encoded across ) the machine executes until HALT, outputting .<br>Let  denote the bit-length of the input, and for any register  at time  write<br><br>We also define for logarithmic and unit cost models respectively: <br><br><br>Definition (Unit-Cost)<br>
Every RAM instruction incurs cost , regardless of operand sizes.<br>Definition (Logarithmic-Cost)<br>
An instruction manipulating registers of bit-lengths  is charged<br><br>Definition (-Bit Word-RAM)<br>
Fix a parameter .  Registers and memory cells are arrays of words, each word storing an integer in .  Operations on single words (addition, bitwise Boolean, shifts, comparisons) cost .  Multiprecision operations on values spanning  words decompose into  or  word-operations depending on the algorithm used.<br><br>Theorem (Unit → Logarithmic)<br>
A program running in  steps under unit-cost, never storing values above , can be simulated in<br><br>steps under logarithmic-cost, where .<br>Proof.<br>
Consider an arbitrary step  of the original program.  At that step the unit-cost RAM performs one of the following:<br>
<br>An arithmetic operation (addition, subtraction, multiplication, or division) on two registers.  
<br>A comparison between two registers.  
<br>A memory read or write (possibly indirect) of a register value.  
<br>Under unit-cost these each take time .  Under logarithmic-cost, however, the cost depends on the bit-length of the operands and results:<br>
<br>Arithmetic operations on -bit words cost  time to execute.  
<br>Comparisons of two -bit words cost  time.  
<br>Memory access of a -bit word costs  time.  
<br>Since no value ever exceeds , the bit-length of every register at time  is at most<br><br>and hence .  Thus each simulated operation at step  requires only<br><br>time on the logarithmic-cost RAM.<br>Total cost.<br>
We perform  steps of simulation, each incurring an overhead of .  Therefore the total simulation time is<br><br>Recalling that , we conclude that<br><br>which completes the proof.<br>Theorem (Logarithmic → Unit)<br>
A program taking  time and using  registers under logarithmic-cost can be simulated in<br><br>unit-cost steps, where  bounds all bit-lengths encountered.<br>Proof.<br>
We represent each of the  registers of  explicitly as a contiguous block of  bits in the unit-cost RAM’s memory.  We maintain the invariant that bits beyond the current logical length of a register are set to 0.<br>Initial setup cost.<br>
At the start, we must zero out all  blocks of  bits.  Scanning through each bit takes one unit step, so initializing all registers costs<br><br>Simulating a single logarithmic-cost step.<br>
In the logarithmic-cost model, at time  each register has some bit-length , and an operation on two registers of lengths  costs .  To simulate such an operation in unit-cost memory, we perform the same bit-level algorithm (e.g., grade-school addition, bitwise AND/OR, shifts, etc.) on the two -bit blocks. Each bit-operation (read/write/XOR/etc.) costs 1, so the simulation of one logarithmic-step can be done in<br><br>unit steps.<br>However, if a given register does not change value on that step, we need not scan all its bits again.  Instead, we record which registers are actually read or written, do a bit-scan only for those, and leave the remaining blocks untouched.<br>Accounting via bit-flips.<br>
We now charge each time a bit in any register changes its value (from 0 to 1 or vice versa) exactly one unit step.  Then over the entire simulation of  logical steps, the total number of bit-flips is at most<br><br>But each arithmetic or logical operation alters only  bits of the registers it touches, so<br><br>On the other hand, if a register is merely read but not written, no bits change, so we do not incur any bit-scan for reads beyond checking a small length-field (bounded by  in unit cost).<br>Putting it all together.<br>
<br>Initialization:  steps to zero all bits.  
<br>Writes / bit-flips: at most  steps in total, over all  operations.  
<br>Reads without writes: only  per operation, i.e.,  overall.  
<br>Hence the grand total is<br><br>as claimed.<br><br><br>Definition (Deterministic Turing Machine)<br>
A deterministic Turing machine (DTM) is a tuple  <br><br>where  <br>
<br> is a finite set of states.  
<br> is a finite tape alphabet,  is the blank symbol.  
<br> is the input alphabet.  
<br> is the transition function<br>
(write a symbol, move the head left , stay , or right ).  
<br> are the initial, accepting, and rejecting states, with  and no outgoing transitions from either.
<br>The machine has an infinite tape, initially<br><br>(i.e. the input word  surrounded by blanks) and the single head starts on .<br>
A configuration is a triple : state , tape contents  of which only finitely many cells differ from , and head position .<br>Let an input  have length .<br>
For a computation of  on  define<br><br>For a function  we say  <br>
<br> runs in time  if  for all .  
<br> runs in space  if  for all .
<br>We extend to languages in the usual way:<br><br><br>Definition (Single-Tape Cost)<br>
In the single-tape model every state transition costs , regardless of the head movement.<br>
Time complexity is measured as , space as .<br>Definition (-Tape Cost)<br>
A -tape DTM has  semi-infinite work tapes, each with its own head.<br>
A transition  <br><br>reads the  symbols under the heads, writes  on tape , moves head  by , and costs .<br>
Time and space are defined as<br><br>Definition (Random-Access Turing Machine)<br>
A random-access Turing machine (RATM) augments the DTM with a<br>
binary address tape whose content is interpreted as a non-negative integer .<br>
Special instructions  <br><br>address tape movements cost  per position, while each random access (read/write) also costs .<br>
Thus time counts address moves plus RAM accesses; space counts the maximum index  ever addressed.<br>Random access renders the machine behaviorally close to a (logarithmic-word) RAM, yet its memory is still unbounded and one-dimensional.<br><br><br>Theorem (Multi-Tape  Single-Tape)<br>
A -tape DTM running in time  and space  can be simulated by a single-tape DTM in<br><br>Proof<br>
Fix the computation of  on the given input and write .  <br>During this computation no head ever ventures more than  positions to the right of its starting cell, so the useful part of every tape is contained in the first  columns.  To simulate  on one tape,  lays out those columns sequentially: column  stores the  symbols that appear in position  of the  work tapes, and the character under each head is distinguished by a special “marked’’ version.  <br>Columns are separated by a delimiter, giving a layout  <br><br>followed by blanks.  Because every column contains exactly  symbols plus one delimiter, the segment ever used by  is bounded by  cells.  This proves the claimed space bound.<br>To perform one step of , the simulator makes a left-to-right sweep over the occupied segment, thereby learning in its finite control (i) ’s current state and (ii) the  symbols that are currently marked.  Having reached the right end, it consults ’s transition function to decide the new state, the  symbols to write, and the  head moves.  A second sweep, now right-to-left, carries out those updates: each marked symbol is overwritten, the new mark is placed one column left, right, or at the same position, and a fresh blank column is created when a head moves onto unused tape.  Thus simulating one step of  costs two full sweeps over the at-most- columns that have been visited so far, requiring  cell visits when the original time is .<br>Summing over  to , the total running time of  is  <br><br>where the factor  is absorbed into the big- because  is a fixed constant of the machine model.  <br>Hence a -tape deterministic Turing machine running in time  and space  can indeed be simulated by a single-tape deterministic Turing machine that uses  space and  time.  <br><br>Theorem (Single-Tape  Two-Tape)<br>
A single-tape DTM running in time  and space  can be simulated by a two-tape DTM in<br><br>Proof<br>
Write  and .  <br>Tape 1 of  always contains the part of ’s tape to the left of the simulated head, in reverse order; tape 2 stores the current cell and everything to its right in the natural order.<br>
At any moment the two tape heads therefore face the symbols immediately adjacent to the simulated head: tape 1’s head scans the symbol just left of it, tape 2’s head the symbol currently under it.  This split is essentially the classical “two-stack’’ representation of an infinite tape.<br>Suppose  is in state  and sees the symbol  under its head, represented on tape 2.<br>
From  the transition function of  prescribes a new state , a symbol  to write, and a move .<br>
<br>Writing.<br>
 overwrites  on tape 2 by .  
<br>Head move.<br>
If  no further action is necessary.<br>
If  (move right)  copies the now-old  onto tape 1 (pushing it onto the left stack) and then moves the tape-2 head one cell right, creating a blank if none exists.<br>
If  (move left)  first moves the tape-1 head right to fetch the left-hand neighbour (blank if the stack is empty), copies that symbol onto tape 2 (thus making it the new current cell), and finally erases the fetched cell on tape 1 to realise the pop.  
<br>Each of the three cases involves  tape operations, so one step of  is simulated in  time.  Consequently  steps take  time in total.<br>Because at all times tape 1 holds exactly those squares originally to the left of ’s head and tape 2 holds the current and right-hand squares, the total number of non-blank symbols across both tapes never exceeds .  Thus the space consumption of  is .<br>Hence the two-tape machine  runs in linear time  while using only  tape squares, completing the proof. ]]></description><link>ch02-cost-measures.html</link><guid isPermaLink="false">CH02-Cost-Measures.md</guid><pubDate>Fri, 18 Jul 2025 09:39:06 GMT</pubDate></item><item><title><![CDATA[CH03-Recursion]]></title><description><![CDATA[ 
 <br><br>Primitive recursion sits at the bottom of the computability ladder.  <br>It captures all total functions that can be computed by a fixed-depth nest of for-loops whose bounds are values of earlier arguments.  <br>Everything is guaranteed to halt because the final argument decreases by one on every self-call.<br><br>For  let , start with two given functions  <br>
<br>base 
<br>step 
<br>Primitive recursion produces a new function <br><br>by the clauses  <br><br>where .  <br>Because the second clause applies only to a strictly smaller , repeated expansion eventually reaches the base clause at .  <br>Hence every primitive-recursive (PR) function is total.<br>
Notation.  Many textbooks introduce a recursion operator<br>
and define  to be the smallest class of functions that contains the initial functions and is closed under composition and .
<br><br>Primitive recursion alone is enough to reconstruct the whole toolkit of elementary arithmetic:<br><br><br>Define  <br><br>Let the characteristic function of  be .  <br>A bounded search can be implemented by primitive recursion:<br><br>Hence bounded minimisation, and therefore bounded quantifiers  and , are primitive recursive.  <br><br>Primitive recursion forbids unbounded search.  Adding even a single unbounded  operator yields the class of partial recursive (a.k.a. just “recursive”) functions, matching Turing-computability.<br>The classical witness that breaks out of  is the Ackermann function<br><br><br>
<br>
Fast‐growing hierarchy<br>
Define  (the -fold iterate of ).  Each  is primitive recursive, and every PR function is majorised by some :<br>


<br>
Ackermann outruns every <br>
By induction on  one shows  for all .

<br>Combining (1) and (2) yields .<br>This implies that  is large—it contains towers of exponentials of any fixed height, but still too small for some totally computable, rapidly growing functions.<br><br>Goal. Within a 1 ms interrupt, evaluate the hyper-geometric probability  <br><br>for parameters  on an ATmega328P (Arduino Uno) featuring  <br>
<br>16 MHz clock, single-cycle 8 × 8 → 16-bit multiplier  
<br>2 kB SRAM, 32 general-purpose 8-bit registers  
<br>no hardware divide.
<br>Plan of attack  <br>
<br>specify a primitive-recursive algorithm,  
<br>translate it to C,  
<br>inspect the exact machine code GCC emits,  
<br>account for every clock cycle,  
<br>prove functional correctness, and  
<br>situate the whole exercise inside the class .
<br><br>Standard primitive recursion drops a single argument.  For the binomial  two indices must descend lexicographically:<br><br>Because each recursive call strictly lowers the pair  in lexicographic order and , expansion always reaches a base case.  Encoding the pair  as a single natural (e.g. via Cantor pairing) places  squarely inside .<br><br>#include &lt;avr/io.h&gt;      /* register names,  -mmcu=atmega328p */
#include &lt;util/atomic.h&gt; /* ATOMIC_BLOCK macros               */
#include &lt;stdint.h&gt;

static uint16_t binom(uint8_t n, uint8_t k)
{
    if (k &gt; n)      return 0;
    if (k &gt; n &gt;&gt; 1) k = n - k;    /* C(n,k) = C(n,n-k) */

    uint16_t row[17];             /* 17 × 2 = 34 B fits SRAM */
    row[0] = 1;

    for (uint8_t i = 1; i &lt;= n; ++i)
    {
        uint16_t prev = 1;        /* C(i,0) */
        row[i] = 1;               /* C(i,i) */

        /* inner loop ≤ 15 iterations (k ≤ n/2 ≤ 15) */
        for (uint8_t j = 1; j &lt; i &amp;&amp; j &lt;= k; ++j)
        {
            uint16_t tmp = row[j];      /* C(i-1,j)         */
            row[j] = tmp + prev;        /* C(i,j)           */
            prev   = tmp;               /* slide window     */
        }
    }
    return row[k];
}
<br>Why primitive recursion? The outer for is the single descending . The inner for merely looks up and updates earlier values—no self-calls—so the overall depth of primitive recursion is 1.<br><br>binom:
    push r28               ; frame pointer
    push r29
    push r17               ; callee-saved
    ...
    ; row array at Y-offset −34
    ldi  r24,1             ; row[0] = 1
    sts  -34,Y,r24
outer_i:
    cp   r18,r20           ; i ≤ n ?
    brhi done_outer
    ldi  r17,1             ; prev = 1
    sts  row+i,1           ; row[i] = 1
inner_j:
    cp   r19,r17           ; j &lt; i ?
    brge done_inner
    ld   r25,row+j
    add  r25,r17           ; add prev
    st   row+j,r25
    mov  r17,r25           ; prev = tmp
    inc  r19
    rjmp inner_j
done_inner:
    inc  r18
    rjmp outer_i
done_outer:
    ld   r24,row+k         ; result → r24:r25
    ...
    pop  r17
    pop  r29
    pop  r28
    ret
<br>
<br>86 instructions total
<br>Zero run-time stack growth (array resides in fixed frame)
<br>Division-free: only add, cp, ld, st, inc, br* branches.
<br><br>Loop counters<br>outer&nbsp;iterations=n≤30,inner&nbsp;iterations=∑i=1nmin⁡(i ⁣− ⁣1,k).\text{outer iterations}=n\le 30,\qquad \text{inner iterations} =\sum_{i=1}^{n}\min(i!-!1,k).<br>Worst case  gives<br><br>inner iterations.<br>Instruction counts<br><br>Execution time<br><br>leaving over 85 % head-room inside the 1 ms interrupt service routine.<br><br><br>In intensional Martin-Löf type theory (<a class="internal-link" data-href="Appendix-III" href="appendix-iii.html" target="_self" rel="noopener nofollow">MLTT</a>) an inductive type is a familial collection of values obtained by finitely many constructors whose recursive occurrences satisfy a strict-positivity condition (doesn't encode potentially non-terminating self-reference). An inductive definition is constituted by four mutually coherent judgemental rules: formation, introduction, elimination, and computation.  <br><br>Given a parameter context  <br><br>the formation sequent introduces a type family  <br><br>where  is itself a type (often a simple finite index such as  or ) and  is the ambient<br>
universe. The metavariable  is called the index.<br><br>For each constructor label  we prescribe a typing rule of the form  <br><br>Each argument type  may contain recursive occurrences of , but only in strictly positive positions:  may appear to the right of an even number of arrows and never to the left of a function arrow.  Formally, the endofunctor on  generated by the constructor arguments must be polynomial and covariant in .  This syntactic discipline guarantees that the constructor relation “is an immediate sub-term of’’ is well-founded.<br><br>For any motive  <br><br>the eliminator  <br><br>is generated, where  <br> abbreviates  <br><br>Operationally,  supplies one branch per constructor, and recursive calls are authorised exactly on the constructor fields whose type is a recursive occurrence of .<br><br>A type expression  is strictly positive in  if it is constructed from:<br>
<br>constants and parameters that do not mention ,
<br>sums () and products (),
<br>covariant function spaces  where  occurs<br>
exclusively in the codomain.
<br>Negative positions such as  or function spaces nested contravariantly  are forbidden: they would invalidate well-foundedness and break totality.<br><br>Let  be the signature functor obtained by replacing every recursive occurrence of  inside the constructor arguments with the functor variable .   The pair , where<br>
 bundles the constructors, is the **initial<br><a class="internal-link" data-href="Appendix-III" href="appendix-iii.html" target="_self" rel="noopener nofollow">F-algebra</a>:<br>
<br>for any -algebra  there exists a unique<br>
such that  


<br>uniqueness yields the eliminator; initiality implies termination.
<br>Conversely, any initial algebra in  (or in a locally-finitely-presentable category) gives rise to an inductive type.<br><br>Once an inductive type is declared, its generic recursion principles—also called elimination rules—are generated automatically by the type theory or proof assistant.<br>They come in two flavours that share the same well-founded backbone but differ in whether<br>
the result type may depend on the term being de-constructed.<br><br>Let  <br><br>be the inductive family with constructors  <br><br>where each telescope  is strictly positive in . Write  <br><br>for its polynomial <a class="internal-link" data-href="Appendix-III" href="appendix-iii.html" target="_self" rel="noopener nofollow">signature functor</a>. The pair , with  <br><br>is the initial -algebra. Initiality yields a unique morphism<br><br>given any -algebra , and characterised by the commuting law<br><br>Concretely, one supplies one branch per constructor<br><br>and the fold is defined recursively by the right-hand side of the equation above.  <br>Because every recursive occurrence of  lives strictly inside one outer constructor, the unfolding depth is bounded by the size of the input term, guaranteeing termination.<br><br>For a motive<br><br>(the type family of properties we wish to compute or prove), the dependent eliminator<br><br>is produced, where<br>
<br> is obtained from  by decorating each recursive field  with an extra argument<br>
This allows the branch handler to assume the induction hypothesis for every immediate sub-term.
<br>As with the non-dependent fold, strict positivity ensures that the recursive calls embedded in those  refer only to proper sub-structures, making the entire computation well-founded.
<br><br>For each constructor the eliminator satisfies a definitional equality that unfolds exactly one layer of the data:<br><br><br>where  acts functorially on the telescope and  is the sub-tuple of recursive fields.<br>
These -rules are judgmental equalities in systems such as Coq or Agda, which means that terms normalise by literal rewriting without an extra proof of correctness.<br><br>
<br>Uniqueness.<br>
If  is any function satisfying the commuting diagram with , then by initiality
<br>   The dependent eliminator enjoys an analogous uniqueness in the category of dialgebras.<br>
<br>Termination measure.<br>
Every recursive call consumes exactly one constructor of the argument value.  Let  be the constructor height of ; the maximum unfolding depth of either eliminator is , providing an explicit linear bound on evaluation steps and stack frames.
<br><br>When  is the unary natural numbers type and , the generic fold and its -equality recover the classical primitive-recursion scheme<br><br>Thus structural recursion on inductive types is a strict generalisation of primitive recursion from  to all strictly positive algebraic data.<br><br>We build the familiar “binary tree with data at the leaves” from scratch, starting with a polynomial endofunctor and ending with<br>(1) its concrete data declaration,<br>
(2) the structural recursion rule generated by initiality,<br>
(3) a categorical proof of uniqueness, and<br><br>Fix a set-parameter  whose elements label leaves. Define the endofunctor  <br><br>
<br>The left summand  corresponds to a constructor<br>

<br>The right summand  corresponds to a constructor<br>

<br> is polynomial (built from ) and therefore preserves filtered colimits; initial algebras are guaranteed to exist in .<br><br>Let  <br><br>be the initial -algebra.   Because  is coproduct + product,  is uniquely determined by two injections<br><br>Writing  and renaming the injections,<br>data Tree a
  = Leaf a
  | Node (Tree a) (Tree a)
<br>gives an explicit syntactic form for . By Lambek’s lemma  is an isomorphism, so every<br>
value of Tree a decomposes uniquely into one Leaf or one Node.<br><br>For any -algebra , i.e. a pair of functions<br>ell  :: a -&gt; B
comb :: (B, B) -&gt; B
<br>initiality yields one and only one morphism<br>cata :: Tree a -&gt; B
<br>such that <br>This is the familiar foldTree but uniqueness is categorical: no other definition can satisfy the same two equations.<br><br>
<br>Size<br>
  returns the number of leaves + internal nodes.
<br>Leaf list (in-order)<br>

<br>module BinaryTreeAlgebra where

-- 1. The signature functor F_A(X) = A + X × X
--    corresponds to the following Functor:
data FA a x
  = LeafF a
  | NodeF x x
  deriving (Functor, Show)

-- 2. The fixpoint of a functor: the initial algebra μF ≅ Fix F
newtype Fix f = Fix { unFix :: f (Fix f) }

-- 3. The generic catamorphism (fold) from initiality:
--    For any algebra alg :: f b -&gt; b, we get
--      cata alg :: Fix f -&gt; b
cata :: Functor f =&gt; (f b -&gt; b) -&gt; Fix f -&gt; b
cata alg (Fix t) = alg (fmap (cata alg) t)

-- 4. Instantiate: Tree a ≔ Fix (FA a)
type Tree a = Fix (FA a)

-- 5. Smart‐constructors witnessing the Lambek isomorphism
leaf :: a -&gt; Tree a
leaf x = Fix (LeafF x)

node :: Tree a -&gt; Tree a -&gt; Tree a
node l r = Fix (NodeF l r)

-- Now the datatype Tree a is exactly
--   data Tree a = Leaf a | Node (Tree a) (Tree a)

-- 6. Example 1: Size = number of total nodes
size :: Tree a -&gt; Int
size = cata alg
  where
    alg :: FA a Int -&gt; Int
    alg (LeafF _)      = 1
    alg (NodeF lCount rCount) = 1 + lCount + rCount

-- 7. Example 2: Leaf‐list in order
toList :: Tree a -&gt; [a]
toList = cata alg
  where
    alg :: FA a [a] -&gt; [a]
    alg (LeafF x)     = [x]
    alg (NodeF xs ys) = xs ++ ys

-- 8. Example 3: Mirror
--    Notice that mirror *is* a fold if we swap the pair in the algebra
mirror :: Tree a -&gt; Tree a
mirror = cata alg
  where
    alg :: FA a (Tree a) -&gt; Tree a
    alg (LeafF x)      = leaf x
    alg (NodeF lTree rTree) = node rTree lTree
<br><br>Divide-and-conquer is an algorithmic paradigm in which a problem of size  is solved by:<br>
<br>Dividing it into one or more subproblems of the same form but smaller size.
<br>Conquering each subproblem by (typically) recursive invocation.
<br>Combining the subproblem solutions into a solution for the original problem.
<br>Because the subproblems are (ideally) independent and of reduced size, this pattern often yields elegant algorithms whose performance is captured by a simple recurrence.<br><br>Suppose a divide-and-conquer algorithm on an input of size  splits it into  subproblems, each of size , incurs a division overhead of  and a combination cost of .  Then its time  satisfies<br><br>where  is a constant threshold below which base-case strategies apply.  Frequently  and  are both  for some , yielding the canonical form<br><br>with .<br><br>The Master Theorem gives tight bounds when subproblems are equal-sized and  is polynomially related to :<br>
<br>If  for some , then   
<br>If  for some , then   
<br>If  and regularity holds ( for some ), then   
<br>For more complex splits—unequal subproblem sizes or non-polynomial —the Akra-Bazzi method applies, solving<br><br>under mild smoothness conditions on .<br><br>Pseudocode<br>function karatsuba(x, y):
    // if numbers are small, do naïve multiplication
    if x &lt; 10 or y &lt; 10:
        return x * y

    // split size
    m ← max(number_of_digits(x), number_of_digits(y)) ⌈÷2⌉
    b ← 10^m

    // split x, y into high and low halves
    x_H ← ⌊x / b⌋,   x_L ← x mod b
    y_H ← ⌊y / b⌋,   y_L ← y mod b

    // three recursive multiplies
    z0 ← karatsuba(x_L, y_L)
    z2 ← karatsuba(x_H, y_H)
    z1 ← karatsuba(x_H + x_L, y_H + y_L) − z2 − z0

    // recombine
    return z2·b^2 + z1·b + z0
<br>Recurrence and Complexity<br>Each call makes three multiplications on half-sized operands plus  work for additions and shifts. Thus<br>
<br>By the Master Theorem (with , ),<br><br>which beats the  of the grade-school algorithm.<br>Example on <br>We have  digits, so , :<br>
<br>
Split<br>


<br>
Compute<br>


<br>
Sum halves and multiply<br>


<br>
Recover middle term<br>


<br>
Recombine


<br>which matches .]]></description><link>ch03-recursion.html</link><guid isPermaLink="false">CH03-Recursion.md</guid><pubDate>Thu, 17 Jul 2025 19:28:31 GMT</pubDate></item><item><title><![CDATA[CH04-DP]]></title><description><![CDATA[ 
 <br><br>Dynamic programming is a disciplined way to turn an exponential‐time recursion into a polynomial‐time algorithm by remembering the answers to subproblems and reusing them.  Its two essential pillars are optimal substructure—the fact that an optimal solution can be composed from optimal solutions of smaller subproblems—and overlapping subproblems—the same subproblems recur many times in a naïve recursive approach.<br><br>The Principle of Optimality, introduced by Richard Bellman, lies at the heart of dynamic programming. It asserts that an optimal policy (or trajectory) over a planning horizon possesses the property that, whatever the initial state and decision are, the remaining decisions must constitute an optimal policy with regard to the state resulting from the first decision. This deceptively simple statement carries profound implications for breaking down complex multistage decision problems into a sequence of smaller subproblems.<br>Consider a decision problem over discrete time steps , with state space  and control (or action) space . Let  denote the state at time , and  the control chosen in state . The system evolves according to a transition function<br><br>incurring a one‐stage cost . The total cost over the horizon is<br><br>where  is a terminal cost. Define the optimal cost‐to‐go (value) function at time  as<br><br>with boundary condition . The Principle of Optimality guarantees that solving this recursion—known as the Bellman equation—yields the globally optimal control sequence.<br>Intuitively, if one had an optimal sequence  from state , then after the first action  leading to state , the remaining sequence  must minimize the cost from  onward. Otherwise, one could replace it with a better tail policy and improve the overall cost, contradicting optimality. This recursive structure is the lever that dynamic programming uses to avoid the combinatorial explosion of brute‐force search.<br>In infinite‐horizon settings or stochastic variants, the same principle applies under suitable regularity conditions. For a stochastic system, one replaces the deterministic transition by a probability kernel , and the Bellman equation becomes<br><br>A subtle yet important requirement for the principle to hold is no regret in future decisions: once optimal actions are chosen up to time , the optimization from time  onward should be independent of past decisions beyond their effect on the current state. In other words, the state  must be a sufficient statistic for all future costs. When hidden state or path‐dependence arises, one must augment the state to restore the Markov property before applying dynamic programming.<br><br>The Markov property asserts that, in a stochastic process, the conditional distribution of the next state depends only on the current state and not on the sequence of events that preceded it.  In formal terms, for a sequence of random variables  taking values in a state space , we require that  <br><br>so that  is a sufficient statistic for predicting .  This memoryless property underpins both the theory of Markov chains and the more general framework of Markov decision processes (MDPs).<br>In an MDP with actions , the Markov property extends to  <br><br>emphasizing that the pair  fully captures all relevant information for future evolution.  Under this assumption, one can define a transition kernel  and one‐step cost , making dynamic programming tractable: the Bellman recursion needs only the current state–action pair, not the entire history.<br><br>We want to make change for an amount  using the fewest coins possible from a given set of denominations .  Dynamic programming builds up a table of optimal answers for every sub‐amount .<br><br>Define<br><br>By the Principle of Optimality, if the optimal solution for  uses coin , then the remaining  must itself be made with the minimum possible coins.<br><br>def min_coins(A, coins):
    INF = A + 1           # anything &gt;A is "impossible"
    T = [INF] * (A + 1)   # T[a] = best for amount a
    T[0] = 0              # base case: zero coins for amount 0

    choice = [-1] * (A + 1)  # which coin gave the best result

    for a in range(1, A+1):
        for c in coins:
            if c &lt;= a and T[a - c] + 1 &lt; T[a]:
                T[a] = T[a - c] + 1
                choice[a] = c

    if T[A] &gt; A:
        return None, []
    return T, choice
<br>
<br>Outer loop  computes each sub‐amount.
<br>Inner loop tries each coin  to update  using previously computed .
<br><br><br>
<br>: only coin 1 fits ⇒ , choice[1]=1.
<br>: try 1 ⇒ , try 3 ⇒  best ⇒ , choice[3]=3.
<br>Continue similarly up to  to fill the table.
<br><br>def get_coins(A, choice):
    if choice[A] == -1:
        return []
    res = []
    a = A
    while a &gt; 0:
        c = choice[a]
        res.append(c)
        a -= c
    return res
<br>For , this outputs [3, 4], since choice[7]=3 then choice[4]=4.<br>
<br>Time: , since we do  checks for each of the  sub‐amounts.
<br>Space:  for arrays T and choice.
<br><br>
<br>
Confirm DP is appropriate<br>
Ensure the problem has overlapping subproblems (repeated work) and optimal substructure (solutions build from smaller ones).

<br>
Define the state<br>
Pick the minimal parameters that describe progress (for example, index i, capacity w, or positions i,j).

<br>
Formulate the recurrence<br>
Write dp[state] in terms of smaller states.<br>
Examples:  

<br>dp[i] = dp[i-1] + dp[i-2]  
<br>dp[i][w] = max(dp[i-1][w], dp[i-1][w - weight[i]] + value[i])


<br>
Set base cases<br>
Handle the smallest inputs explicitly (e.g. dp[0] = 0, dp[0][*] = 1 for counting paths).

<br>
Choose an implementation style  

<br>Top-down: recursive + memoization (caches only needed states).  
<br>Bottom-up: iterative table filling (predictable order).


<br>
Implement and test<br>
Run simple examples (e.g. small N) to catch off-by-one or logic errors.

<br><br>After seeing how the coin-change DP reuses each sub-amount exactly once, we now deeper into why that reuse is both possible and essential. A problem has overlapping subproblems when the naïve recursion would recompute the same state many times, and those repeats grow exponentially.<br>Suppose we implement minCoins(a) recursively:<br>def minCoins(a):
    if a == 0: return 0
    best = ∞
    for c in coins:
        if c &lt;= a:
            best = min(best, 1 + minCoins(a - c))
    return best
<br>For A=7 and coins=[1,3,4], the call tree begins:<br>minCoins(7)
├─ minCoins(6)
│  ├─ minCoins(5)
│  │  ├─ minCoins(4)
│  │  │  ├─ minCoins(3)
│  │  │  │  ├─ minCoins(2)
│  │  │  │  │  └─ minCoins(1)
│  │  │  │  └─ minCoins(0)
│  │  │  └─ minCoins(0)
│  │  └─ minCoins(1)
│  └─ minCoins(3)
└─ minCoins(4)
<br>Already you see minCoins(4) and minCoins(3) invoked multiple times. In general, the recursion graph for states  is a DAG with edges<br><br>Naïvely exploring that DAG as a tree repeats each node once for every incoming edge. The total node‐visits is exponential in  when the in‐degree is bounded below by a constant.<br>By contrast, the DP table T[0..A] visits each state  exactly once so the total work is proportional to .<br><br>Dynamic programming rests on the same recurrence but can be implemented either as memoization (top-down caching) or as tabulation (bottom-up table filling).  Both guarantee that each state  is evaluated exactly once, yielding total time<br><br><br>In memoization, you write the natural recursive function and attach a cache so that once you compute DP(s) it is stored and never recomputed.  The first time you call DP(s₀) the recursion descends into sub-states as needed.  Whenever a recursive call reaches a state s that has already been solved, you return the cached result in  rather than recomputing.  Because only states reachable from your initial query are ever visited, memoization can save work when many theoretical states are never needed.<br>cache = {}
def DP(s):
    if s in cache:
        return cache[s]
    if is_base(s):
        ans = base_value(s)
    else:
        ans = float('inf')
        for r in R(s):
            ans = min(ans, g(s,r) + DP(h(s,r)))
    cache[s] = ans
    return ans
<br>This style follows the recursion tree, using the call stack up to the maximum dependency depth, and shines when the dependency graph is irregular or sparse.<br><br>Tabulation reverses the approach: you precompute a topological order of all states so each state’s dependencies come before it. Then a simple loop fills an array or dictionary T[s]:<br>T = {}
for s in topo_order:
    if is_base(s):
        T[s] = base_value(s)
    else:
        best = float('inf')
        for r in R(s):
            best = min(best, g(s,r) + T[h(s,r)])
        T[s] = best
<br>By the time you reach any state s, every T[h(s,r)] is already available. This iterative style avoids recursion entirely, uses no extra stack, and often achieves better memory locality when states map naturally to contiguous indices.<br><br>Memoization is often the quickest to write when you have a clear recursive specification but no obvious ordering of states, and when many states may go unused in practice. Tabulation is preferable when every subproblem will be needed, when you must avoid deep recursion (e.g.\ in languages without tail-call elimination), or when you can exploit simple array indices to maximize cache performance. In both cases, the same optimal-substructure and overlapping-subproblem properties justify the transformation from exponential recursion to efficient polynomial-time computation.<br><br><br>Given two sequences  <br><br>the Longest Common Subsequence problem asks for a sequence  <br><br>of maximum length  such that  appears in order (not necessarily contiguously) in both  and .<br>Let<br><br>We build  by comparing the last elements  and :<br>
<br>If , then any LCS of  and  can be obtained by appending  to an LCS of  and .  Thus  


<br>If , the best LCS must either exclude  or exclude , so  


<br>We set the base conditions  <br><br>We allocate a table L[0..m][0..n] and fill it in row‐major order:<br>def lcs_length(X, Y):
    m, n = len(X), len(Y)
    L = [[0]*(n+1) for _ in range(m+1)]
    for i in range(1, m+1):
        for j in range(1, n+1):
            if X[i-1] == Y[j-1]:
                L[i][j] = L[i-1][j-1] + 1
            else:
                L[i][j] = max(L[i-1][j], L[i][j-1])
    return L
<br>After this, L[m][n] holds the length of the LCS.<br>To reconstruct an actual subsequence of length L[m][n], we trace back from (i,j)=(m,n):<br>def lcs_sequence(X, Y, L):
    i, j = len(X), len(Y)
    seq = []
    while i&gt;0 and j&gt;0:
        if X[i-1] == Y[j-1]:
            seq.append(X[i-1])
            i, j = i-1, j-1
        elif L[i-1][j] &gt;= L[i][j-1]:
            i -= 1
        else:
            j -= 1
    return ''.join(reversed(seq))
<br>This follows the rule that when characters match we include them, otherwise we move in the direction of the larger neighbor.<br><br>We build a table  where  <br><br>Initialize  and .  Label rows by characters of  (with a leading blank) and columns by :<br><br>
<br>
Row 1 ():  

<br>:  ⇒   
<br>:  ⇒   
<br>:  ⇒   
<br>:  ⇒   
<br>:  ⇒   
<br>:  ⇒   

Row 1 becomes .

<br>
Row 2 ():  

<br>:  ⇒   
<br>:  ⇒   
<br>:  ⇒   
<br>:  ⇒   
<br>:  ⇒   
<br>:  ⇒   

Row 2: .

<br>
Row 3 () yields .

<br>
Row 4 () yields .

<br>
Row 5 () yields .

<br>
Row 6 () yields .

<br>
Row 7 () yields .

<br>The completed table is<br><br>The length of the LCS is .  Backtracking from  via the “match” rules recovers one LCS, for example “BCBA.”  <br><br>The edit distance (or Levenshtein distance) between two strings  <br><br>is the minimum number of character insertions, deletions, and substitutions needed to transform  into .<br>We define a table D[0..m][0..n] where  <br><br>The base cases are  <br><br>since converting a length- string to empty costs  deletions (and vice-versa for insertions).  For  the recurrence is<br><br>where  is  when  and  otherwise.<br><br>def edit_distance(X, Y):
    m, n = len(X), len(Y)
    D = [[0]*(n+1) for _ in range(m+1)]
    for i in range(1, m+1):
        D[i][0] = i
    for j in range(1, n+1):
        D[0][j] = j

    for i in range(1, m+1):
        xi = X[i-1]
        prev_row = D[i-1]
        cur_row  = D[i]
        for j in range(1, n+1):
            cost = 0 if xi == Y[j-1] else 1
            deletion    = prev_row[j]   + 1
            insertion   = cur_row[j-1]  + 1
            substitution= prev_row[j-1] + cost
            cur_row[j] = min(deletion, insertion, substitution)
    return D
<br>After running this, D[m][n] is the edit distance between  and .<br><br>def get_edits(X, Y, D):
    edits = []
    i, j = len(X), len(Y)
    while i &gt; 0 or j &gt; 0:
        if i &gt; 0 and j &gt; 0 and X[i-1] == Y[j-1]:
            i, j = i-1, j-1
        elif i &gt; 0 and j &gt; 0 and D[i][j] == D[i-1][j-1] + 1:
            edits.append(('substitute', i-1, Y[j-1]))
            i, j = i-1, j-1
        elif i &gt; 0 and D[i][j] == D[i-1][j] + 1:
            edits.append(('delete', i-1))
            i -= 1
        else:
            edits.append(('insert', i, Y[j-1]))
            j -= 1
    return list(reversed(edits))
<br>Each tuple describes an operation:<br>
<br>('substitute', i-1, Y[j-1])
<br>('delete', i-1)
<br>('insert', i, Y[j-1])
<br>Filling the  table does  work per entry, for a total of  time and  space. If only the distance is required, one can reduce space to  by keeping two rows at a time.<br><br>Let  <br><br>We build a  table , where<br><br>and for ,<br><br>Here  is  if  and  otherwise.<br><br>Fill row 1 ()<br>
<br>  
<br>  
<br>Continue likewise to get row 1:<br>

<br>Fill row 2 ()<br>
<br>  
<br> (match ).  
<br>Row 2 becomes<br>

<br>Applying the same rule for each cell yields:<br><br>The final entry is<br><br>so the edit distance between “kitten” and “sitting” is 3.  One optimal sequence of edits is:<br><br><br>In the 0/1 knapsack problem you have  items, each with weight  and value , and a capacity .  You must choose a subset of the items whose total weight does not exceed  and whose total value is as large as possible.<br>We define a table dp[0..n][0..W] where<br><br>The base cases are<br><br>since no items or no capacity yields zero value.  For  and  the recurrence is<br><br>def knapsack(weights, values, W):
    n = len(weights)
    dp = [[0] * (W + 1) for _ in range(n + 1)]
    for i in range(1, n + 1):
        wi, vi = weights[i-1], values[i-1]
        for w in range(W + 1):
            if w &lt; wi:
                dp[i][w] = dp[i-1][w]
            else:
                dp[i][w] = max(
                    dp[i-1][w],
                    dp[i-1][w - wi] + vi
                )
    return dp
<br>After running dp = knapsack(weights, values, W), the maximum achievable value is dp[n][W].<br>To recover which items were chosen, trace back from :<br>def recover_items(weights, values, W, dp):
    items = []
    i, w = len(weights), W
    while i &gt; 0 and w &gt; 0:
        if dp[i][w] != dp[i-1][w]:
            items.append(i-1)       # item i-1 was included
            w -= weights[i-1]
        i -= 1
    return list(reversed(items))
<br>This runs in  time and uses  space. To reduce space to  (at the cost of more complex backtracking), you can keep only two rows of the table at a time.<br>Example.<br>
Three items with  <br><br>and knapsack capacity .  We build a table<br>
dp[0..3][0..5] where<br><br><br><br><br>For each :<br>
<br>If , then .
<br>If , then  


<br><br><br>For each :<br>
<br>If , .
<br>If ,  


<br>Compute:<br>
<br>:   
<br>:   
<br>:   
<br>: 
<br><br><br>For each :<br>
<br>If , .
<br>If ,  


<br>Compute:<br>
<br>:   
<br>:   
<br>: 
<br><br>The final table is<br><br>Hence the maximum value for capacity  is<br><br>achieved by selecting items 2 and 3 (weights , values ).<br><br>In the two-dimensional 0/1 knapsack problem each item  has two “sizes”  and a value , and the knapsack has capacities .  We seek a subset  maximizing<br><br>subject to<br><br>We extend the classic 1D DP to a two-dimensional table dp[0..W1][0..W2] where<br><br>Initialize dp[a][b]=0 for all , .  Then for each item  in turn, we update the table in reverse to avoid reuse within the same iteration:<br>def knapsack_2d(weights1, weights2, values, W1, W2):
    # weights1[i], weights2[i], values[i] for i=0..n-1
    dp = [[0]*(W2+1) for _ in range(W1+1)]
    n = len(values)
    for i in range(n):
        w, v, u = weights1[i], weights2[i], values[i]
        # iterate capacities in reverse so each item is used at most once
        for a in range(W1, w-1, -1):
            row = dp[a]
            prev = dp[a - w]
            for b in range(W2, v-1, -1):
                # either skip item i or take it (if fits both dims)
                row[b] = max(row[b], prev[b - v] + u)
    return dp
<br>After this, dp[W1][W2] is the maximum total value under both capacity constraints.<br>To recover which items were chosen, one can trace back from , checking for each item whether<br><br>and descending accordingly, subtracting  from  when an item is included.<br><br>For  resource constraints  and item sizes , one defines a -dimensional array<br><br>and updates for each item  by iterating  in reverse lex order, setting<br><br>The running time is  and space , which is practical only for small  and modest capacities.<br>Let’s work through an instance of the two‐constraint knapsack by hand.  Suppose we have three items:<br><br>and knapsack capacities  (weight) and  (volume).<br>We build a table  for , , .  By definition,<br><br>with<br><br>For each item , if  or  we cannot include it and<br><br>Otherwise<br><br>We fill  in turn.  For each , view the slice  as a  grid indexed by .<br> (item 1 has )<br>Any  with  and  can include item 1 with value<br><br>Otherwise the value remains 0.  Thus<br><br> (item 2 has )<br>Start from the previous slice and consider including item 2 wherever  and .  For example at  the “without” value is<br><br>and the “with” value is<br><br>so we take 16.  Filling in every entry gives:<br><br> (item 3 has )<br>Again start from the  slice and include item 3 when .  At  the “without” entry is<br><br>and the “with” entry is<br><br>so we take 18.  The completed table is:<br><br>The entry  is the maximum value.  Backtracking from , we see it came from including item 3 (value 12) then reaching  whose value is 6 (item 1).  Thus the optimal subset is  with total weight , volume , and value .  <br><br><br>Given matrices  where  has dimensions , we seek the most efficient parenthesization of the product  to minimize scalar multiplications.<br><br>Define<br><br>Here  is the minimum cost to compute , and  is the cost to multiply the two resulting matrices of sizes  and .<br><br>def matrix_chain(p):
    # p is a list of length n+1: [p0, p1, ..., pn]
    n = len(p) - 1
    # m[i][j] = minimum cost for Ai...Aj
    m = [[0]*(n+1) for _ in range(n+1)]
    # s[i][j] = index k at which to split for optimal cost
    s = [[0]*(n+1) for _ in range(n+1)]
    # L is the chain length
    for L in range(2, n+1):
        for i in range(1, n-L+2):
            j = i + L - 1
            m[i][j] = float('inf')
            for k in range(i, j):
                cost = m[i][k] + m[k+1][j] + p[i-1] * p[k] * p[j]
                if cost &lt; m[i][j]:
                    m[i][j] = cost
                    s[i][j] = k
    return m, s
<br>After calling m, s = matrix_chain(p), the minimal multiplication cost is m[1][n].<br><br>def print_optimal_parens(s, i, j):
    if i == j:
        print(f"A{i}", end="")
    else:
        print("(", end="")
        k = s[i][j]
        print_optimal_parens(s, i, k)
        print_optimal_parens(s, k+1, j)
        print(")", end="")
<br>Calling print_optimal_parens(s, 1, n) outputs the optimal parenthesization, for example:<br>(A1((A2A3)A4))
<br><br>Filling the table requires examining each pair  with  and iterating , for a total time<br><br>and uses  space. This transforms the naïve  search over all parenthesizations into a practical cubic‐time algorithm.<br><br>Consider an  grid with rows indexed  from top to bottom and columns  from left to right.  Each cell  may contain an obstacle flag and, for the weighted variant, a cost  incurred when the cell is entered.  From any free cell you may move right  or down .<br>We describe two dynamic-programming tables built over the same state space.<br><br>Let  <br><br>If  is blocked, set .<br>
Otherwise the only ways to reach  are from its neighbor above or its neighbor to the left:<br><br>The table is filled row major in  time and the answer is .<br>def count_paths(grid):           # grid: list of strings, '#' = obstacle
    m, n = len(grid), len(grid[0])
    P = [[0]*n for _ in range(m)]
    if grid[0][0] == '.':
        P[0][0] = 1
    for i in range(m):
        for j in range(n):
            if grid[i][j] == '#':
                continue
            if i &gt; 0:
                P[i][j] += P[i-1][j]
            if j &gt; 0:
                P[i][j] += P[i][j-1]
    return P[m-1][n-1]
<br><br>Let<br><br>counting the entry cost of every visited cell, including the start.<br>Base cell:<br><br>For all other free cells,<br><br>with  substituted when a neighbor is out of bounds or blocked. The table is again .<br>def min_cost(grid, cost):        # cost[i][j]=w_{ij}; obstacle = large sentinel
    m, n = len(grid), len(grid[0])
    INF = 10**18
    D = [[INF]*n for _ in range(m)]
    if grid[0][0] == '.':
        D[0][0] = cost[0][0]
    for i in range(m):
        for j in range(n):
            if grid[i][j] == '#':
                continue
            if i &gt; 0:
                D[i][j] = min(D[i][j], D[i-1][j] + cost[i][j])
            if j &gt; 0:
                D[i][j] = min(D[i][j], D[i][j-1] + cost[i][j])
    return D[m-1][n-1] if D[m-1][n-1] &lt; INF else None
<br>When costs are uniform  the recurrence degenerates to counting Manhattan‐length; every path from  to  must make exactly  down moves and  right moves, so the optimum has length .]]></description><link>ch04-dp.html</link><guid isPermaLink="false">CH04-DP.md</guid><pubDate>Fri, 13 Jun 2025 15:32:31 GMT</pubDate></item><item><title><![CDATA[CH05-Graphs]]></title><description><![CDATA[ 
 <br>The origins of graph theory date back to 1736, when Leonhard Euler solved the Königsberg bridge problem, showing no walk could traverse each bridge exactly once. This launched the study of Eulerian trails and inaugurated graph theory as a mathematical discipline. In the 19ᵗʰ century, Sir William Rowan Hamilton investigated cycles on polyhedral graphs, giving rise to Hamiltonian paths. Cayley’s enumeration of trees in 1889 foreshadowed both combinatorial and algebraic methods. In the 20ᵗʰ century, Kuratowski’s planarity criterion (1930) and the Robertson-Seymour Graph Minor Theorem (1980s–2000s) established deep connections between local structure and global graph properties.<br><br><br><br>A graph  is a pair  where  is a (typically finite) set of vertices, and  is a set whose elements describe how those vertices are connected.  In the simplest case of a simple undirected graph, each edge is an unordered pair of distinct vertices, so<br><br>We refer to  as the order of  and  as its size.  When loops or multiple edges are allowed, one speaks of a pseudograph or multigraph, in which  may contain repeated pairs or pairs of the form .<br>If edges carry a direction, we instead take<br><br>so that an edge  goes from  to .  In-degree and out-degree then record how many edges enter or leave each node:<br><br>When every edge  is equipped with a real weight , the pair  is called a weighted graph, and one studies shortest paths or minimum-cost tours by taking those weights into account.<br>Two vertices  and  in an undirected graph are said to be adjacent precisely if .  The set of all neighbors of a vertex  is its neighborhood,<br><br>The degree of  is then , measuring how many edges touch it (with loops counted twice in a pseudograph).<br>Important substructures arise by restricting to subsets of .  Given , the induced subgraph  has vertex-set  and includes exactly those edges of  whose endpoints both lie in .  Dually, the complement of a simple graph  is the graph on the same  but with edge-set<br><br>so that two vertices are adjacent in the complement precisely when they were not adjacent in .<br>One sometimes passes to the line graph , whose vertices are the edges of .  In , two vertices (that is, two original edges) are joined by an edge exactly when they share a common endpoint in .<br><br>A spanning tree of a connected graph  is a subgraph  with  that is both acyclic and connects all vertices.  Algebraically, the number of spanning trees, denoted , equals any cofactor of the Laplacian , i.e.  <br><br>where  is  with its -th row and column removed.<br>A simple random walk on  is the Markov chain that at each step moves from the current vertex  to a neighbour  chosen uniformly at random.  Its one-step transition probabilities form the matrix  <br><br>The mixing time  measures how quickly this walk approaches its stationary distribution .  In spectral terms, if  are the eigenvalues of , then  <br><br>where  is called the spectral gap.<br>The effective resistance  between two vertices  treats  as an electrical network with unit resistors on each edge.  It can be expressed via the Moore–Penrose pseudoinverse  of the Laplacian:  <br><br>and governs both commute times of the random walk and energy dissipation in the network.<br><br>In category theory a directed graph can be described as a presheaf on a tiny “shape” category.  Let  be the category with two objects, say  (vertices) and  (edges), and exactly two parallel arrows <br><br>standing for “source” and “target.”  A graph  is then nothing more than a functor<br><br>so that  is its set of vertices,  its set of edges, and the maps<br><br>send each edge to its source and target.  In this way the category of graphs is canonically equivalent to the presheaf topos<br><br>which immediately grants it all limits, colimits, exponentials, and a subobject classifier inherited pointwise from .<br>Under this lens, a graph homomorphism  is simply a natural transformation between the corresponding presheaves.  The commuting square<br><img alt="Pasted image 20250610140501.png" src="assets/pasted-image-20250610140501.png"><br>ensures that sources and targets are preserved.<br>Because  is a presheaf category, all limits and colimits are computed “pointwise.”  <br>The product of two graphs  and  has vertex‐set  and edge‐set  while the coproduct (disjoint union) simply takes the disjoint union of vertices and edges.  More sophisticated constructions—equalisers, pullbacks, pushouts—are obtained by performing the usual Set‐wise constructions separately on vertices and edges. <br>In particular, the pushout along a monomorphism models the gluing of graphs along a common subgraph, the foundational step of the double‐pushout approach to graph rewriting.<br>An important adjunction relates graphs to categories.  The forgetful functor (<a data-href="Appendix-III" href="appendix-iii.html" class="internal-link" target="_self" rel="noopener nofollow">Appendix-III</a>)<br><br>drops composition and identities, leaving only the underlying directed graph.  Its left adjoint<br><br>freely generates a category on a graph: objects are the original vertices, morphisms are finite paths (including the empty path as identity), and composition is path concatenation.  This adjunction  underlies the passage from transition graphs to their semantic categories of executions or “runs.”<br>Because  is cartesian closed, it admits an internal hom: for any graphs  and  there is a graph  whose vertices are all graph‐homomorphisms , and whose edges correspond to commuting squares in . <br><br>Algebraic graph theory studies a graph’s structure through matrices whose entries encode adjacency or incidence relationships, and through the spectral properties of those matrices.  Given a simple undirected graph  with , one labels the vertices  and forms the adjacency matrix  by<br><br>Because  is real and symmetric, it admits an orthonormal basis of eigenvectors and real eigenvalues<br><br>The trace  counts closed walks (source = target) of length , and in particular .  <br>The largest eigenvalue —the spectral radius—satisfies , with equality if and only if  is regular.  Bipartiteness is witnessed by spectral symmetry:  is bipartite precisely when  for each . <br>To capture connectivity and flow, one introduces the combinatorial Laplacian , where  is the diagonal matrix of vertex degrees.  As a positive semidefinite matrix, its eigenvalues <br><br>encode deep combinatorial invariants.  The multiplicity of the zero eigenvalue equals the number of connected components, and the second‐smallest eigenvalue , known as the algebraic connectivity, quantifies how “hard” it is to disconnect the graph.  Through the Rayleigh quotient characterization<br><br>one sees directly its relation to isoperimetric constants and hence to expansion.<br>In parallel, the normalized Laplacian  has spectrum contained in  and arises naturally when studying random walks.  <br>The transition matrix  governs a simple random walk on , and one shows that  and  share eigenvectors, with eigenvalues related by  when  is an eigenvalue of .  The spectral gap  controls the mixing time , giving quantitative bounds on how quickly the walk converges to the uniform distribution.<br>A crowning result of algebraic graph theory is the Matrix‐Tree Theorem.  Remove the -th row and column from  to obtain the principal minor .  Kirchhoff’s theorem asserts that<br><br>counts the number of spanning trees in , independent of the choice of .  In spectral language one can also write<br><br>when  is regular, linking tree‐counts to eigenvalue products.<br>Beyond enumeration, the pseudoinverse  of the Laplacian yields notions of effective resistance between vertices :<br><br>which in turn governs commute times of random walks. <br><br>Let’s compute the number of spanning trees of a small 4-vertex graph via the Matrix-Tree Theorem.  Label the vertices  and suppose its adjacency matrix is<br><br>Here  are the edges.<br>First, form the degree matrix  by summing each row of :<br>
<br>, , , .
<br>Hence<br><br>The (combinatorial) Laplacian is , namely<br><br>By the Matrix-Tree Theorem, the number of spanning trees  equals the determinant of any cofactor of .  Remove the 4ᵗʰ row and column to obtain the principal minor<br><br>We compute its determinant by expansion along the first row:<br><br>so this graph has exactly three spanning trees.<br><br>Breadth‐First Search (BFS) One maintains a queue of discovered but unprocessed vertices.  Initially only  is in the queue and marked at distance .  Then, repeatedly:<br>
<br>Dequeue a vertex ,  
<br>For each neighbor  of  not yet discovered, set , mark  discovered, and enqueue .  
<br>This guarantees that when  is first discovered, the path from  to  uses the minimum possible number of edges. In pseudocode:<br>function BFS(G, s):
    for each vertex u in G:
        color[u] ← WHITE
        d[u]     ← ∞
        π[u]     ← NIL
    color[s] ← GRAY
    d[s]     ← 0
    π[s]     ← NIL
    Q ← empty queue
    enqueue(Q, s)
    while Q not empty:
        u ← dequeue(Q)
        for each v in Adj[u]:
            if color[v] = WHITE:
                color[v] ← GRAY
                d[v]     ← d[u] + 1
                π[v]     ← u
                enqueue(Q, v)
        color[u] ← BLACK
<br>Here color[u] tracks whether  is undiscovered (WHITE), in the queue (GRAY), or fully explored (BLACK);  records the BFS tree parent. Since each vertex is enqueued and dequeued exactly once, and each edge  is examined exactly twice (once from each end), the running time is<br><br>The distances  satisfy the invariant that the queue is always ordered by non‐decreasing distance from , ensuring optimality.<br>Depth‐First Search (DFS) instead dives as deeply as possible before backtracking. It can be implemented with recursion or an explicit stack. On visiting a vertex  one marks it GRAY, then recursively explores each undiscovered neighbor , and finally marks  BLACK when all its outgoing edges have been examined. Timestamps of discovery and finish— and —encode the structure of the search tree and its back‐edges.<br>time ← 0
function DFS(G):
    for each vertex u in G:
        color[u] ← WHITE
        π[u]     ← NIL
    for each vertex u in G:
        if color[u] = WHITE:
            DFS-Visit(u)

function DFS-Visit(u):
    time ← time + 1
    disc[u]  ← time
    color[u] ← GRAY
    for each v in Adj[u]:
        if color[v] = WHITE:
            π[v] ← u
            DFS-Visit(v)
    color[u] ← BLACK
    time ← time + 1
    fin[u]   ← time
<br>Because each vertex enters DFS-Visit exactly once and each edge is considered once, DFS also runs in<br><br>
<br>If  is an edge and , it is a tree edge or forward edge. 
<br>If , it is a back edge, signalling a cycle.
<br>Remaining edges are cross edges, connecting different branches of the DFS forest.
<br><img alt="1_GT9oSo0agIeIj6nTg3jFEA.gif" src="assets/1_gt9oso0agieij6ntg3jfea.gif"><br>
<a data-tooltip-position="top" aria-label="https://medium.com/analytics-vidhya/a-quick-explanation-of-dfs-bfs-depth-first-search-breadth-first-search-b9ef4caf952c" rel="noopener nofollow" class="external-link" href="https://medium.com/analytics-vidhya/a-quick-explanation-of-dfs-bfs-depth-first-search-breadth-first-search-b9ef4caf952c" target="_blank">Source</a><br><br>Vertices , edges .<br>
Adjacency lists:  <br>
<br>  
<br>  
<br>  
<br>  
<br>  
<br>We run BFS from .  Distances  initialized to , . <br><br>After step 5 the queue is empty and BFS is complete.<br><br>We perform a recursive DFS, visiting neighbors in alphabetical order.  We record a global time counter time, incremented on each discovery and finish.<br><br>From this trace we extract discovery/finish times and parent pointers:<br><br><br>A minimum‐spanning tree (MST) of a connected, weighted undirected graph  is a subset  that connects all vertices with no cycles and minimizes the total weight<br><br>Two classical greedy routines—Kruskal’s and Prim’s algorithms—find an MST in  time on a graph with , .  Both rely on the cut property: for any bipartition of the vertices, the minimum‐weight edge crossing the cut belongs to some MST.<br><br>The disjoint-set union (or union-find) structure maintains a partition of a universe of elements into disjoint classes, supporting three operations:<br>
<br>MakeSet : create a new singleton set .  
<br>Find : return a representative (root) of the set containing .  
<br>Union : merge the two sets containing  and  into one.
<br>A classic implementation uses parent‐pointer trees: each element  stores a pointer  initially to itself.  The Find operation follows parent pointers until it reaches a root  with .  To keep trees shallow, we combine two heuristics:<br>
<br>
Union by rank (or size): each root  maintains a small integer  estimating its tree’s height.  When uniting roots  and , attach the smaller‐rank tree under the larger; if ranks are equal, pick one and increment its rank by 1.

<br>
Path compression: during Find, make every visited node  point directly to the root , flattening the tree.

<br>Here is a standard pseudocode:<br>function MakeSet(x):
    parent[x] ← x
    rank[x]   ← 0

function Find(x):
    if parent[x] ≠ x then
        parent[x] ← Find(parent[x])   # path compression
    return parent[x]

function Union(x, y):
    r_x ← Find(x)
    r_y ← Find(y)
    if r_x = r_y then return
    if rank[r_x] &lt; rank[r_y] then
        parent[r_x] ← r_y
    else if rank[r_x] &gt; rank[r_y] then
        parent[r_y] ← r_x
    else
        parent[r_y] ← r_x
        rank[r_x]   ← rank[r_x] + 1
<br>With these two optimizations, any sequence of  operations (on  elements) runs in<br><br>where  is the extremely slow‐growing inverse Ackermann function (for all practical , ). In effect, Find and Union take amortized constant time.<br>Under the hood, the invariant is that each set is represented by a rooted tree whose height remains  by union-by-rank, and path compression reduces the length of subsequent root‐search paths. Despite its simplicity, this combination yields near-optimal performance.<br>Union-find is indispensable in Kruskal’s MST algorithm, connectivity queries in dynamic graphs, and clustering applications (e.g. union by similarity), wherever one must repeatedly merge and query equivalence classes efficiently.<br><br>Kruskal’s method sorts all edges in non‐decreasing order of weight and then scans them, adding each edge if and only if it does not create a cycle in the growing forest.  A union‐find (disjoint‐set) data structure tracks which vertices are already connected, supporting  and  in nearly constant amortized time.<br>function Kruskal(G):
    A ← ∅
    sort edges E by increasing w(e)
    for each edge (u,v) in sorted E:
        if Find(u) ≠ Find(v):
            A ← A ∪ {(u,v)}
            Union(u,v)
        if |A| = n-1: break
    return A
<br>Since sorting takes  and each of the  union/find operations costs  (inverse‐Ackermann), the overall runtime is<br><br>Correctness follows by the exchange argument: when considering an edge  that crosses some cut, if  is the minimum remaining and would form a cycle with previously chosen edges , swapping  into an alternative spanning tree reduces or preserves total weight, so  can safely enter the MST.<br>Correctness Proof<br>
Let .  Kruskal’s algorithm builds a set  by scanning the edges in non‐decreasing weight order and adding each edge  to  if it does not create a cycle, stopping once .  We must show:<br>
<br>
 is a spanning tree:<br>
(a)  is acyclic by construction, and<br>
(b) , so as an acyclic set of  edges on  vertices it is necessarily connected.

<br>
 has minimum total weight:<br>
Let  be some minimum‐weight spanning tree of  (exists by connectivity).  We show by induction on the number of edges Kruskal has added that after each addition, the current set  is contained in some MST.

<br>
Invariant.  At the start of each iteration, just before Kruskal considers the next lightest edge , there exists an MST  such that .
<br>Base case.  Initially , and any MST  trivially contains .<br>Inductive step.  Suppose the invariant holds and Kruskal now considers the next edge <br><br>of minimum weight  among those not yet examined.  Two cases arise:<br>
<br>
Case 1:  would form a cycle.<br>
Then  and  are already connected by a path in .  Since no cycles are ever introduced,  remains unchanged and the invariant is unchanged: the same MST  still contains .

<br>
Case 2:  is acyclic.<br>
We will exhibit a new MST  with .
By the invariant, there is an MST  with .  If  already, set .  Otherwise, since  is a tree, there is a unique simple path in  between  and .  This path together with  forms a cycle in .  On that cycle pick any edge 

that also crosses the cut  where  is the vertex‐set of the component of  containing  (and  lies in  because  did not create a cycle when added to ).  
Since  was the minimum‐weight edge crossing that cut (all lighter edges were either already rejected because they would form cycles, or not yet considered), we have

Define

Then:

<br>
 is still a spanning tree (removing  breaks the unique cycle created by adding ).  

<br>
Its total weight

so  is also minimum‐weight.

<br>
By construction .



<br>Thus in both cases there exists an MST containing the updated .  This completes the induction.<br>When Kruskal’s algorithm terminates it has added  edges without ever forming a cycle, so  is a spanning tree.  By the invariant,  is contained in some MST at each step, and in particular the final  itself has weight<br><br>Therefore Kruskal’s algorithm correctly computes a minimum‐spanning tree. <br><br>Prim’s algorithm grows a single tree, starting from an arbitrary root  and repeatedly adding the cheapest edge that connects the current tree to a new vertex. Implementing the “best outgoing edge” selection with a binary (or Fibonacci) heap yields the same  bound (or  with Fibonacci heaps).<br>function Prim(G,r):
    for each v in V:
        key[v] ← ∞
        π[v]   ← NIL
    key[r] ← 0
    Q ← make‐min‐heap(V, key)
    while Q not empty:
        u ← ExtractMin(Q)
        for each neighbor v of u:
            if v in Q and w(u,v) &lt; key[v]:
                π[v]   ← u
                key[v] ← w(u,v)
                DecreaseKey(Q, v, key[v])
    return {(π[v], v) : v ≠ r}
<br>Here key[v] maintains the weight of the lightest edge connecting  to the evolving tree, and π[v] records its parent in the final MST. Each vertex is extracted once ( extracts at  each) and each edge triggers at most one DecreaseKey ( at ), for total<br><br>Correctness Proof<br>
Let  be a connected, weighted undirected graph.  Prim’s algorithm grows a tree  on a vertex set , starting from an arbitrary root , by repeatedly adding the minimum‐weight edge  that crosses the cut .  We show that when it has added  edges, the resulting tree  is a minimum‐spanning tree (MST).<br>Invariant. After  iterations there exists some MST  of  such that .<br>Base case ().  Initially  and .  Any MST  contains the empty set of edges, so the invariant holds.<br>Inductive step.  Suppose after  steps we have  for some MST .  Let  be the minimum‐weight edge crossing the cut , with , .  <br>If  already, then setting  shows , preserving the invariant.<br>Otherwise  contains a unique simple path from  to , and that path includes exactly one edge  crossing the same cut.  Since  is the minimum‐weight crossing edge,  <br><br>Form the tree  <br><br>Removing  breaks the unique cycle created by adding , so  is a spanning tree, and  <br><br>making  also minimum‐weight.  Moreover , so the invariant holds for .<br>When the algorithm terminates with  edges,  is acyclic and spans , hence is a tree; by the invariant it must be an MST.  <br><br>Dijkstra’s algorithm solves the single‐source shortest‐path problem on a directed or undirected graph with nonnegative edge weights.  Given a weighted graph  and a source vertex , it computes for each  the length<br><br>where the minimum is over all paths  from  to .  The key requirement is  for every edge .<br>Dijkstra published the algorithm in 1959; its elegance comes from a simple greedy idea augmented by a priority queue to pick the “closest” unreached vertex at each step.<br>function Dijkstra(G, w, s):
    for each v in V:
        d[v] ← ∞
        π[v] ← NIL
    d[s] ← 0

    Q ← a min‐priority queue of all v∈V keyed by d[v]

    while Q not empty:
        u ← ExtractMin(Q)           # the unreached vertex with smallest d[u]
        for each edge (u,v) in E:
            alt ← d[u] + w(u,v)
            if alt &lt; d[v]:
                d[v] ← alt
                π[v] ← u
                DecreaseKey(Q, v, alt)
    return (d, π)
<br>When implemented with a binary heap, each of the  extractions costs , and each of the  edge‐relaxations may trigger a DecreaseKey also in , giving overall<br><br>If one uses a Fibonacci heap, DecreaseKey becomes amortized , yielding<br>]]></description><link>ch05-graphs.html</link><guid isPermaLink="false">CH05-Graphs.md</guid><pubDate>Mon, 16 Jun 2025 18:42:28 GMT</pubDate><enclosure url="assets/pasted-image-20250610140501.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;assets/pasted-image-20250610140501.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[CH06-Trees]]></title><description><![CDATA[ 
 <br><br>A tree is, at its simplest, an undirected graph (<a class="internal-link" data-href="CH05-Graphs.md" href="ch05-graphs.html" target="_self" rel="noopener nofollow">Graphs</a>)  that is both connected and acyclic.  Equivalently, it satisfies any of the following equivalent conditions:<br><br>together with connectedness; or, there is exactly one simple path between every pair of vertices.<br>When we want to work with a hierarchy or genealogy, we pick out a distinguished vertex , called the root, and regard  as a rooted tree.  In a rooted tree each edge is implicitly oriented away from the root: if  and  lies on the unique path from  to , we call  the parent of  and  a child of .  Thus every vertex except  has exactly one parent, yielding a function <br><br>The depth of a node  is the number of edges on the path from  to , and the height of the tree is<br><br>Nodes with no children are called leaves, and those with at least one child are internal nodes.<br>If, in addition, we impose a left‐to‐right ordering on each sibling set, we obtain an ordered (or plane) tree, where each node  carries an ordered list of its children.  A special case is the -ary tree, in which every node has at most  children labeled (for example) “first,” “second,” …, “th.”<br>When  is viewed as a forest, it is simply an acyclic graph that may be disconnected—equivalently a disjoint union of trees.  <br><img alt="Pasted image 20250610213006.png" src="assets/pasted-image-20250610213006.png"><br>
<a data-tooltip-position="top" aria-label="https://condor.depaul.edu/ichu/csc416/notes/notes4/tree.htm" rel="noopener nofollow" class="external-link" href="https://condor.depaul.edu/ichu/csc416/notes/notes4/tree.htm" target="_blank">Source</a><br><br>To process every node of a tree exactly once we use traversals, which produce a linear ordering of the nodes. <br><br>Depth-first traversals explore as far down one branch before backtracking. On a binary tree they come in three flavors:<br>
<br>Preorder ()<br>
Visit the current node before its subtrees.
<br>Inorder  ()<br>
Visit the left subtree, then the node, then the right subtree (only defined for binary trees).
<br>Postorder()<br>
Visit subtrees before the node itself.
<br>For a binary‐tree node type  <br>class Node:
    def __init__(self, value, left=None, right=None):
        self.value = value
        self.left = left
        self.right = right
<br>the recursive code is:<br>def preorder(node, output):
    if node is None:
        return
    output.append(node.value)
    preorder(node.left, output)
    preorder(node.right, output)

def inorder(node, output):
    if node is None:
        return
    inorder(node.left, output)
    output.append(node.value)
    inorder(node.right, output)

def postorder(node, output):
    if node is None:
        return
    postorder(node.left, output)
    postorder(node.right, output)
    output.append(node.value)
<br>Each of these runs in  time and uses  auxiliary space for the call stack, where  is the tree height. Iterative versions replace the system stack with an explicit stack data structure.<br><br>Breadth-first (or level-order) traversal visits nodes level by level, from the root down. It uses a queue:<br>from collections import deque

def level_order(root, output):
    if root is None:
        return
    q = deque([root])
    while q:
        node = q.popleft()
        output.append(node.value)
        if node.left:
            q.append(node.left)
        if node.right:
            q.append(node.right)
<br>On a binary tree this enqueues node.left then node.right. The running time is , and the maximum queue size is the maximum number of nodes at any single depth (the tree’s width), which in the worst case can be  but is often much smaller (e.g.  for a full binary tree of height ).<br><br>A binary tree over a set of keys  is defined inductively by the grammar<br><br>where  is the key at the root, and  are (possibly empty) left and right subtrees.  Equivalently, a binary tree is a rooted tree in which every vertex has at most two children, distinguished as “left” and “right.”<br>
<br>
The size of a binary tree , denoted , is the total number of nodes (non‐empty constructors) it contains.

<br>
The height  is the length of the longest root‐to‐leaf path, with the convention  and


<br>
Nodes with no children are leaves; those with one or two children are internal.

<br>A binary search tree (BST) is a binary tree whose keys come from a totally ordered set  and that satisfies the BST invariant at every node:<br>
If a node has key , then every key in its left subtree is strictly less than , and every key in its right subtree is strictly greater than .
<br>Formally, for every subtree ,<br><br>where  denotes the set of all keys stored in  (with the understanding that  and ).<br>Because of this invariant, an in‐order traversal of a BST<br>  traverse(L); visit(k); traverse(R);
<br>visits the keys in ascending order. This property underlies search, insertion, and deletion operations: to locate a key  in , one compares  to the root key  and then recurses into either  or  depending on whether  or .<br>
<br>In the best and average case (for “random” insertions), a BST with  nodes has height , giving  search time.
<br>In the worst case—when the tree is degenerate (a path)—the height is  and search degrades to .    
<br><br>Once you have a binary search tree  over a totally ordered set , the two fundamental update operations—insertion and deletion—both run in time proportional to the height of the tree, .<br><br>To insert a key  into  (assuming no duplicates), we descend from the root, comparing  to each node’s key, until we reach a null subtree and replace it with a new leaf.<br>def insert(T, x):
    if T is None:
        return Node(x)
    if x &lt; T.key:
        T.left = insert(T.left, x)
    elif x &gt; T.key:
        T.right = insert(T.right, x)
    return T
<br>
<br>Each recursive call moves one level down, so the cost satisfies
<br><br>where .<br>
<br>Hence insertion takes  time. 
<br>If  is balanced so that  for , insertion is ; in the worst (degenerate) case  and it degrades to .<br><br>To delete a key , we first locate the node holding  (or conclude it’s not present), then consider three cases:<br>
<br>Leaf: if the node has no children, replace it with .
<br>One child: if exactly one of  is nonempty, splice out the node by returning its nonempty child.
<br>Two children: replace the node’s key with its in‐order predecessor (maximum in the left subtree) or in‐order successor (minimum in the right subtree), then delete that predecessor/successor from the corresponding subtree.
<br>def _max_node(T):
    while T.right:
        T = T.right
    return T

def delete(T, x):
    if T is None:
        return None
    if x &lt; T.key:
        T.left = delete(T.left, x)
    elif x &gt; T.key:
        T.right = delete(T.right, x)
    else:
        if T.left is None:
            return T.right
        if T.right is None:
            return T.left
        y = _max_node(T.left)
        T.key = y.key
        T.left = delete(T.left, y.key)
    return T
<br>
<br>Locating  costs , and splicing or recursive delete in case 3 also costs .
<br>Thus deletion is  overall.
<br><br>A -ary tree is a rooted tree in which each node has at most  ordered children.  We write a node as  <br><br>where  is its value and each  is either a subtree or the empty tree .<br>In the special case of a full -ary tree of height , every internal node has exactly  children and all leaves lie at depth .  Such a tree has<br><br>total nodes, and its height in terms of  is<br><br>A complete -ary tree is filled level by level, left to right, so that every level except possibly the last is full, and on the last level nodes occupy the leftmost positions.  Complete -ary trees admit a very efficient array representation: if we index nodes from  to , then the -th node’s children (when present) live at indices<br><br>and its parent (for ) sits at<br><br>This indexing underlies the classic -ary heap data structure (a generalisation of the binary heap to ), giving  time for  and , while trade‐offs between branching factor and per‐node cost are tuned via .<br>More generally, a -ary search tree stores up to  keys in each node and has  subtrees partitioning the key space.  B-trees of order  are precisely balanced -ary search trees with additional invariants ensuring all leaves remain at the same depth and each internal node (except the root) has between  and  children.  Their height is<br><br><br><br>By definition a binary heap of size  is a rooted tree with exactly  nodes that satisfies:<br>
<br>Completeness: all levels except possibly the last are perfectly full; on the last level, nodes occupy the leftmost positions.  
<br>Heap‐order: for every node  with key , and each child  of  with key , we have


<br>Completeness implies the tree’s height satisfies<br><br>so any root‐to‐leaf path has length .<br><br>A complete binary tree can be stored in an array A[0…n−1] with no wasted slots.  We number the nodes in breadth‐first order:<br>
<br>Root   
<br>If a node is at index , then  

provided those indices are .  Conversely, for   


<br>This arithmetic mapping enforces completeness automatically: inserting a new element appends it at A[n], and deleting the root replaces A[0] with the last element before shrinking.<br><br>Assume the following max-heap:<br>class MaxHeap:
    def __init__(self):
        self.A = []
    def parent(self, i):
        return (i - 1) // 2
    def left(self, i):
        return 2 * i + 1
    def right(self, i):
        return 2 * i + 2
<br>To restore heap‐order after insertion or removal we percolate a single out‐of‐place element up or down the tree.<br>Insert a key : append  at A[n], then “sift‐up”. Each swap climbs one level; since at most  levels exist, insertion is .<br>    def insert(self, x):
        self.A.append(x)
        i = len(self.A) - 1
        while i &gt; 0 and self.A[self.parent(i)] &lt; self.A[i]:
            p = self.parent(i)
            self.A[i], self.A[p] = self.A[p], self.A[i]
            i = p
<br>Extract‐max (in a max‐heap): remove the root<br>
<br>Save max := A[0].
<br>Move A[n−1] to A[0], decrement .   
<br>“Sift‐down” from :
<br>    def extract_max(self):
        n = len(self.A)
        if n == 0:
            raise IndexError("extract_max from empty heap")
        maximum = self.A[0]
        last = self.A.pop()
        if n &gt; 1:
            self.A[0] = last
            i = 0
            n -= 1
            while self.left(i) &lt; n:
                l = self.left(i)
                r = self.right(i)
                j = r if r &lt; n and self.A[r] &gt; self.A[l] else l
                if self.A[j] &gt; self.A[i]:
                    self.A[i], self.A[j] = self.A[j], self.A[i]
                    i = j
                else:
                    break
        return maximum
<br>Swapping downward also takes at most  steps.<br><br>Surprisingly, turning an arbitrary array into a heap takes  time, not . The heapify algorithm runs sift‐down on each non‐leaf node in reverse breadth‐first order:<br>for i = ⌊n/2⌋−1 downto 0 do
  sift-down(A, i, n)
end
<br>Nodes at depth  from the root can sift down at most  levels. Summing the work yields<br><br>since . For example: <br>def heapify(arr, n, i):
    while True:
        largest = i
        left = 2*i + 1
        right = 2*i + 2
        if left &lt; n and arr[left] &gt; arr[largest]:
            largest = left
        if right &lt; n and arr[right] &gt; arr[largest]:
            largest = right
        if largest == i:
            break
        arr[i], arr[largest] = arr[largest], arr[i]
        i = largest

def build_max_heap(arr):
    n = len(arr)
    for i in range(n//2 - 1, -1, -1):
        heapify(arr, n, i)
<br><br>Heap operations enable in‐place sorting in  time with no extra memory:<br>
<br>Heapify the array in .
<br>Repeat  times: swap A[0] (max) with A[n−1], decrement , and sift‐down the new root.
<br>After each extract, the suffix A[n…end] is sorted in ascending order.<br>def heap_sort(arr):
    n = len(arr)
    build_max_heap(arr)
    for i in range(n-1, 0, -1):
        arr[0], arr[i] = arr[i], arr[0]
        heapify(arr, i, 0)
    return arr
<br><br>A -ary heap generalises the binary heap by letting each internal node have up to  children instead of two.  It retains the two classical heap invariants:<br>
<br>Shape: the tree is a complete -ary tree—every level except the last is full, and the last is filled left-to-right.  
<br>Heap order: for a max-heap, every parent’s key is  each of its children’s keys (reverse for min-heap).
<br>Because completeness pins down the shape, a -ary heap of  elements has height<br><br><br>Store the heap in an array A[0…n−1] so that for each index :<br>
<br>Children occupy indices


<br>Parent of node  sits at


<br>This implicit structure requires no pointers, maximises spatial locality, and makes traversals extremely cache-friendly when  is tuned to match cache‐line or disk‐block size.<br><br>def push(A, n, x, d):
    A.append(x)
    i = n
    while i &gt; 0:
        p = (i - 1) // d
        if A[p] &lt; A[i]:
            A[p], A[i] = A[i], A[p]
            i = p
        else:
            break
    return n + 1
<br>Each iteration moves one level up; the worst-case number of swaps is .<br><br>def pop(A, n, d):
    if n == 0:
        raise IndexError("pop from empty heap")
    maximum = A[0]
    A[0] = A[n-1]
    A.pop()
    n -= 1
    i = 0
    while True:
        best = i
        for k in range(1, d+1):
            c = d*i + k
            if c &lt; n and A[c] &gt; A[best]:
                best = c
        if best == i:
            break
        A[i], A[best] = A[best], A[i]
        i = best
    return maximum, n
<br>At each of  levels we scan up to  children for the maximum, so extract-max costs<br><br><br>To heapify an arbitrary array A[0…n−1], perform sift-down on every non-leaf index from  down to . The total work is<br><br>Since there are at most  nodes at depth , the sum telescopes to :<br><br>because  converges for .<br><br>Suppose you need a priority queue on an embedded system where cache locality matters.  A 4-ary heap (each node has up to four children) can reduce height compared to a binary heap, trading off a slightly more expensive per-node “sift” for fewer levels.<br><br>We store the heap in a zero-based array A[0…n−1].  For a 4-ary heap the children of node at index  are at<br><br>and the parent of node  is at<br><br>This yields a height<br><br>so operations cost  but with fewer levels than a binary heap.<br><br>To insert a key x:<br>
<br>Append x at A[n]; increment n.  
<br>“Sift up” from index i = n-1:<br>
Repeat while i &gt; 0 and A[i] &lt; A[parent(i)]:
<br>def push_min(A, n, x):
    A.append(x)
    n += 1
    i = n - 1
    while i &gt; 0:
        p = (i - 1) // 4
        if A[i] &lt; A[p]:
            A[i], A[p] = A[p], A[i]
            i = p
        else:
            break
    return n
<br>Each swap moves you one level up; in the worst case you move  times, so insertion is .<br><br>To remove the minimum (root A[0]):<br>
<br>Replace A[0] with A[n-1]; decrement n.
<br>“Sift down” from i = 0:
<br>def pop_min(A, n):
    if n == 0:
        raise IndexError("pop from empty heap")
    minimum = A[0]
    A[0] = A[n - 1]
    A.pop()
    n -= 1
    i = 0
    while True:
        best = i
        for j in range(1, 5):
            c = 4 * i + j
            if c &lt; n and A[c] &lt; A[best]:
                best = c
        if best == i:
            break
        A[i], A[best] = A[best], A[i]
        i = best
    return minimum, n
<br>Each loop moves you one level down at cost  per level, so extraction is also .<br><br>Start with an empty heap; insert the sequence<br>[7, 3, 10, 1, 5, 2, 8, 4, 6]
<br>Insert 7 → [7]<br>
Insert 3 → [3,7] (sift up swaps 3↔7)<br>
Insert 10 → [3,7,10] (no sift)<br>
Insert 1 → [1,3,10,7] (1→index 3, parent=0, swap 1↔3, then 1↔root)<br>
Insert 5 → [1,3,5,7,10] (5→index 4, parent=0, no swap)<br>
Insert 2 → [1,2,5,7,10,3] (2→5, parent=1, swap)<br>
Insert 8 → [1,2,5,7,10,3,8]<br>
Insert 4 → [1,2,4,7,10,3,8,5] (4→7, parent=1, swap)<br>
Insert 6 → [1,2,4,6,10,3,8,5,7]<br>After these nine insertions the array is<br>Index:  0 1 2 3  4 5 6 7 8
Value: [1,2,4,6,10,3,8,5,7]
<br>and the implicit 4-ary tree has height .<br>Because each sift-up or sift-down step does up to  comparisons (one per child) instead of  in a binary heap, the per-level cost is higher, but the heap is roughly half as tall:<br>
<br>Binary heap height  levels, 2 comparisons per level.
<br>4-ary heap height  levels, 4 comparisons per level.<br>

<br>Total comparisons per operation:<br><br>In practice the 4-ary heap often wins due to better cache behavior: its nodes are more compact, and sifts touch fewer distinct cache lines.<br>Because the 4 children of node  are contiguous in memory, linear scans over them are cache-friendly. In low-level languages like C one might write:<br>size_t parent(size_t i) { return (i - 1) &gt;&gt; 2; }

void sift_down(int A[], size_t n) {
    size_t i = 0;
    while (1) {
        size_t best = i;
        for (size_t j = 1; j &lt;= 4; ++j) {
            size_t c = 4*i + j;
            if (c &lt; n &amp;&amp; A[c] &lt; A[best]) best = c;
        }
        if (best == i) break;
        int tmp = A[i]; A[i] = A[best]; A[best] = tmp;
        i = best;
    }
}
<br><br>A segment tree is a binary‐tree data structure built on an underlying array  that supports range queries and point or range updates in  time.  Conceptually, you imagine a full binary tree whose root covers the interval , and each internal node at index  covers some interval , storing a summary—such as the sum, minimum, or greatest common divisor—of the subarray .<br><br>Range queries and point or range updates are the two fundamental operations supported by segment‐tree–style data structures on an underlying array .  Formally, fix a binary combine operation  (e.g. , , ) with identity element , and an update operation  (e.g.\ assignment, increment) on individual array entries, together with a way to lift it over intervals.<br>
<br>
A range query on  returns

i.e.\ the –aggregate of all elements in the subarray .  

<br>
A point update at position  modifies a single entry, either by

<br>assignment: 


<br>increment (or more generally –update):




<br>
A range update over  applies the same update to every element in the interval:


<br><br>In the above, the two key operations—combine and update—must satisfy certain algebraic properties to make segment‐tree algorithms correct and efficient:<br><br>
<br>A combine operation  

 takes two values of type  (e.g.\ integers, reals, pairs) and merges them.  We require:

<br>Associativity:  


<br>Identity element  such that  

 Together,  is a monoid.<br>
Common examples:


<br>Range‐sum: , , .  
<br>Range‐minimum: , , .  
<br>Range‐gcd: , , .


<br>If  is also commutative (), some variants (e.g.\ Fenwick trees) become possible, but segment trees work with any monoid.<br><br>
<br>An update operation  

  applies an update of type  (e.g.\ a delta value, an assignment tag) to a single element of .  To support lazy propagation, we also require:

<br>A neutral update  with  


<br>Update composition  

 such that applying two updates in sequence equals a single composed update:



<br>Distribution over combine:  




<br>These conditions make  a monoid of updates that “commutes” with the data‐monoid .  Common instances:<br><br>
<br>Point‐assign + range‐sum: each update overwrites a single element to , and combining two assignments picks the later one.  
<br>Point‐increment + range‐sum: updates add a delta; composition accumulates deltas.  
<br>Range‐assign + range‐min: lazy‐propagate “set to ” over an interval; newer assignments override older ones.
<br><br>The tree is defined recursively:  <br>
<br>The root node  covers  


<br>If node  covers  and , let  

Then its left child at index  covers , and its right child at index  covers .  
<br>If , node  is a leaf storing the single element .
<br>Assume the following constructor:<br>class SegmentTree:
    def __init__(self, A, combine, identity):
        self.n = len(A)
        self.combine = combine
        self.identity = identity
        self.seg = [identity] * (4 * self.n)
        self._build(1, 0, self.n - 1, A)
<br>In an array‐based implementation you typically allocate an array seg[1..4*n], then:<br>    def _build(self, i, L, R, A):
        if L == R:
            self.seg[i] = A[L]
        else:
            M = (L + R) // 2
            self._build(2*i,     L,   M, A)
            self._build(2*i+1, M+1, R, A)
            self.seg[i] = self.combine(self.seg[2*i], self.seg[2*i+1])
<br>Here combine(x,y) is the associative operation you need (e.g.\ $x+y$ for range sum, min(x,y) for range minimum, etc.). Building the entire tree takes<br><br>since the tree has  nodes.<br><br>To query the aggregate over an arbitrary subinterval , you recurse only into those children whose intervals intersect :<br>    def query(self, ql, qr):
        return self._query(1, 0, self.n - 1, ql, qr)

    def _query(self, i, L, R, ql, qr):
        if qr &lt; L or R &lt; ql:
            return self.identity
        if ql &lt;= L and R &lt;= qr:
            return self.seg[i]
        M = (L + R) // 2
        left  = self._query(2*i,     L,   M, ql, qr)
        right = self._query(2*i+1, M+1, R, ql, qr)
        return self.combine(left, right)
<br>Each level of recursion splits the interval in two, and you visit at most two nodes per level, so query runs in .<br>To update a single element , you descend to the leaf covering , set seg[i]=v, then propagate the change upward:<br>    def update(self, p, v):
        self._update(1, 0, self.n - 1, p, v)

    def _update(self, i, L, R, p, v):
        if L == R:
            self.seg[i] = v
        else:
            M = (L + R) // 2
            if p &lt;= M:
                self._update(2*i,     L,   M, p, v)
            else:
                self._update(2*i+1, M+1, R, p, v)
            self.seg[i] = self.combine(self.seg[2*i], self.seg[2*i+1])
<br>Again this touches one node per level, giving  time.<br><br>A lazy segment tree can be defined as: <br>class LazySegmentTree:
    def __init__(self, A, combine, apply, combine_lazy, identity, identity_lazy):
        self.n = len(A)
        self.combine = combine
        self.apply = apply
        self.combine_lazy = combine_lazy
        self.identity = identity
        self.identity_lazy = identity_lazy
        self.seg = [identity] * (4 * self.n)
        self.lazy = [identity_lazy] * (4 * self.n)
        self._build(1, 0, self.n - 1, A)
<br>For range updates (e.g. “add  to every element in ”), a naive segment tree would require  per update. By storing an auxiliary lazy array lazy[1..4*n] that accumulates pending updates, you can achieve both range updates and range queries in  amortised time:<br>
<br>Each node i carries a lazy[i] value meaning “this entire segment needs to be incremented by lazy[i],” applied to seg[i] when you visit it.
<br>When you descend, you push the pending update to the children.
<br>Both query and update begin by calling push(i,L,R) before recursing, ensuring the segment’s value is up-to-date.
<br>    def _build(self, i, L, R, A):
        if L == R:
            self.seg[i] = A[L]
        else:
            M = (L + R) // 2
            self._build(2*i,   L,   M, A)
            self._build(2*i+1, M+1, R, A)
            self.seg[i] = self.combine(self.seg[2*i], self.seg[2*i+1])

    def _push(self, i, L, R):
        if self.lazy[i] != self.identity_lazy:
            self.seg[i] = self.apply(self.seg[i], self.lazy[i], R - L + 1)
            if L &lt; R:
                self.lazy[2*i]   = self.combine_lazy(self.lazy[2*i], self.lazy[i])
                self.lazy[2*i+1] = self.combine_lazy(self.lazy[2*i+1], self.lazy[i])
            self.lazy[i] = self.identity_lazy

    def update_range(self, ql, qr, v):
        self._update_range(1, 0, self.n - 1, ql, qr, v)

    def _update_range(self, i, L, R, ql, qr, v):
        self._push(i, L, R)
        if qr &lt; L or R &lt; ql:
            return
        if ql &lt;= L and R &lt;= qr:
            self.lazy[i] = self.combine_lazy(self.lazy[i], v)
            self._push(i, L, R)
        else:
            M = (L + R) // 2
            self._update_range(2*i,   L,   M, ql, qr, v)
            self._update_range(2*i+1, M+1, R, ql, qr, v)
            self.seg[i] = self.combine(self.seg[2*i], self.seg[2*i+1])

    def query_range(self, ql, qr):
        return self._query_range(1, 0, self.n - 1, ql, qr)

    def _query_range(self, i, L, R, ql, qr):
        self._push(i, L, R)
        if qr &lt; L or R &lt; ql:
            return self.identity
        if ql &lt;= L and R &lt;= qr:
            return self.seg[i]
        M = (L + R) // 2
        left  = self._query_range(2*i,   L,   M, ql, qr)
        right = self._query_range(2*i+1, M+1, R, ql, qr)
        return self.combine(left, right)
<br><br>Imagine you’re building a real‐time dashboard for daily sales over a month.  You maintain an array  <br><br>of length , where  is the sales on day .  You must support two operations:<br>
<br>Add a promotional bonus of  to every day in an interval :<br>
  
<br>Query the total sales in any interval :<br>

<br>And do both in  time. <br><br>We build a complete binary tree over .  The root covers .  At each node covering  we store:<br>
<br>sum: the current value of   
<br>add: a lazy tag meaning “every element in  still needs to be incremented by this amount”
<br>Leaf nodes at  store a single element sum=A[L] and add=0.  Internal nodes combine:<br><br><br>#include &lt;bits/stdc++.h&gt;
using namespace std;

class SegTree {
private:
    int n;
    vector&lt;long long&gt; sum, lazy;

    // Build tree from initial array A
    void build(int i, int L, int R, const vector&lt;long long&gt;&amp; A) {
        if (L == R) {
            sum[i] = A[L];
        } else {
            int M = (L + R) &gt;&gt; 1;
            build(2*i,     L,   M, A);
            build(2*i + 1, M+1, R, A);
            sum[i] = sum[2*i] + sum[2*i + 1];
        }
    }

    // Push pending updates at node i down to children
    void push(int i, int L, int R) {
        if (lazy[i] != 0) {
            long long v = lazy[i];
            sum[i] += v * (R - L + 1);
            if (L &lt; R) {
                lazy[2*i]     += v;
                lazy[2*i + 1] += v;
            }
            lazy[i] = 0;
        }
    }

    // Internal range‐add
    void update(int i, int L, int R, int ql, int qr, long long v) {
        push(i, L, R);
        if (qr &lt; L || R &lt; ql) return;            // no overlap
        if (ql &lt;= L &amp;&amp; R &lt;= qr) {               // full cover
            lazy[i] += v;
            push(i, L, R);
            return;
        }
        int M = (L + R) &gt;&gt; 1;
        update(2*i,     L,   M, ql, qr, v);
        update(2*i + 1, M+1, R, ql, qr, v);
        sum[i] = sum[2*i] + sum[2*i + 1];
    }

    // Internal range‐sum query
    long long query(int i, int L, int R, int ql, int qr) {
        push(i, L, R);
        if (qr &lt; L || R &lt; ql) return 0;          // identity = 0
        if (ql &lt;= L &amp;&amp; R &lt;= qr) return sum[i];
        int M = (L + R) &gt;&gt; 1;
        return query(2*i,     L,   M, ql, qr)
             + query(2*i + 1, M+1, R, ql, qr);
    }

public:
    // Constructor: pass size and initial array
    SegTree(int _n, const vector&lt;long long&gt;&amp; A) {
        n = _n;
        sum.assign(4*n,  0);
        lazy.assign(4*n, 0);
        build(1, 0, n-1, A);
    }

    // Public wrappers
    void update(int ql, int qr, long long v) {
        update(1, 0, n-1, ql, qr, v);
    }

    long long query(int ql, int qr) {
        return query(1, 0, n-1, ql, qr);
    }
};

// Example usage
int main() {
    ios::sync_with_stdio(false);
    cin.tie(nullptr);

    // Sample array
    vector&lt;long long&gt; A = {1, 2, 3, 4, 5};
    SegTree st((int)A.size(), A);

    // Query sum of A[1..3]
    cout &lt;&lt; "Sum [1..3] = " &lt;&lt; st.query(1, 3) &lt;&lt; "\n";  // → 2+3+4 = 9

    // Add +5 to A[2..4]
    st.update(2, 4, 5);

    // Now A = {1,2,8,9,10}; query sum of A[3..4]
    cout &lt;&lt; "Sum [3..4] = " &lt;&lt; st.query(3, 4) &lt;&lt; "\n";  // → 9+10 = 19

    return 0;
}
<br><br>Let initially<br>
<br>
<br>Build in : leaves get their , internal sum = child sums.
<br>Update add  to days  (update(2,5,10)):

<br>Start at root , partially overlap → recurse.
<br>At node covering , still partial → recurse to children.
<br>Eventually at node exactly , we set lazy+=10 and push:

<br>increase its sum by ,
<br>mark its two children’s lazy+=10 (deferred).


<br>On unwinding, ancestors recompute their sum = left.sum + right.sum.


<br>Query sum on  (query(3,7)):

<br>Descend, pushing lazy tags so each visited node has correct sum.
<br>Combine contributions from nodes covering subranges of .
<br>Total cost .


<br>After the update, the new  in  is , and querying  returns<br><br><br>A Fenwick tree, or Binary Indexed Tree (BIT), is a space- and time-efficient structure for maintaining a dynamic array  under point updates and prefix‐sum queries, both in  time and  space.  It was introduced by Peter Fenwick in 1994 as a simpler, lower-constant alternative to segment trees.<br>class FenwickTree:
    def __init__(self, n):
        self.n = n
        self.BIT = [0] * (n + 1)

    def build(self, A):
        for i, v in enumerate(A, start=1):
            self.update(i, v)
<br><br>At the heart of the BIT is the function<br><br>which extracts the least significant ‐bit of the binary representation of .  Every index  can thus be viewed as covering the interval<br><br>in the original array.  We store in BIT[i] the cumulative sum of exactly that block:<br><br>Because these blocks partition every prefix  into at most  disjoint suffix-aligned intervals, prefix sums and updates reduce to repeatedly climbing or descending these blocks.<br><br>To add a value  to , we must update every block that contains .  Starting at , we climb to the next covering block by<br>    def update(self, p, delta):
        i = p
        while i &lt;= self.n:
            self.BIT[i] += delta
            i += i &amp; -i
<br>Each increment clears the lowest set bit of the “complement” of  in effect, so the number of iterations equals the number of -bits in the binary expansion of indices from  up to , which is  in the worst case.<br><br>To compute<br><br>we accumulate the pre-computed blocks by walking “down”:<br>    def query(self, p):
        s = 0
        i = p
        while i &gt; 0:
            s += self.BIT[i]
            i -= i &amp; -i
        return s
<br>Each step removes the lowest set bit from , so we perform at most as many additions as there are bits in , again .<br><br>A 2D Fenwick tree (or 2D BIT) generalises the 1D BIT to maintain an  array  under point‐updates and axis‐aligned rectangle‐sum queries in <br><br>time, using only  space.<br>Fenwick’s insight is that each entry  stores the sum of a lowbit-aligned submatrix of :<br><br>where<br><br>extracts the least significant ‐bit of .<br>class Fenwick2D:
    def __init__(self, n, m):
        self.n = n
        self.m = m
        self.BIT = [[0] * (m + 1) for _ in range(n + 1)]

    def _lowbit(self, x):
        return x &amp; -x
<br><br>To add  to , we must update every BIT cell whose submatrix covers :<br>    def update(self, p, q, delta):
        i = p
        while i &lt;= self.n:
            j = q
            while j &lt;= self.m:
                self.BIT[i][j] += delta
                j += self._lowbit(j)
            i += self._lowbit(i)
<br>
<br>Each outer iteration increases  by , clearing its lowest set bit of the form .
<br>Since an ‐bit integer has at most  ones, the outer loop runs O(log⁡n)O(\log n) times.
<br>Similarly, each inner loop runs  steps.
<br>Total cost per update: .
<br><br>To compute<br>
we accumulate those pre‐summed blocks whose rectangles exactly tile :<br>    def range_sum(self, x1, y1, x2, y2):
        return (
            self.query(x2, y2)
            - self.query(x1 - 1, y2)
            - self.query(x2, y1 - 1)
            + self.query(x1 - 1, y1 - 1)
        )
        
    def query(self, p, q):
        result = 0
        i = p
        while i &gt; 0:
            j = q
            while j &gt; 0:
                result += self.BIT[i][j]
                j -= self._lowbit(j)
            i -= self._lowbit(i)
        return result
<br>Each subtraction clears one ‐bit of  or , so the nested loops again cost .<br><br>For an arbitrary rectangle , use<br><br>invoking four prefix queries in  total.<br><br>Suppose you need to maintain a multiset of integers in the range , supporting three operations on the fly:<br>
<br>Insert an element .
<br>Delete one occurrence of  (if present).
<br>Find by order: report the -th smallest element in the multiset.
<br><br>We maintain an array BIT[1..N], initially all zeros. At any time<br><br>where  is the current frequency of element  in the multiset. Hence<br>
<br>prefix_sum =  is computed by
<br>    int s = 0;
    for(int i = p; i &gt; 0; i -= i&amp;-i)
      s += BIT[i];
    return s;
<br>
<br>update adds  to :
<br>    for(int i = p; i &lt;= N; i += i&amp;-i)
      BIT[i] += Δ;
<br>Since each loop changes one bit of , both run in  steps.<br><br>We want the smallest  such that<br><br>We can do this by a binary-lifting trick over the Fenwick tree in :<br>// find smallest x with prefix_sum(x) &gt;= k
int find_by_order(int k) {
    int pos = 0;
    // Assume N &lt;= 2^LOG; pick LOG so that (1&lt;&lt;LOG) &gt;= N
    for(int pw = 1&lt;&lt;LOG; pw &gt; 0; pw &gt;&gt;= 1) {
        if(pos + pw &lt;= N &amp;&amp; BIT[pos + pw] &lt; k) {
            k -= BIT[pos + pw];
            pos += pw;
        }
    }
    return pos + 1;
}
<br>At each step we test whether jumping by pw stays below ; if so we subtract that block’s sum and move pos forward. After  rounds, pos+1 is the desired element.<br><br>#include &lt;bits/stdc++.h&gt;
using namespace std;

struct Fenwick {
    int N;
    vector&lt;int&gt; BIT;
    Fenwick(int _N): N(_N), BIT(N+1, 0) {}
    // add Δ (+1 for insert, -1 for delete) at position p
    void update(int p, int Δ) {
        for(int i = p; i &lt;= N; i += i &amp; -i)
            BIT[i] += Δ;
    }
    // sum of f[1..p]
    int prefix_sum(int p) {
        int s = 0;
        for(int i = p; i &gt; 0; i -= i &amp; -i)
            s += BIT[i];
        return s;
    }
    // find smallest x with prefix_sum(x) &gt;= k
    int find_by_order(int k) {
        int pos = 0;
        for(int pw = 1 &lt;&lt; (31 - __builtin_clz(N)); pw &gt; 0; pw &gt;&gt;= 1) {
            if(pos + pw &lt;= N &amp;&amp; BIT[pos + pw] &lt; k) {
                k -= BIT[pos + pw];
                pos += pw;
            }
        }
        return pos + 1;
    }
};

int main(){
    ios::sync_with_stdio(false);
    cin.tie(NULL);

    int N = 1000000;    // universe size
    Fenwick fw(N);

    int Q;              // number of operations
    cin &gt;&gt; Q;
    while(Q--){
        char op;
        int x;
        cin &gt;&gt; op &gt;&gt; x;
        if(op == 'I'){            // insert x
            fw.update(x, +1);
        } else if(op == 'D'){     // delete x
            if(fw.prefix_sum(x) - fw.prefix_sum(x-1) &gt; 0)
                fw.update(x, -1);
        } else if(op == 'K'){     // find k-th smallest
            if(x &lt; 1 || x &gt; fw.prefix_sum(N)){
                cout &lt;&lt; "invalid\n";
            } else {
                cout &lt;&lt; fw.find_by_order(x) &lt;&lt; "\n";
            }
        }
    }
    return 0;
}
<br>
<br>Insert (‘I x’): update(x, +1)
<br>Delete (‘D x’): only if there’s at least one x, do update(x, -1)
<br>Kth (‘K k’): find and print the th smallest, or “invalid”
<br><br>Let  be the string  terminated by a unique end-of-string symbol  such that  for every . A suffix tree for  is a rooted, directed tree  with the following properties:<br>
<br>Edge labeling<br>
Each edge is labeled with a non-empty substring of . The concatenation of edge labels on the path from the root to any node<br>
is a substring of .  
<br>No two edges out of a node share the same first character (so outgoing edges can be keyed by that character).
<br>Every suffix is present<br>
For each  there is a unique leaf whose path label is<br>

<br>Compressed<br>
Every internal node has at least two children; equivalently, no unary chain occurs (they are merged into one edge).
<br>Let  be the set of nodes and  the set of edges of . Because of compression,  <br>for any -character string.<br>class Node:
    def __init__(self, start=None, end=None):
        self.children = {}         # dict: char -&gt; Node
        self.suffix_link = None    # suffix link
        self.start = start         # edge start index
        self.end = end             # edge end index reference (mutable for leaves)

class SuffixTree:
    def __init__(self, text):
        self.text = text
        self.n = len(text)
        self.root = Node()
        self.root.suffix_link = self.root
        self.active_node = self.root
        self.active_edge = -1
        self.active_length = 0
        self.remaining = 0
        self.leaf_end = -1
        self.last_new_node = None
        self.build()
<br><br>Ukkonen processes the text  left-to-right. After phase  the algorithm maintains an implicit suffix tree for the prefix ; edges ending on the current rightmost character are left “open” and acquire their final label endpoint only when a later character forces a split or at the terminal phase .<br>Three invariants drive the procedure:<br>
<br>Implicit-tree invariant – every suffix of  is represented as a path whose edge labels are substrings of , but edges may end inside the input (using open ends).  
<br>End-extension property – when  arrives, all new suffixes end with that character, so only those suffixes may require repair.  
<br>Active point + suffix links – we resume each extension from where the previous one stopped, and if we split an edge we connect the new internal node to its suffix counterpart, allowing  jumps.
<br>   def _edge_length(self, node):
        return node.end[0] - node.start + 1

    def _walk_down(self, node):
        if self.active_length &gt;= self._edge_length(node):
            self.active_edge += self._edge_length(node)
            self.active_length -= self._edge_length(node)
            self.active_node = node
            return True
        return False

    def _extend(self, pos):
        self.leaf_end[0] = pos
        self.remaining += 1
        self.last_new_node = None
        while self.remaining &gt; 0:
            if self.active_length == 0:
                self.active_edge = pos
            ch = self.text[self.active_edge]
            if ch not in self.active_node.children:
                leaf = Node(pos, self.leaf_end)
                self.active_node.children[ch] = leaf
                if self.last_new_node:
                    self.last_new_node.suffix_link = self.active_node
                    self.last_new_node = None
            else:
                next_node = self.active_node.children[ch]
                if self._walk_down(next_node):
                    continue
                if self.text[next_node.start + self.active_length] == self.text[pos]:
                    self.active_length += 1
                    if self.last_new_node:
                        self.last_new_node.suffix_link = self.active_node
                        self.last_new_node = None
                    break
                split_end = next_node.start + self.active_length - 1
                split = Node(next_node.start, [split_end])
                self.active_node.children[ch] = split
                leaf = Node(pos, self.leaf_end)
                split.children[self.text[pos]] = leaf
                next_node.start += self.active_length
                split.children[self.text[next_node.start]] = next_node
                if self.last_new_node:
                    self.last_new_node.suffix_link = split
                self.last_new_node = split
                split.suffix_link = self.root
            self.remaining -= 1
            if self.active_node == self.root and self.active_length &gt; 0:
                self.active_length -= 1
                self.active_edge = pos - self.remaining + 1
            else:
                self.active_node = self.active_node.suffix_link or self.root

    def build(self):
        for i in range(self.n):
            self._extend(i)
<br><br><br>Once you have built the suffix tree for a text  (e.g.\ with Ukkonen’s algorithm), you can answer “How many times does a pattern  occur in ?” in  time by descending the tree and then reading a precomputed leaf‐count.<br><br>Augment each node  of the (explicit) suffix tree with<br><br>You compute this by a single post‐order DFS in  time and space:<br>    def compute_counts(self):
        def dfs(v):
            if not v.children:
                v.count = 1
            else:
                total = 0
                for child in v.children.values():
                    total += dfs(child)
                v.count = total
            return v.count
        dfs(self.root)
<br>After this, each internal node knows how many suffixes pass through it, i.e. how many occurrences of its path‐label appear in .<br><br>To count occurrences of , we simulate walking from the root along the characters of :<br>    def count_occurrences(self, P):
        v = self.root
        i, m = 0, len(P)
        while i &lt; m:
            c = P[i]
            if c not in v.children:
                return 0
            w = v.children[c]
            length = w.end[0] - w.start + 1
            segment = self.text[w.start:w.start+length]
            if P[i:i+length] != segment:
                return 0
            i += length
            v = w
        return v.count
<br>
<br>Each edge comparison does at most length character checks, but across the descent you compare exactly  characters total.
<br>You perform at most one get_edge and one dest lookup per edge, so the overall time is .
<br><br>Given a suffix tree built over the text  (with a unique terminal \$), the locate query—<br>
“Return all starting positions of the pattern  in ”
<br>—can be implemented in  time, where  is the number of occurrences.  <br><br>We follow exactly the characters of  from the root, walking edge by edge:<br>def find_locus(root, S, P):
    node = root
    i = 0
    while i &lt; len(P):
        c = P[i]
        if c not in node.children:
            return None, 0       # no such edge: pattern absent
        edge = node.children[c]
        length = edge.end - edge.start + 1
        # Match up to `length` characters on this edge
        j = 0
        while j &lt; length and i &lt; len(P):
            if S[edge.start + j] != P[i]:
                return None, 0   # mismatch: pattern absent
            i += 1
            j += 1
        if j &lt; length:
            # Pattern ended in the middle of this edge
            return edge.dest, 0  # we treat the dest as the locus
        # else: we consumed the entire edge, move to its dest
        node = edge.dest
    return node, 0
<br>
<br>We compare exactly  characters in total.
<br>We perform one dictionary lookup and at most one character‐by‐character scan per edge, so time .
<br><br>Once we have the locus node v, every leaf in its subtree corresponds to one occurrence starting at position leaf.pos. Two approaches:<br>
<br>DFS in :
<br>    def collect_leaves(v, out):
        if not v.children:
            out.append(v.leaf_pos)
            return
        for edge in v.children.values():
            collect_leaves(edge.dest, out)
    
    def locate(root, S, P):
        v, _ = find_locus(root, S, P)
        if v is None:
            return []      # no occurrences
        out = []
        collect_leaves(v, out)
        return sorted(out)  # optional if you need positions in order
<br>
<br>Precomputed leaf lists stored at each node during tree construction:
<br>    # After building the tree, run:
    def annotate_leaves(v):
        if not v.children:
            v.leaf_list = [v.leaf_pos]
        else:
            v.leaf_list = []
            for e in v.children.values():
                annotate_leaves(e.dest)
                v.leaf_list.extend(e.dest.leaf_list)
    
    # Then locate is trivial:
    def locate(root, S, P):
        v, _ = find_locus(root, S, P)
        return v.leaf_list[:] if v else []
<br>Storing leaf_list at each node costs  extra memory overall and gives  time without recursion at query time.<br><br>Let , and build its suffix tree. To locate :<br>
<br>Descend:

<br>From root follow edge ’a’ → match “a” ().
<br>Now from that node follow edge starting “na” → match “na” ().
<br>We reached node v exactly at the end of pattern, after matching 3 chars.


<br>Enumerate:

<br>The subtree at v has two leaves with leaf_pos=2 and leaf_pos=4.


<br>Hence locate returns [2,4], the correct starting indices of “ana” in “banana”.<br><br><br>In a rooted tree  with root , every node  has a unique simple path back to the root. We write  for the number of edges on that path, and say  is an ancestor of , written , whenever  lies on the path from  to . Given two nodes , their Lowest Common Ancestor is the deepest node that is an ancestor of both. Equivalently,<br><br>A naïve way to compute  without any preprocessing is to walk from  up to the root, marking each visited node in  time, and then walk from  upward until you first encounter a marked node. This uses only parent‐pointers and  time per query, where  is the height of the tree, but in the worst case  so each query can be linear.<br>To speed queries to , one can use binary lifting. We precompute an array  giving the -th ancestor of . Concretely, we set<br><br>Filling this table takes  time. To answer , first lift whichever of  is deeper until they are at equal depth—by examining the binary expansion of the depth difference and jumping in powers of two via . Then, if , we scan  from  down to , and whenever <br><br>we set<br><br>After this loop,  (or ) is the LCA. Each query thus takes  time.<br>For truly constant‐time queries one exploits the equivalence between LCA and a range‐minimum query (RMQ) on an Euler tour of the tree. Performing a DFS from  and recording each node whenever it is visited (and revisited upon backtracking) yields an Euler array  of length  together with a depth array . If  is the index of the first occurrence of  in , then<br><br>Building a linear‐time RMQ structure on  (e.g. Fischer–Heun) takes  time and answers each minimum‐query in , so each LCA query becomes  after  preprocessing.<br><br>Consider the rooted tree with root  and edges:<br><br>Depths from the root are<br><br>We will preprocess and answer the queries:<br>
<br>,
<br>,
<br>,
<br>.
<br># Binary lifting LCA implementation on the example tree

n = 9  # number of nodes
LOG = (n-1).bit_length()  # maximum power-of-two needed

# adjacency list
adj = [[] for _ in range(n+1)]
edges = [(1,2),(1,3),(2,4),(2,5),(3,6),(3,7),(6,8),(6,9)]
for u, v in edges:
    adj[u].append(v)
    adj[v].append(u)

# parent and depth arrays
parent = [0]*(n+1)
depth = [0]*(n+1)

def dfs(u, p):
    for v in adj[u]:
        if v == p:
            continue
        parent[v] = u
        depth[v] = depth[u] + 1
        dfs(v, u)

# build parent and depth starting from root = 1
root = 1
parent[root] = root
depth[root] = 0
dfs(root, 0)

# build binary lifting table up[k][v] = 2^k-th ancestor of v
up = [[0]*(n+1) for _ in range(LOG)]
up[0] = parent[:]  # 2^0 = 1-step ancestor

for k in range(1, LOG):
    for v in range(1, n+1):
        up[k][v] = up[k-1][up[k-1][v]]

def lca(u, v):
    if depth[u] &lt; depth[v]:
        u, v = v, u
    # lift u up to depth of v
    diff = depth[u] - depth[v]
    for k in range(LOG):
        if diff &gt;&gt; k &amp; 1:
            u = up[k][u]
    if u == v:
        return u
    # lift both until parents differ
    for k in reversed(range(LOG)):
        if up[k][u] != up[k][v]:
            u = up[k][u]
            v = up[k][v]
    return parent[u]

# example queries
queries = [(4,5), (4,6), (8,9), (5,9)]
for u, v in queries:
    print(f"LCA({u},{v}) = {lca(u,v)}")
<br>Expected output:<br>LCA(4,5) = 2
LCA(4,6) = 1
LCA(8,9) = 6
LCA(5,9) = 1
<br><br>When you need to answer queries or perform updates on paths or subtrees of a tree in logarithmic time, two powerful techniques are centroid decomposition and heavy–light decomposition.  They both build a hierarchy over the original tree that guarantees any root‐to‐leaf path is broken into only  pieces.<br><br>A centroid of a tree  is a vertex  whose removal splits  into connected components, each of size at most .  Every tree has either one or two adjacent centroids.  To build the centroid decomposition:<br>
<br>Size computation.  Pick an arbitrary root and compute for each node  the size  of its rooted subtree in  time by a DFS.
<br>Centroid finding.  Starting from the root, walk to any child whose subtree size exceeds ; repeat until no such child exists.  That node is a centroid of .
<br>Recurse.  Remove the centroid , yielding subtrees .  In the centroid tree, make  the parent of the centroids of each  (found recursively).  
<br>Because each removal cuts component sizes in half, the centroid tree has height .  To answer a query—say, “what is the distance from a node  to the nearest red node?”—you maintain for each centroid‐ancestor pair  the distance .  When you recolor or query , you walk up the centroid tree in  steps, combining precomputed distances in each ancestor’s component.<br><br>Heavy–Light Decomposition partitions  into chains so that any root‐to‐leaf path crosses at most  chains.  Here is how:<br>
<br>Subtree sizes.  As before, compute  for every .
<br>Heavy child.  For each non‐leaf , pick the child  whose subtree is largest; mark the edge  as heavy.  All other incident edges from  are light.
<br>Chains.  Each maximal path connected by heavy edges is a chain.  Assign each node  to the chain whose head is the nearest ancestor  such that  are all heavy.
<br>Because every time you follow a light edge you move into a subtree of size at most half, any path from root to leaf uses at most  light edges and hence at most that many chains.<br>To perform a query or update along the path between two nodes :<br>
<br>While  and  lie in different chains, lift the deeper of the two up to its chain head.  On each chain segment you can apply a segment‐tree or fenwick‐tree operation in .
<br>Once  and  share the same chain, perform the final segment operation between their positions in the chain.
<br>A single path operation costs  chain‐jumps, each costing  for the segment data structure, giving  total.  With careful implementation (e.g.\ using Euler‐tour indices and a single segment tree), this can be improved to  per path.<br>Both centroid decomposition and heavy–light decomposition transform global tree queries into  local steps, enabling fast dynamic algorithms for path sums, subtree updates, distance queries, and more—while remaining relatively easy to implement.  <br><br>We want to support two operations on a tree with  nodes (1‐indexed):<br>
<br>update: set the value at node  to .
<br>query: return the sum of values on the unique path between  and .
<br>Using Heavy–Light Decomposition (HLD), each path breaks into at most  chains, and we maintain a segment tree over a base array of size .  <br>#include &lt;bits/stdc++.h&gt;
using namespace std;
const int MAXN = 100000;

vector&lt;int&gt; adj[MAXN+1];
int parent[MAXN+1], depth[MAXN+1], heavy[MAXN+1];
int head[MAXN+1], pos[MAXN+1], subtreeSize[MAXN+1];
int curPos;
long long baseVal[MAXN+1]; // values remapped by pos[]

struct SegmentTree {
    int n;
    vector&lt;long long&gt; st;
    SegmentTree(int _n): n(_n), st(4*_n,0) {}
    void build(int p,int l,int r) {
        if (l==r) { st[p]=baseVal[l]; return; }
        int m=(l+r)/2;
        build(p&lt;&lt;1, l, m);
        build(p&lt;&lt;1|1, m+1, r);
        st[p]=st[p&lt;&lt;1]+st[p&lt;&lt;1|1];
    }
    void update(int p,int l,int r,int idx,long long x) {
        if (l==r) { st[p]=x; return; }
        int m=(l+r)/2;
        if (idx&lt;=m) update(p&lt;&lt;1, l, m, idx, x);
        else        update(p&lt;&lt;1|1, m+1, r, idx, x);
        st[p]=st[p&lt;&lt;1]+st[p&lt;&lt;1|1];
    }
    long long query(int p,int l,int r,int L,int R) {
        if (R&lt;l || r&lt;L) return 0;
        if (L&lt;=l &amp;&amp; r&lt;=R) return st[p];
        int m=(l+r)/2;
        return query(p&lt;&lt;1, l, m, L, R)
             + query(p&lt;&lt;1|1, m+1, r, L, R);
    }
};

int dfs(int v,int p){
    parent[v]=p; depth[v]=(p?depth[p]+1:0);
    subtreeSize[v]=1;
    int maxSub=0;
    heavy[v]=-1;
    for(int u: adj[v]) if(u!=p){
        int sz=dfs(u,v);
        if(sz&gt;maxSub){
            maxSub=sz;
            heavy[v]=u; // heavy child has max subtree size
        }
        subtreeSize[v]+=sz;
    }
    return subtreeSize[v];
}

void decompose(int v,int h){
    head[v]=h;
    pos[v]=++curPos;                 // assign $$\text{pos}[v]\in[1,n]$$
    baseVal[curPos]= /* initial value of node v */;
    if(heavy[v]!=-1)
        decompose(heavy[v], h);      // continue the chain
    for(int u: adj[v]) if(u!=parent[v] &amp;&amp; u!=heavy[v]){
        decompose(u, u);             // new chain at each light edge
    }
}

long long queryPath(int a,int b, SegmentTree &amp;st){
    long long res=0;
    while(head[a]!=head[b]){
        if(depth[head[a]]&lt;depth[head[b]])
            swap(a,b);
        // query the segment [pos(head[a]), pos(a)]
        res += st.query(1,1,curPos, pos[head[a]], pos[a]);
        a = parent[head[a]];
    }
    // now same chain: query [min(pos(a),pos(b)), max(...)]
    if(depth[a]&gt;depth[b]) swap(a,b);
    res += st.query(1,1,curPos, pos[a], pos[b]);
    return res;
}

void updateNode(int v,long long x, SegmentTree &amp;st){
    st.update(1,1,curPos, pos[v], x);
}

int main(){
    ios::sync_with_stdio(false);
    cin.tie(nullptr);

    int n,q; 
    cin&gt;&gt;n&gt;&gt;q;
    for(int i=1;i&lt;n;i++){
        int u,v; cin&gt;&gt;u&gt;&gt;v;
        adj[u].push_back(v);
        adj[v].push_back(u);
    }
    // Read initial values
    vector&lt;long long&gt; init(n+1);
    for(int i=1;i&lt;=n;i++) cin&gt;&gt;init[i];

    dfs(1,0);
    curPos=0;
    decompose(1,1);

    // Move init[] into baseVal by pos[]
    for(int v=1;v&lt;=n;v++)
        baseVal[pos[v]] = init[v];

    SegmentTree st(n);
    st.build(1,1,n);

    while(q--){
        char type; cin&gt;&gt;type;
        if(type=='U'){ // update: U v x
            int v; long long x; cin&gt;&gt;v&gt;&gt;x;
            updateNode(v,x,st);
        } else {       // query: Q u v
            int u,v; cin&gt;&gt;u&gt;&gt;v;
            cout&lt;&lt;queryPath(u,v,st)&lt;&lt;"\n";
        }
    }
    return 0;
}
]]></description><link>ch06-trees.html</link><guid isPermaLink="false">CH06-Trees.md</guid><pubDate>Thu, 17 Jul 2025 19:42:39 GMT</pubDate><enclosure url="assets/pasted-image-20250610213006.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;assets/pasted-image-20250610213006.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[CH07-Polynomials]]></title><description><![CDATA[ 
 <br><br><br>Multiplying two -digit numbers by the grade-school method costs .  Karatsuba’s trick reduces the number of recursive multiplies from 4 to 3, achieving<br><br>Suppose each integer is written in base  with  digits (padding with leading zeros if necessary).  Split<br><br>Rather than compute all four products , , , , Karatsuba computes only<br><br>and then reassembles:<br><br>def karatsuba(x, y):
    # base case for small values
    if x &lt; 10 or y &lt; 10:
        return x * y
    # number of digits
    n = max(len(str(x)), len(str(y)))
    m = n // 2
    # split x and y into high and low parts
    high_x, low_x = divmod(x, 10**m)
    high_y, low_y = divmod(y, 10**m)
    # three recursive calls
    z2 = karatsuba(high_x, high_y)
    z0 = karatsuba(low_x, low_y)
    z1 = karatsuba(high_x + low_x, high_y + low_y) - z2 - z0
    # recombine
    return z2 * 10**(2*m) + z1 * 10**m + z0
<br>Example:<br><br>base , digit‐length , so split at <br>First, write  <br><br>Karatsuba makes three recursive products:<br>
<br>

Since these are two‐digit numbers, we use the standard method:  


<br>


<br>

First compute the sums:  

Multiply:  

Then  


<br>Now reassemble the final product:  <br><br>That is,  <br><br>Indeed, .<br><br><br>Let  be an integer.  A root of unity is any complex number  satisfying<br><br>Equivalently,  is a root of the polynomial<br><br>Since  factors as<br><br>where<br><br>there are exactly  distinct solutions given by the points<br><br>on the unit circle in the complex plane.  The particular choice<br><br>is called the principal th root of unity.  It generates all others via powers:<br><br><br>The set  forms a cyclic group under multiplication, isomorphic to .  In particular:<br>
<br>
Order.   has exact order , since 

<br>
Conjugation.  , so complex conjugation reverses powers.

<br>
Sum of powers.  For any integer ,

This follows by summing the geometric progression


<br><br>Over the rationals,  factors into cyclotomic polynomials:<br><br>where  is the minimal polynomial whose roots are the primitive th roots of unity.  In particular,  is a root of , which has degree .<br><br>Let  be polynomials of degree .  Choose an integer  that is a power of two, and let<br><br>be the principal th root of unity.  Extend the coefficient vectors<br><br>to length  by padding with zeros.<br>The Discrete Fourier Transform (DFT) of  is the evaluation map<br><br>Similarly define .  By the Convolution Theorem, the pointwise product<br><br>is the DFT of the cyclic convolution .  If , this agrees for  with the linear convolution giving the coefficients of .<br><br>When , write<br><br>where<br><br>Then for each ,<br><br>and since  is a primitive th root of unity, each half‐size DFT costs  ring operations.  Merging them takes  more multiplications and additions.  Hence the recurrence<br><br>solves to<br><br>The inverse FFT uses  in the same algorithm and divides every entry by  at the end:<br><br><br>To multiply two ‐digit integers in base , decompose each into a length‐ digit array, embed into length‐ sequences, and perform:<br>
<br>Compute  and  via FFT in .
<br>Form  pointwise in .
<br>Apply inverse FFT to  in  to recover raw convolution coefficients .
<br>Round each  to the nearest integer (possible if the rounding error is ).
<br>Carry‐propagate modulo :
<br><br>Under standard floating‐point precision with machine epsilon , the error in each coefficient is , so by choosing  and  appropriately one ensures exact integer results after rounding.<br><br>We multiply  <br>  <br>with a length- FFT.  Because  the smallest power of two that is  is .  The principal -th root of unity is  <br><br>Forward DFTs.<br>
Zero-pad to four coefficients:  <br>  <br>For each  compute  <br><br><br>Thus  <br><br>Pointwise products.  For each  evaluate .<br><br>So  <br><br>Inverse DFT.<br>
Because ,  <br><br>Calculate each  separately.<br><br>Hence the convolution vector is  and therefore  <br><br>If these were base- digits of integers, one would now round (already exact) and propagate carries, but no carry is needed in this small example.<br><br>import math
import cmath

def fft(a, invert=False):
    n = len(a)
    # Bit‐reversal permutation
    j = 0
    for i in range(1, n):
        bit = n &gt;&gt; 1
        while j &amp; bit:
            j ^= bit
            bit &gt;&gt;= 1
        j |= bit
        if i &lt; j:
            a[i], a[j] = a[j], a[i]

    # Iterative FFT
    length = 2
    while length &lt;= n:
        ang = 2 * math.pi / length * (-1 if invert else 1)
        wlen = complex(math.cos(ang), math.sin(ang))
        for i in range(0, n, length):
            w = 1
            half = length // 2
            for k in range(half):
                u = a[i + k]
                v = a[i + k + half] * w
                a[i + k]       = u + v
                a[i + k + half]= u - v
                w *= wlen
        length &lt;&lt;= 1

    # Normalize if inverse
    if invert:
        for i in range(n):
            a[i] /= n

def multiply_poly(a, b):
    # determine power‐of‐two size
    n = 1
    total_length = len(a) + len(b) - 1
    while n &lt; total_length:
        n &lt;&lt;= 1

    # prepare FFT arrays
    fa = list(map(complex, a)) + [0] * (n - len(a))
    fb = list(map(complex, b)) + [0] * (n - len(b))

    # forward FFTs
    fft(fa, invert=False)
    fft(fb, invert=False)
    # pointwise multiply
    for i in range(n):
        fa[i] *= fb[i]
    # inverse FFT
    fft(fa, invert=True)

    # round real parts to nearest integer
    result = [int(round(fa[i].real)) for i in range(total_length)]
    return result

def int_to_digits(x, base):
    if x == 0:
        return [0]
    digits = []
    while x &gt; 0:
        digits.append(x % base)
        x //= base
    return digits

def digits_to_int(digits, base):
    carry = 0
    for i in range(len(digits)):
        total = digits[i] + carry
        digits[i] = total % base
        carry = total // base
    while carry:
        digits.append(carry % base)
        carry //= base
    # rebuild the integer from digits
    result = 0
    for d in reversed(digits):
        result = result * base + d
    return result

def multiply_int(x, y, base=10**4):
    # convert to digit arrays
    da = int_to_digits(x, base)
    db = int_to_digits(y, base)
    # convolve
    dc = multiply_poly(da, db)
    # carry‐propagate and reconstruct
    return digits_to_int(dc, base)

# Example usage
if __name__ == "__main__":
    # Multiply two large integers
    X = 123456789012345678901234567890
    Y = 987654321098765432109876543210
    product = multiply_int(X, Y)
    print("Product correct?", product == X * Y)
    print("FFT product:", product)
    print("Built‐in product:", X * Y)
<br><br>We multiply  and  in base . Converting to least‐significant‐first digit arrays gives  <br>so the convolution length is  and we choose . Padding to length 4 yields  <br>We first perform the bit‐reversal permutation with . For  set ; since , let  and because  we swap  with , giving  and . For  we find  so , then  and , so  but  fails and no swap. For  set ,  so  and  fails, ending with  <br>Next the in‐place Cooley–Tukey FFT runs iteratively. When  we compute  <br>For each block at  and  with , the butterfly  yields at : ; at : , so  <br>When  we have  <br>At  reset  and for :  and then ; for : . Thus the forward transforms are  <br>Pointwise multiplication gives  <br>so <br><br>For the inverse FFT we again bit‐reverse to , and at  with  <br><br>the butterflies  and  produce . At  with  <br>we take  and :  then ; : , and dividing by  yields  <br>After rounding we carry‐propagate in base 10:  giving  which is .<br><br>Schönhage and Strassen’s algorithm multiplies two ‐bit integers in  <br><br>bit‐operations by reducing integer multiplication to a negacyclic convolution via the Fast Fourier Transform over a Fermat‐number ring.<br>Choose a parameter  and base .  Write each ‐bit integer<br><br>in radix  as coefficient vectors of length :<br><br>We view these as polynomials in ,<br><br>and seek their product<br><br>whose coefficients give the convolution<br><br><br>Let  be the unique power of two with .  Select the Fermat modulus<br><br>In the ring , the element  satisfies<br><br>so  is a primitive th root of unity and  itself is a primitive th root.  Define<br><br>a primitive th root of unity in .  Then the negacyclic convolution modulo  is given by the Discrete Fourier Transform of length  in :<br>
<br>
Encode coefficient vectors of length  (pad  with zeros for ).

<br>
Forward transform (NTT) in :


<br>
Pointwise multiply in :

<br><br>
<br>
Inverse transform using  and a final factor  to recover the negacyclic convolution


<br>
Convert the negacyclic result modulo  into the linear convolution of length  by noting that modulo  the wrap‐around terms acquire a sign .

<br>Each ring multiplication in  involves operands of bit‐length .  To multiply them we:<br>
<br>Recursively apply Schönhage–Strassen to these length‐ integers.
<br>Perform two forward FFTs and one inverse FFT of size , each costing  ring‐operations.
<br>Thus if  is the bit‐complexity for ‐bit inputs, choosing  makes  and .  The recurrence is<br><br>Unravelling this recurrence over  levels yields<br><br>
<br>The Fermat modulus  guarantees no wrap‐around collision for convolution coefficients up to size , well below .  
<br>Division by  and handling of signs is exact in  because  exists (since ).  
<br>Carry propagation in base  reconstructs the integer product exactly, with no rounding or floating‐point error.
<br><br>We multiply the small integers  <br>using Schönhage–Strassen.  Choose <br>so that in radix   <br>and view them as polynomials  <br>We need negacyclic convolution of length  (smallest power of 2 ) in the ring  <br>where  satisfies , so  <br>is a primitive th root of unity.  <br>We form length  arrays by padding to eight entries:  <br>  <br>Forward NTT (, ) in :  <br>
<br>Since only ,<br>
  
<br>We need :  
<br>  Hence<br>
  <br>Pointwise multiply:  <br>  <br>Inverse NTT uses  and factor .  For  compute  <br><br>where .  One finds in each case:<br>
<br>
For , , sum, so<br>


<br>
For , , sum, so<br>


<br>
For , , sum, so<br>


<br>
For , , sum, so<br>


<br>Thus the negacyclic convolution modulo  is  <br>Since our original linear convolution has length , we take  <br>which indeed matches<br>
  <br>Finally, carry‐propagate in base :  <br><br>Reading digits  backwards gives<br>
which is exactly .  <br><br>import math

# Extended GCD for modular inverse
def _egcd(a, b):
    if b == 0:
        return (a, 1, 0)
    g, y, x = _egcd(b, a % b)
    return (g, x, y - (a // b) * x)

def _modinv(a, m):
    g, x, _ = _egcd(a, m)
    if g != 1:
        raise ValueError("No inverse for {} mod {}".format(a, m))
    return x % m

def _bit_reverse_permutation(a):
    n = len(a)
    j = 0
    for i in range(1, n):
        bit = n &gt;&gt; 1
        while j &amp; bit:
            j ^= bit
            bit &gt;&gt;= 1
        j |= bit
        if i &lt; j:
            a[i], a[j] = a[j], a[i]

def _ntt(a, root, mod, invert=False):
    n = len(a)
    _bit_reverse_permutation(a)

    length = 2
    while length &lt;= n:
        # wlen is a primitive 'length'-th root of unity
        ang = pow(root, (mod - 1) // length, mod)
        if invert:
            ang = _modinv(ang, mod)
        for i in range(0, n, length):
            w = 1
            half = length &gt;&gt; 1
            for j in range(half):
                u = a[i + j]
                v = (a[i + j + half] * w) % mod
                a[i + j] = (u + v) % mod
                a[i + j + half] = (u - v) % mod
                w = (w * ang) % mod
        length &lt;&lt;= 1

    if invert:
        inv_n = _modinv(n, mod)
        for i in range(n):
            a[i] = (a[i] * inv_n) % mod

def _negacyclic_convolution(x, y):
    m = len(x)
    # compute L0 = next power of two &gt;= m
    L0 = 1 &lt;&lt; (m - 1).bit_length()
    N = 2 * L0
    # Fermat modulus F = 2^N + 1
    F = (1 &lt;&lt; N) + 1
    # primitive 4N-th root r=2 mod F, so w = r^2 is primitive 2N-th root.
    r = 2 % F
    w = (r * r) % F

    # pad to length 2N
    a = x + [0] * (2*L0 - m)
    b = y + [0] * (2*L0 - m)
    for lst in (a, b):
        lst += [0] * (2*L0 - len(lst))

    # forward NTT of length 2N
    _ntt(a, w, F, invert=False)
    _ntt(b, w, F, invert=False)
    # pointwise multiply
    for i in range(2*L0):
        a[i] = (a[i] * b[i]) % F
    # inverse NTT
    _ntt(a, w, F, invert=True)

    # convert negacyclic (mod x^(2L0)+1) back to linear convolution of length 2m-1
    # c[k] = a[k] for k &lt; L0
    # and a[k+L0] contributes with a minus sign
    c = [0] * (2*m - 1)
    for k in range(2*m - 1):
        val = a[k]
        if k + L0 &lt; 2*L0:
            val = (val - a[k + L0]) % F
        c[k] = val
    return c

def sch_mul(u, v):
    if u == 0 or v == 0:
        return 0
    # Choose a small base B=2^b so that digits fit in Python ints comfortably
    # Here we pick b = 15; you can adjust if inputs are extremely large.
    b = 15
    B = 1 &lt;&lt; b

    # decompose into base-B digits
    x = []
    tmp = u
    while tmp:
        x.append(tmp &amp; (B - 1))
        tmp &gt;&gt;= b
    y = []
    tmp = v
    while tmp:
        y.append(tmp &amp; (B - 1))
        tmp &gt;&gt;= b

    # compute convolution of digit sequences
    c = _negacyclic_convolution(x, y)

    # carry propagation
    carry = 0
    for i in range(len(c)):
        total = c[i] + carry
        c[i] = total &amp; (B - 1)
        carry = total &gt;&gt; b
    while carry:
        c.append(carry &amp; (B - 1))
        carry &gt;&gt;= b

    # reassemble the integer
    result = 0
    for i in reversed(range(len(c))):
        result = (result &lt;&lt; b) | c[i]
    return result

# Example usage:
a = 92719287489171927891
b = 73764873164712537212
print(sch_mul(a, b))
<br><br><br>The Chinese Remainder Theorem (CRT) provides a powerful criterion for solving systems of simultaneous congruences with pairwise coprime moduli. At its core, it states that if  are positive integers satisfying  for all , then for any given residues , the system  <br><br>admits a unique solution modulo the product . This theorem transforms a potentially tangled web of congruences into a single congruence in a higher modulus, enabling reconstruction of  from its residues.<br>To see why existence holds, one constructs the standard “CRT solution.” Define  and observe that , so there exists an inverse  satisfying  <br><br>Then the candidate  <br><br>indeed satisfies  since every term with  vanishes mod , while  picks out . By construction  is determined uniquely up to addition of multiples of , guaranteeing uniqueness in .<br>The requirement of pairwise coprimality is essential. When the moduli share a common factor, consistency conditions arise: each congruence pair  <br><br>admits a solution if and only if . In that case the system can be reduced by merging the two congruences into one with modulus . Iterating this reduction leads to a generalized CRT valid even for non‐coprime moduli, provided compatibility holds at each step.<br>Example Implementation:<br>from typing import List, Tuple, Optional

def extended_gcd(a: int, b: int) -&gt; Tuple[int, int, int]:
    if b == 0:
        return a, 1, 0
    g, x1, y1 = extended_gcd(b, a % b)
    x = y1
    y = x1 - (a // b) * y1
    return g, x, y

def crt(congruences: List[Tuple[int, int]]) -&gt; Optional[Tuple[int, int]]:
    # Start with the trivial solution x ≡ 0 (mod 1)
    x, M = 0, 1
    
    for (a_i, m_i) in congruences:
        # Solve:
        #   x ≡ current x    (mod M)
        #   x ≡ a_i          (mod m_i)
        # i.e. find t such that:
        #   M * t + x ≡ a_i  (mod m_i)
        # =&gt; M * t ≡ (a_i - x) (mod m_i)
        g, s, t = extended_gcd(M, m_i)
        if (a_i - x) % g != 0:
            # No solution exists
            return None
        
        # Combine the solutions
        # t0 is one particular solution to M*t ≡ (a_i - x) (mod m_i)
        t0 = (s * ((a_i - x) // g)) % (m_i // g)
        # Update x to the new combined solution
        x = x + M * t0
        # Update modulus to lcm(M, m_i)
        M = (M // g) * m_i
        # Normalize x to [0, M)
        x %= M
    
    return x, M

# Example usage:
if __name__ == "__main__":
    # Solve:
    #   x ≡ 2 (mod 3)
    #   x ≡ 3 (mod 5)
    #   x ≡ 2 (mod 7)
congruences = [(2, 3), (3, 5), (2, 7)]
solution = crt(congruences)
if solution is None:
    print("No solution exists.")
else:
    x, M = solution
    print(f"x ≡ {x} (mod {M})")
<br>We can work through a concrete example to see the Chinese Remainder Theorem in action. Suppose we wish to find an integer  satisfying<br><br>Here the moduli , , and  are pairwise coprime, so we know a unique solution exists modulo .<br>First, compute the product of all moduli:<br><br>Next for each congruence, define<br><br>so that<br><br>We then need inverses  satisfying<br><br>Concretely, for the first modulus , we solve<br><br>Since , the inverse of  modulo  is  (because ), giving . Similarly, for  we solve<br><br>and noting , we have . Finally, for ,<br><br>and since , it follows that .<br>The CRT prescribes the solution<br><br>Carrying out the arithmetic gives<br><br>Since CRT guarantees uniqueness modulo , we reduce  mod :<br><br>Thus the smallest nonnegative solution is<br><br>and indeed one can check<br><br><br>The Euclidean algorithm for polynomials mirrors its integer counterpart, operating in the polynomial ring  over a field . Its goal is to compute the greatest common divisor (gcd) of two polynomials  and , denoted , by a sequence of polynomial divisions. The fundamental insight is that, just as with integers, the gcd of two polynomials does not change if we replace the larger one by its remainder upon division by the smaller one.<br>Given nonzero  with , the division algorithm guarantees unique polynomials  such that<br><br>One then sets , , and recursively computes<br><br>until a remainder of zero appears. The last nonzero  is, up to multiplication by a nonzero constant in , the gcd of  and .<br>Beyond merely computing the gcd, the Euclidean algorithm can be “extended” to produce polynomials  such that<br><br>This is accomplished by back‐substitution: knowing that  and , one expresses  in terms of  and , then iterates until obtaining an explicit linear combination of  and . Such representations are crucial, for instance, in constructing inverses in quotient rings  when .<br><br>def strip_leading_zeros(p):
    i = 0
    while i &lt; len(p) and p[i] == 0:
        i += 1
    return p[i:] or [0]

def poly_degree(p):
    p = strip_leading_zeros(p)
    return len(p) - 1

def poly_scalar_mul(p, scalar):
    return [coef * scalar for coef in p]

def poly_sub(p, q):
    # pad shorter with leading zeros
    diff = len(p) - len(q)
    if diff &gt; 0:
        q = [0]*diff + q
    elif diff &lt; 0:
        p = [0]*(-diff) + p
    return strip_leading_zeros([a - b for a, b in zip(p, q)])

def poly_divmod(a, b):
    a = strip_leading_zeros(a[:])
    b = strip_leading_zeros(b[:])
    deg_a, deg_b = poly_degree(a), poly_degree(b)
    if b == [0]:
        raise ZeroDivisionError("polynomial division by zero")
    quotient = [0] * (max(deg_a - deg_b + 1, 0))
    remainder = a[:]
    while poly_degree(remainder) &gt;= deg_b and remainder != [0]:
        lead_coeff_ratio = remainder[0] / b[0]
        deg_diff = poly_degree(remainder) - deg_b
        # monomial = lead_coeff_ratio * x^deg_diff
        monomial = [0]*deg_diff + [lead_coeff_ratio]
        quotient[deg_diff] = lead_coeff_ratio
        # subtract monomial * b from remainder
        subtraction = poly_scalar_mul(b + [0]*deg_diff, lead_coeff_ratio)
        remainder = poly_sub(remainder + [0]*deg_diff, subtraction)
    return strip_leading_zeros(quotient), strip_leading_zeros(remainder)

def poly_gcd(a, b):
    a = strip_leading_zeros(a)
    b = strip_leading_zeros(b)
    # ensure deg(a) &gt;= deg(b)
    if poly_degree(a) &lt; poly_degree(b):
        a, b = b, a
    while b != [0]:
        _, r = poly_divmod(a, b)
        a, b = b, r
    # make monic
    lead = a[0]
    return poly_scalar_mul(a, 1/lead)

# a(x) = x^3 + x^2 - 2x - 2  =&gt; [1, 1, -2, -2]
# b(x) = x^2 - 1             =&gt; [1, 0, -1]
a = [1, 1, -2, -2]
b = [1, 0, -1]
gcd = poly_gcd(a, b)
print("gcd:", gcd)  # should print [1, 1] representing x + 1
<br><br>Consider the polynomials  <br><br>We wish to compute  by successive polynomial division.<br>First, since , divide  by . Observe that  <br><br>so the remainder is  <br><br>Thus the first quotient is  and  <br><br>We may ignore the unit  and take our next divisor as  <br><br>Next, divide  by . Since  <br><br>the remainder is  <br><br>Here the second quotient is  and the remainder vanishes.<br>By the Euclidean algorithm in the polynomial ring, the last nonzero remainder (up to a nonzero constant) is the greatest common divisor. Hence  <br><br>In compact form, the divisions are  <br><br>and the last nonzero remainder  yields the monic gcd .<br><br>We begin with a monic, squarefree polynomial  <br><br>defined over the finite field .  Our aim is to recover each irreducible factor  by a sequence of algebraic operations whose cost is polynomial in  and .  The overall strategy splits into two main phases: first isolating factors of equal degree, and then recursively “splitting” each equal‐degree chunk into its irreducible components.<br>To ensure  is squarefree, one computes  <br><br>where  is the derivative.  Square‐freeness follows if and only if this gcd is , since any repeated irreducible factor would divide both  and .  From here on, we assume  has no repeated roots in its splitting field.<br>Distinct‐Degree Factorization.  For each integer  from  up to , consider the polynomial  <br><br>Working modulo , we compute  <br><br>By the property that in any extension field  we have  for every element,  collects exactly those irreducible factors of  whose degrees divide .  To isolate those of degree exactly , one then divides out all previously found pieces:  <br><br>Each exponentiation  is performed by binary (square‐and‐multiply) exponentiation in time , and each gcd by the subquadratic Euclidean algorithm in .  Summing over  gives a soft‐O cost of  <br><br>for the entire distinct‐degree stage.<br>Equal‐Degree Splitting.  Fix one factor  <br><br>whose irreducible constituents all have the same degree .  In the quotient ring  <br><br>the Chinese‐remainder theorem yields an isomorphism  <br><br>since  and each .  Consequently, the multiplicative group  factors as  <br><br>each component cyclic of order .<br>We now choose a random polynomial  <br><br>uniformly at random.  Since  is squarefree,  with overwhelming probability, so  defines a unit in .  One computes  <br><br>by repeated squaring in .  In each factor , exponentiation to  collapses every element to either  or , according to whether it is a quadratic residue.  Thus  vanishes on exactly those components where  lay in the subgroup of squares, and  vanishes on the complementary components.<br>We then set  <br><br>Unless  (a “failure” event of probability at most ), both  and  are nontrivial divisors of , each collecting a strict subset of the irreducible factors.  One then recurses on  and  independently.<br>Recursive Structure and Termination.  At each recursive call on a polynomial of degree , one performs one modular exponentiation in time  and two gcds in .  The probability of a successful split in each trial is at least , so the expected number of trials is at most .  The recursion depth is bounded by , since each split reduces the number of irreducible factors by a constant fraction.  Summing the expected costs over the recursion tree yields  <br><br>for splitting , and aggregating over all  recovers the overall expected complexity  <br><br><br>Let  <br><br>We will factor  by the Cantor–Zassenhaus method.<br>First, perform distinct‐degree factorization.<br>Linear factors (): compute <br><br>Over ,  <br><br>Since  shares no linear factor,  <br><br>so there are no roots in .<br>Quadratic factors (): compute  <br><br>Note that , and over  every irreducible quadratic divides .  One checks by Euclid’s algorithm that  <br><br>Thus all irreducible factors of  have degree , and we set  <br><br>Now apply the equal‐degree splitting for .  Here  and irreducible degree , so work in the ring , whose multiplicative group has order .<br>Choose a random polynomial  <br><br>Compute the exponentiation  <br><br>We do this by repeated squaring, reducing modulo  at each step.<br>Square once.  <br><br>Reduce :  <br><br>Square to get .  <br><br>Reduce  and :  <br><br>Square to get .  <br><br>Expand, reduce powers , and collect coefficients to get  <br><br>Multiply to reach .  <br><br>which reduces to  <br><br>Compute the two gcds  <br><br>Since  <br><br>Euclid’s algorithm yields  <br><br>Interpreting in , since ,  <br><br>both irreducible quadratics.  Therefore  <br><br><br>We wish to factor  <br><br>into irreducible factors  <br><br>Let , , and .  The algorithm proceeds through the following detailed stages.<br><br>First, ensure  is squarefree in each variable.  For each , compute  <br><br>and set  <br><br>Replace  by ; now  for all .  This costs  operations in , where  is the cost of degree– multiplication.<br><br>Choose random coefficients  from a set of size .  Define the linear form  <br><br>and its inverse on the hyperplane  by solving  <br><br>Substitute into  to obtain the univariate specialization  <br><br>By Schwartz–Zippel, the probability two true factors collide in  is  <br><br>so with high probability  has exactly  irreducible factors corresponding to .<br><br>Factor  in  via any –time algorithm, yielding  <br><br>with each .  Denote these monic  as our initial approximations of the  restricted to .<br><br>Work in the local ring  <br><br>where  generate the maximal ideal.  For each , initialize  <br><br>Thus  <br><br><br>Repeat for :<br>
<br>
Let current precision exponents be , set .  

<br>
Compute the residual  

truncated modulo each .  

<br>
Linearize around the  by writing  

and expand  


<br>
Discard higher‐order terms beyond total order , enforce  

<br><br>   yielding a linear system in the unknown coefficients .  The system matrix is the Jacobian  <br><br>   truncated appropriately.<br>
6. Solve this structured linear system using fast linear algebra in time , where  <br><br>
<br>Update each  and double exponents  
<br><br>After  iterations, each  and one obtains exact multivariate factors  <br><br><br>Each exact factor  has known degree vector .  For , choose sample shifts  <br><br>and evaluate the lifted approximation at  <br><br>This yields a tensor of values  <br><br>For each fixed , solve a univariate Vandermonde system in  to recover coefficients in , then repeat for , etc.  The total cost is  <br><br>dominated by the lifting cost when  is fixed.<br><br>If  with input coefficients of bit‐size , pick primes  exceeding all bad‐prime bounds, apply the above factorization mod each , lift and interpolate in , then use the Chinese remainder theorem and rational reconstruction to recover integer/rational coefficients of .  The global bit‐complexity is  <br><br><br>Combining all stages, the total arithmetic cost in  is  <br><br>The failure probability arises from (i) bad projection  (Schwartz–Zippel bound ) and (ii) bad primes dividing discriminants (), yielding overall  <br><br><br><br>Compute the formal derivative:<br><br>Apply the Euclidean algorithm to :<br><br>The last nonzero remainder is (1).  Hence  and  is squarefree.<br>Let (n=\deg f=4).  We check  and .<br> <br>Compute . Then<br><br>Divide:<br><br>The last nonzero remainder is , so .  There are no irreducible factors of degree 1.<br> <br>Compute .  Since , we have<br><br>so<br><br>Thus  and all irreducible factors of  have degree 2.<br>Set , with .  The splitting exponent is<br><br>Choose .  Check  by noting .  Compute<br><br>Since , it follows<br><br>We now compute<br><br>with<br><br><br>The last nonzero remainder is<br><br><br>Up to the nonzero constant factor , the monic gcd is<br><br>Putting it all together, we obtain the exact factorization in :<br><br><br><br>Lagrange interpolation addresses the following fundamental question: given  distinct nodes  and values , does there exist a unique polynomial  of degree at most  satisfying  for each ? One views the map <br><br>as a linear operator whose matrix in the monomial basis is the Vandermonde matrix <br><br>Since the nodes are distinct, , so  is invertible and there is exactly one interpolant.<br>An explicit construction uses the cardinal (Lagrange) basis polynomials<br><br>Hence the interpolation operator is<br><br>which manifestly satisfies . Equivalently, one can express each  in terms of Vandermonde determinants as<br><br>A central result is the error formula. If  is the true function and  its degree‐ interpolant at the nodes,<br><br>This follows by considering the function  and applying Rolle’s theorem  times. The factor  explains why widely spaced or uneven nodes can amplify the error.<br>From the viewpoint of operator norms, interpolation is not uniformly stable. The Lebesgue function<br><br>measures how interpolation magnifies data errors, and its maximum<br><br>is the Lebesgue constant. For equispaced nodes this grows exponentially in , whereas for Chebyshev nodes it grows only like , justifying their use for stable approximation.<br>A highly practical and equally elegant reformulation is the barycentric form. Define weights<br><br>then<br><br>This second‐form barycentric formula requires  operations per evaluation, avoids explicit polynomial products, and is numerically stable even as .<br><br>import numpy as np

class BarycentricInterpolator:
    def __init__(self, x, y):
        x = np.asarray(x, dtype=float)
        y = np.asarray(y, dtype=float)
        if x.ndim != 1 or y.ndim != 1 or x.size != y.size:
            raise ValueError("x and y must be one-dimensional and of the same length.")
        if np.unique(x).size != x.size:
            raise ValueError("Interpolation nodes must be distinct.")
        self.x = x
        self.y = y
        n = x.size
        # Precompute weights
        w = np.ones(n, dtype=float)
        for j in range(n):
            diffs = x[j] - np.delete(x, j)
            w[j] = 1.0 / np.prod(diffs)
        self.w = w

    def __call__(self, x_eval):
        x_eval = np.asarray(x_eval, dtype=float)
        scalar_input = (x_eval.ndim == 0)
        x_flat = x_eval.ravel()

        numerator = np.zeros_like(x_flat)
        denominator = np.zeros_like(x_flat)

        # Build sums, skipping direct x==x_j in the division
        for xj, yj, wj in zip(self.x, self.y, self.w):
            diff = x_flat - xj
            tmp = np.where(diff != 0, wj / diff, 0.0)
            numerator   += tmp * yj
            denominator += tmp

        L_flat = numerator / denominator

        # For any x_eval that exactly equals a node, override with y_j
        for xj, yj in zip(self.x, self.y):
            mask = (x_flat == xj)
            L_flat[mask] = yj

        L = L_flat.reshape(x_eval.shape)
        return L[0] if scalar_input else L

x_nodes = [0, 1, 2, 3]
y_nodes = [1, 2, 0, 3]
interp = BarycentricInterpolator(x_nodes, y_nodes)

xs = np.linspace(0, 3, 100)
ys = interp(xs)

for xv, yv in zip(xs[::25], ys[::25]):
    print(f"L({xv:.2f}) = {yv:.4f}")
<br>Example Calculation<br>We seek the unique polynomial  of degree  satisfying , , .  The Lagrange basis polynomials are  <br><br><br>Hence  <br><br>Substitute and expand term by term:  <br><br>Summing gives  <br><br>Verifying the nodes:  <br><br>as required.  <br><br>Newton interpolation offers a constructive and incremental approach to the unique polynomial of degree at most  passing through  data points . Rather than solving a full Vandermonde system at once, Newton’s method builds the interpolant by adding one basis function at a time, using the machinery of divided differences.<br>At the heart of the method lies the notion of the divided difference.  For two nodes,<br><br>and more generally, for  nodes ,<br><br>These quantities play the role of generalized finite differences, symmetric in their arguments, and satisfy a recursive definition that mirrors the triangular structure of a difference table.<br>The Newton form of the interpolant is then given by<br><br>By construction, evaluating  collapses all terms beyond , recovering .  Each new term extends the polynomial degree by one and involves exactly the highest‐order divided difference, so adding a new data point only requires computing one new column of the divided‐difference table.<br>From a theoretical standpoint, Newton interpolation manifests the linear isomorphism between the space  and  in a lower‐triangular basis.  The Newton basis functions<br><br>are clearly linearly independent, and the mapping<br><br>is bijective.  The divided differences  are precisely the coordinates of the interpolant in this basis.<br>A fundamental theoretical result is the error representation.  If  on an interval containing the nodes, then for each  there exists  between the smallest and largest  such that<br><br>This shows that the error is proportional to the next divided difference (or the next derivative), and again highlights the role of the node‐spacing factor  in controlling interpolation quality.<br>Computationally, constructing the table of divided differences takes  time and storage, since each new column builds on the previous one.  However, once the coefficients  are known, evaluating  at a given  can be done in  operations via the nested (Horner‐like) form:<br><br>where .  This efficiency makes Newton interpolation particularly attractive when one needs multiple evaluations after building the table once.<br>Theoretically, Newton and Lagrange forms are equivalent: one may convert between them by expressing the Newton basis in the monomial basis or by rewriting divided differences in determinantal form.  <br>Yet Newton’s incremental nature grants it an edge when data arrive sequentially, since adding a new node  requires only one additional divided difference column and one new basis factor, without recomputing earlier work.<br><br>import numpy as np

def divided_differences(x, y):
    x = np.asarray(x, dtype=float)
    coeffs = np.asarray(y, dtype=float).copy()
    n = len(x)
    # Build the table in-place: each pass computes the next column
    for j in range(1, n):
        # Compute f[x_i, ..., x_{i+j}] for i = 0..n-j
        coeffs[j:n] = (coeffs[j:n] - coeffs[j-1:n-1]) / (x[j:n] - x[0:n-j])
    return coeffs

def newton_interpolate(x, coeffs, xi):
    x = np.asarray(x, dtype=float)
    coeffs = np.asarray(coeffs, dtype=float)
    # Ensure xi as array for vectorized evaluation
    xi_arr = np.atleast_1d(xi).astype(float)
    yi = np.zeros_like(xi_arr)

    # Evaluate via nested (Horner-like) scheme
    for idx, xval in enumerate(xi_arr):
        result = coeffs[-1]
        for k in range(len(coeffs)-2, -1, -1):
            result = result * (xval - x[k]) + coeffs[k]
        yi[idx] = result

    # If input was scalar, return scalar
    return yi if yi.shape != () else yi.item()

# Given data points
x_nodes = [0.0, 1.0, 2.0, 4.0]
y_values = [1.0, 2.0, 0.0, 5.0]

# 1. Compute Newton coefficients
a = divided_differences(x_nodes, y_values)
print("Newton coefficients:", a)

# 2. Evaluate at some points
xs = np.linspace(0, 4, 9)
ys = newton_interpolate(x_nodes, a, xs)

print("Interpolated values:")
for xi, yi in zip(xs, ys):
    print(f"  x = {xi:.2f} -&gt; N(x) = {yi:.4f}")
<br><br><br><br>Let  <br><br>be a polynomial over a commutative ring , and fix .  The evaluation map , with , can be factorized algorithmically by writing  in nested form:  <br><br>Define a recurrence on the coefficients  <br><br>A short induction yields  and  <br><br>so the same  ring operations that evaluate  also perform synthetic division by .  This linear cost is optimal: every coefficient must be read, and Brent’s lower‐bound argument shows no reordering can asymptotically beat Horner for single‐point evaluation.  Moreover, replacing  by a commuting matrix  turns the same recurrence into an efficient algorithm for , illustrating that Horner implements the universal property of the evaluation homomorphism in any algebra.<br><br>In floating arithmetic each step satisfies  with .  Backward‐error analysis shows the computed value equals the exact evaluation of a perturbed coefficient vector  where , i.e.\ Horner is backward stable.  Forward accuracy depends on the condition number  <br><br>so values near multiple or clustered roots remain intrinsically sensitive, regardless of algorithmic stability.<br>Because the recurrence exposes derivatives, one obtains simultaneously  <br><br>yielding  in  operations. <br><br>We evaluate at  by writing it in nested form as  <br>We set up the recurrence on the coefficients .  First<br>
Then for :<br>
Next for :<br>
Finally for :<br>
Hence the value is Simultaneously, synthetic division by  produces the degree-2 quotient with coefficients  and remainder :<br>
Each of the three iterations uses one multiplication by  and one addition (totaling  ring operations), which is optimal and applies unchanged if  is replaced by any commuting element (e.g.\ a matrix  to compute ).  <br><br><br>Let  <br><br>be a monic polynomial of degree  with complex coefficients.  Denote its (unknown) roots by .  Starting from an initial vector of distinct guesses  in , the Durand–Kerner (or Weierstrass) iteration updates all coordinates simultaneously:  <br><br>Written in vector form,  where the map  <br><br>is analytic on the complement of the diagonal .  If the initial configuration is sufficiently close to a permutation of the true roots, classical results of Ostrowski show that the iteration converges quadratically, i.e.  <br><br>with a constant  depending on the root clustering.  When no two roots coincide, a refined analysis using the symmetric power map reveals even quartic convergence because each step implicitly applies a Newton correction to every Vieta symmetric function.<br><br>We find the roots of<br>
by Durand–Kerner iteration.  Take initial guesses  <br>The update rule is  <br><br>At  we have  and denominator , so  <br><br>Similarly  and denominator , giving  <br><br>At  compute  and denominator , so  <br><br>Likewise  and denominator , hence  <br><br>After two iterations we have  <br><br>which rapidly approaches the exact roots  and  with quadratic convergence.<br><br><br>Let  be a field,  of degree , and let  be distinct nodes ().  The evaluation vector  can be viewed as the image of  under the Chinese Remainder homomorphism  <br><br>Because each quotient ring is isomorphic to  via , computing  reduces to simultaneous modular reductions of  by the linear factors .  The divide-and-conquer scheme realises these reductions in quasi-linear time.  One first builds the subproduct tree: at level  one stores ; recursively,  <br><br>so the root holds  where .  The second phase pushes the polynomial  down a remainder tree: if  is attached to an internal node labelled by  then one computes  <br><br>and forwards  to the children.  Because  and , the degrees roughly halve every level.  At each leaf the stored remainder is  by the Remainder Theorem, so the leaves collectively yield .<br><br>Let  denote the cost of multiplying two degree- polynomials in ; with Schönhage–Strassen or NTT arithmetic one has .  The subproduct tree requires <br><br>since level  multiplies  pairs of degree  polynomials.  The remainder tree has the same bound because each modular reduction can be performed via a multiply-and-subtract of identical asymptotic cost.  Setting  therefore gives the overall complexity  <br><br>which is nearly optimal: writing down  outputs already costs , and a lower bound by transference from the polynomial remainder problem shows any algebraic-decision-tree evaluation must incur  ring operations.  The divide-and-conquer algorithm attains this bound up to a single logarithmic factor by sharing intermediate products across all moduli.  <br>When , each step is backward-stable because exact arithmetic takes place in  coefficients propagated through FFT convolutions; forward errors grow only polylogarithmically in . <br><br>We want to compute  <br>at the four nodes  by the divide‐and‐conquer scheme.  Set  so  and .  The subproduct tree is built level by level:<br>
at level 0 we have  <br>At level 1 we pair and multiply:  <br><br>At the root (level 2) we form  <br><br>Since , the remainder of  mod  is  itself.  We now push  down the remainder tree: at the left child we compute  <br>by dividing  by .  The quotient is  because  <br><br>and then  yielding remainder  <br>Thus<br>
At the right child we compute  <br>by dividing by .  Since  <br><br>and<br>
leaves remainder<br>
we have<br>
Finally at the leaves we reduce each linear remainder mod  by evaluation:  <br><br><br>Thus the algorithm produces the vector  in quasi-linear time by sharing the intermediate products  across all evaluations.]]></description><link>ch07-polynomials.html</link><guid isPermaLink="false">CH07-Polynomials.md</guid><pubDate>Mon, 16 Jun 2025 21:09:01 GMT</pubDate></item><item><title><![CDATA[CH08-Numerical-Differenciation]]></title><description><![CDATA[ 
 <br><br><br>Let  and let  be defined on the evenly-spaced grid  (often  or ).  Write the shift operator as .  The forward-difference operator is then<br><br>Iterating  and expanding,  with the binomial theorem yields  <br><br>so  plays for difference calculus the same role that  plays for analysis.<br>Polynomials of degree  satisfy , just as the -st derivative of such a polynomial vanishes.  For the falling-factorial basis  <br><br>one has  <br><br>so  is lower-triangular in that basis exactly as  is in the monomial basis.  A concrete check: for ,  <br><br>Whenever the -th forward differences grow at most exponentially (e.g.\ ), one has the convergent expansion  <br><br>Define the summation operator  <br><br>Telescoping gives  <br><br>so  is a right-inverse (up to a boundary term) of .<br>From Taylor expansion one obtains the classic finite-difference approximations  <br><br>hence  underlies first- and second-order derivative formulas with errors controlled by higher differences.<br>For  and  the Bernoulli numbers (<a class="internal-link" data-href="Appendix-V" href="appendix-v.html" target="_self" rel="noopener nofollow">Appendix V</a>),<br><br>with the remainder  expressed in terms of . This formulates a precise quantitative link between discrete sums and continuous integrals.<br><br>We take  and  at . First compute  <br><br>Then  <br><br>Next  <br><br>so  <br><br>Continue  <br><br>and  <br><br>hence  <br><br>This agrees with the binomial expansion  <br><br>For the falling‐factorial basis with ,  <br><br>we have  <br><br>so  <br><br>verifying . Finally let , , :  <br><br>and  <br><br>confirming .<br><br>import math
from math import comb

def forward_difference(f, x, h=1.0, n=1):
    return sum((-1)**(n-k) * comb(n, k) * f(x + k*h) for k in range(n + 1))


def forward_difference_function(f, h=1.0, n=1):
    return lambda x: forward_difference(f, x, h, n)


def falling_factorial(x, k, h=1.0):
    prod = 1.0
    for i in range(k):
        prod *= (x - i*h)
    return prod


def sum_operator(g, x, h=1.0, n=1):
    return sum(g(x + j*h) for j in range(n))


# --------------------------------------------------------------------------
# Demonstrations
# --------------------------------------------------------------------------

# 1. Verify that Δ_h^3 x^2 ≡ 0
h_demo = 0.5
p = lambda x: x**2
test_points = [0, 1, 2, 3]
delta3_vals = [forward_difference(p, x, h_demo, n=3) for x in test_points]
print("Δ_h^3 p(x) for p(x)=x^2 with h=0.5:", delta3_vals)

# 2. First‑derivative approximation for f(x)=sin(x) at x0=1
f = math.sin
f_prime_exact = math.cos
x0 = 1.0
hs = [2**(-k) for k in range(1, 11)]          # 2^{-1}, …, 2^{-10}
errors = []
for h in hs:
    approx = forward_difference(f, x0, h, n=1) / h
    errors.append(abs(approx - f_prime_exact(x0)))

print("\nForward‑difference derivative error for sin at x=1:")
for h, err in zip(hs, errors):
    print(f"h={h:&lt;9.1e}  |error|={err:.3e}")

# 3. Summation operator &amp; telescoping check
g = lambda x: x**2
a = 0.0
n_sum = 5
h_sum = 1.0

S_val = sum_operator(g, a, h_sum, n_sum)
delta_S = forward_difference_function(lambda y: sum_operator(g, y, h_sum, n_sum), h_sum, n=1)(a)
boundary = g(a + n_sum*h_sum) - g(a)

print(f"\nS_h g(a) with g(x)=x^2, a={a}, n={n_sum}: {S_val}")
print(f"Δ_h S_h g(a): {delta_S} (should equal g(a+nh)-g(a)={boundary})")
<br>Δ_h^3 p(x) for p(x)=x^2 with h=0.5: [0.0, 0.0, 0.0, 0.0]

Forward-difference derivative error for sin at x=1:
h=5.0e-01    |error|=2.283e-01
h=2.5e-01    |error|=1.102e-01
h=1.2e-01    |error|=5.393e-02
h=6.2e-02    |error|=2.664e-02
h=3.1e-02    |error|=1.323e-02
h=1.6e-02    |error|=6.596e-03
h=7.8e-03    |error|=3.292e-03
h=3.9e-03    |error|=1.645e-03
h=2.0e-03    |error|=8.221e-04
h=9.8e-04    |error|=4.110e-04

S_h g(a) with g(x)=x^2, a=0.0, n=5: 30.0
Δ_h S_h g(a): 25.0 (should equal g(a+nh)-g(a)=25.0)
<br><br>Backward differences approximate derivatives while looking only at past mesh points—a key feature for stable implicit time-stepping. On a uniform mesh  with step size  the backward-difference operator is  <br><br>As  one has , making  a discrete analogue of .<br>Repeated application gives the -th backward difference  <br><br>which follows from the binomial identity   with the backward shift operator .<br> kills degree just like a derivative: for any polynomial  of degree ,<br><br>Working in the rising-factorial basis<br><br>one finds  <br><br>The matrix of  in this basis is therefore lower-triangular, mirroring the behavior of  on ordinary monomials.<br>For a function  with sufficiently tame growth of  we have the convergent expansion<br><br>often called the backward Newton series.<br><br>from __future__ import annotations
import math
from typing import Callable

Number = float | int

def nabla(f: Callable[[Number], Number],
          x: Number,
          h: Number = 1.0) -&gt; Number:
    return f(x) - f(x - h)

def nabla_n(f: Callable[[Number], Number],
            x: Number,
            h: Number = 1.0,
            n: int = 1) -&gt; Number:
    return sum(((-1) ** k) * math.comb(n, k) * f(x - (n - k) * h)
               for k in range(n + 1))

def rising_factorial(x: Number,
                     k: int,
                     h: Number = 1.0) -&gt; Number:
    out = 1.0
    for i in range(k):
        out *= x + i * h
    return out

def backward_newton_series(f: Callable[[Number], Number],
                           x: Number,
                           x0: Number,
                           h: Number = 1.0,
                           terms: int = 10) -&gt; Number:
    total = 0.0
    for k in range(terms):
        coeff = nabla_n(f, x0, h, k) / (math.factorial(k) * h**k)
        total += coeff * rising_factorial(x - x0, k, h)
    return total
<br><br>We take  and  at . First compute the function values <br><br>The first backward difference is  <br><br>At  we have  <br><br>so the second backward difference at  is  <br><br>Compute next  <br><br>hence  <br><br>and the third difference at  is  <br><br>confirming  for a quadratic.<br>Alternatively, by the binomial formula  <br><br>In the rising‐factorial basis for ,  <br><br>we have at :  <br><br>so  <br><br>verifying .<br>Finally, the backward Newton series at  truncates after  since higher differences vanish.  We compute  <br><br>The series is  <br><br>Since  and , this becomes  <br><br>as required.<br><br>On a uniform grid with spacing , the central difference operator  provides a symmetric discrete analogue of differentiation.  One defines the first‐order central difference by<br><br>so that the finite‐difference approximation to the first derivative reads  <br><br>More generally, higher‐order central differences arise by iterating  and expressing them in terms of forward and backward shifts:  <br><br>where .  In particular, the second central difference  <br><br>gives a canonical approximation for  via .<br>By Taylor expansion around , one finds  <br><br>so central‐difference formulas achieve second‐order accuracy for both first and second derivatives, outperforming forward or backward schemes of the same stencil width.  In operator terms,  is a skew‐symmetric discretization of , and  is a symmetric discretization of , making them especially suited to conserve symmetry and energy in numerical PDEs.<br><br>On a uniform grid with spacing , define the first‐order central difference operator  <br><br>Iterating  gives the second central difference  <br><br>We begin by Taylor‐expanding  about  up to :  <br><br><br>Now form the first central difference by subtracting term‐by‐term:  <br><br><br><br><br><br><br>Dividing by  gives the second‐order approximation to :  <br><br>For the second central difference, expand  up to :  <br><br><br>Adding these two gives  <br><br>and subtracting  yields  <br><br>Finally divide by  to get the approximation for :  <br><br><br>import numpy as np
from math import comb

def delta_h(f, x, h):
    return f(x + 0.5*h) - f(x - 0.5*h)

def central_derivative(f, x, h):
    return delta_h(f, x, h) / h

def delta_h2(f, x, h):
    return f(x + h) - 2*f(x) + f(x - h)

def central_second_derivative(f, x, h):
    return delta_h2(f, x, h) / h**2

def delta_h_n(f, x, h, n):
    # if n is odd, offsets are half‐integers; if even, integers
    total = 0
    for k in range(n+1):
        shift = (n/2 - k) * h
        total += ((-1)**k) * comb(n, k) * f(x + shift)
    return total

# Example usage
def test():
    import matplotlib.pyplot as plt

    # test function
    f = np.sin
    x0 = 1.23
    h = 1e-3

    # scalar test
    print("f'(x) approx:", central_derivative(f, x0, h))
    print("f'(x) exact :", np.cos(x0))
    print("f''(x) approx:", central_second_derivative(f, x0, h))
    print("f''(x) exact :", -np.sin(x0))

    # vectorized test on a grid
    xs = np.linspace(0, 2*np.pi, 200)
    d1 = central_derivative(f, xs, 0.01)
    d2 = central_second_derivative(f, xs, 0.01)

    plt.figure(figsize=(8,4))
    plt.plot(xs, d1, label="approx f'")
    plt.plot(xs, np.cos(xs), '--', label="exact f'")
    plt.legend()
    plt.title("First Derivative via Central Difference")
    plt.show()

    plt.figure(figsize=(8,4))
    plt.plot(xs, d2, label="approx f''")
    plt.plot(xs, -np.sin(xs), '--', label="exact f''")
    plt.legend()
    plt.title("Second Derivative via Central Difference")
    plt.show()
<br><img alt="Pasted image 20250614195240.png" src="assets/pasted-image-20250614195240.png"><br><img alt="Pasted image 20250614195246.png" src="assets/pasted-image-20250614195246.png"><br><br>Let  be defined on a uniform grid .  The forward difference operator<br><br>satisfies by the binomial theorem  <br><br>so that  <br><br>In the falling‐factorial basis  one shows  <br><br>so  lowers degree by  and annihilates all polynomials of degree .  A compact generating‐function identity is  <br><br>linking difference operators to umbral calculus and the binomial transform.<br>By Taylor expanding each term,<br><br>one deduces<br><br>so  approximates the th derivative with first‐order error.  Symmetric higher differences, defined by  <br><br>yield even‐order approximations with second‐order error:<br><br>These operators underpin high‐order finite‐difference schemes and discrete Newton series,<br><br>and form the backbone of Richardson and Romberg extrapolation, where combining  at multiple step‐sizes cancels leading errors to achieve arbitrarily high convergence orders.  <br><br>import numpy as np
from math import comb

def delta_h(f, x, h):
    return f(x + 0.5*h) - f(x - 0.5*h)

def central_derivative(f, x, h):
    return delta_h(f, x, h) / h

def delta_h2(f, x, h):
    return f(x + h) - 2*f(x) + f(x - h)

def central_second_derivative(f, x, h):
    return delta_h2(f, x, h) / h**2

def delta_h_n(f, x, h, n):
    total = 0
    for k in range(n+1):
        shift = (n/2 - k) * h
        total += ((-1)**k) * comb(n, k) * f(x + shift)
    return total

def forward_difference(f, x, h):
    return f(x + h) - f(x)

def forward_difference_n(f, x, h, n):
    total = 0
    for k in range(n+1):
        total += ((-1)**(n-k)) * comb(n, k) * f(x + k*h)
    return total

def symmetric_even_difference(f, x, h, n):
    return delta_h_n(f, x, h, 2*n)

# ─── Example usage with f(x) = exp(−x²) ─────────────────────────────────────

def test():
    import matplotlib.pyplot as plt

    # New test function and its known derivatives
    f = lambda x: np.exp(-x**2)
    f1 = lambda x: -2*x * np.exp(-x**2)          # f'(x)
    f2 = lambda x: (4*x**2 - 2) * np.exp(-x**2)  # f''(x)

    x0, h = 0.5, 1e-3

    # First derivative: forward vs central vs exact
    fd1 = forward_difference(f, x0, h) / h
    cd1 = central_derivative(f, x0, h)
    ex1 = f1(x0)
    print(f"Forward Δ_h f/h = {fd1:.6e}")
    print(f"Central δ_h f/h = {cd1:.6e}")
    print(f"Exact f'        = {ex1:.6e}\n")

    # Second derivative: Δ_h^2/h^2 vs δ_h^2/h^2 vs exact
    fd2 = forward_difference_n(f, x0, h, 2) / h**2
    cd2 = central_second_derivative(f, x0, h)
    ex2 = f2(x0)
    print(f"Forward Δ_h^2/h^2 = {fd2:.6e}")
    print(f"Central δ_h^2/h^2 = {cd2:.6e}")
    print(f"Exact f''         = {ex2:.6e}\n")

    # Symmetric 4th‐order approx of f^(4)(x) (should be 12x(1 - x^2) e^{-x^2})
    # but we just check the workflow:
    sym4 = symmetric_even_difference(f, x0, h, 2) / h**4
    print(f"Symmetric δ_h^4/h^4 = {sym4:.6e}")

    # Plot comparison on a grid
    xs = np.linspace(-2, 2, 400)
    approx = np.array([central_second_derivative(f, xi, 0.01) for xi in xs])
    exact   = f2(xs)

    plt.figure(figsize=(8,4))
    plt.plot(xs, approx, label="approx f'' via δ_h^2/h^2")
    plt.plot(xs, exact, '--', label="exact f''")
    plt.title("Second Derivative of e^{-x^2}")
    plt.legend()
    plt.show()
<br><img alt="Pasted image 20250614202126.png" src="assets/pasted-image-20250614202126.png"><br><br>We take  on the grid with  at .  First tabulate  <br><br>The first forward difference is  <br><br>Next  <br><br>so the second difference at  is  <br><br>Continuing,  <br><br>hence  <br><br>Finally  <br><br>so  <br><br>confirming  annihilates polynomials of degree .<br>The binomial expansion  <br><br>agrees with the stepwise differences.<br>In the falling‐factorial basis , for  we have  <br><br>so at :  <br><br>and  <br><br>verifying .  Moreover  <br><br>and .<br>By Taylor expansion one shows  <br><br>matching our value , so  approximates  with  error.<br>Finally, the symmetric second difference  <br><br>and  <br><br>recovers the true second derivative  with  accuracy.<br><br><br><br>Monte Carlo methods rest on the idea that we can approximate expectations or integrals by drawing random samples from an underlying distribution and averaging.  Suppose we wish to estimate  <br><br>where  is a random variable on  with law .  If we draw independent samples , then the Monte Carlo estimator  <br><br>is unbiased, i.e.\ , and by the Strong Law of Large Numbers  <br><br>The Central Limit Theorem further ensures that, if , then  <br><br>so that the estimation error decays like  regardless of dimension.<br>The simplest case is crude Monte Carlo, where  are drawn uniformly (or from the target law) using a pseudo‐random number generator.  In practice one often employs importance sampling: choose a proposal density  and write  <br><br>Then  <br><br>remains unbiased but can dramatically reduce  when  is chosen to mimic the shape of .  Other variance‐reduction strategies include stratified sampling, control variates, and antithetic variates, each exploiting problem structure to lower the estimator variance below that of crude sampling.<br>Since  <br><br>one can estimate the standard error on the fly via the sample variance  <br><br>giving an approximate ‐level confidence interval  <br><br>Monitoring the decay of  and running independent replicates enables practical convergence diagnostics.  Although the  rate can be slow, Monte Carlo’s dimension‐independent convergence makes it indispensable in high‐dimensional integration, stochastic optimization, and probabilistic simulation.<br><br>The Law of Large Numbers (LLN) formalizes the intuitive idea that the sample average converges to the true expected value as the sample size grows. It comes in two primary flavors: the Weak Law of Large Numbers (WLLN), concerning convergence in probability, and the Strong Law of Large Numbers (SLLN), concerning almost sure convergence. Both theorems underpin statistical estimation and the foundations of probability theory by guaranteeing stability of averages under repeated trials.<br>Let  be a sequence of independent and identically distributed (i.i.d.) random variables with finite expectation . Define the sample average<br><br>The Weak Law asserts that for any ,<br><br>i.e.\ . A standard proof uses Chebyshev’s inequality: since  when , one obtains<br><br>The Strong Law strengthens this to almost‐sure convergence:<br><br>or . One classical proof employs Kolmogorov’s three‐series theorem or uses the Borel–Cantelli lemma by controlling tail probabilities via a truncation argument. The finiteness of  suffices for the SLLN, and various generalizations relax independence to certain forms of weak dependence or martingale differences.<br>The LLN justifies using the sample mean as a consistent estimator of the population mean in statistics: as  grows, the estimator stabilizes around the truth. In Monte Carlo integration, it guarantees that<br><br>for i.i.d.\ samples , forming the backbone of simulation‐based methods.<br><br>For the Monte Carlo estimator  <br><br>with  i.i.d.\ samples from  and , unbiasedness gives  <br><br>The variance of  is  <br><br>Consequently, the mean squared error (MSE) equals the variance,  <br><br>In practical terms, halving the root‐mean‐square error requires quadrupling .  When using importance sampling with weights , one replaces  by , so the design of  directly targets reduction of this weighted variance.<br>By the Central Limit Theorem, if , then  <br><br>so for large  one has approximately  <br><br>This justifies confidence intervals of width .  More refined bounds arise from the Berry–Esseen theorem, which gives  <br><br>where  is the standard normal CDF, provided .<br>Almost–sure convergence at the  scale is characterized by the Law of the Iterated Logarithm: with probability 1,<br><br>For non‐i.i.d.\ or dependent samples (e.g.\ Markov chains), analogous results hold under mixing or martingale conditions, replacing  by an effective variance term.  Finally, concentration inequalities—such as Hoeffding’s or Bernstein’s—provide non‐asymptotic bounds  <br><br>where  bounds  and  bounds , ensuring exponential decay of large deviations even for moderate .  <br><br>Estimating the derivative of a function or an expectation when only noisy or black‐box evaluations are available is a foundational problem in Monte Carlo optimization and simulation.  Suppose we wish to approximate the gradient of  <br><br>with respect to a parameter vector , but cannot compute analytic derivatives.  Two principal randomized approaches prevail: the score‐function (likelihood‐ratio) method and randomized finite‐difference (smoothed/directional) estimators.<br>Write  <br><br>so that  <br><br>A Monte Carlo estimator draws independent  and computes  <br><br>This estimator is unbiased and applies even when  is non‐differentiable in , but its variance can be large.  Common variance‐reduction techniques include control variates (subtracting a baseline  so  replaces ), and Rao‐Blackwellization when parts of  admit analytic conditional expectations.<br>Alternatively, one can approximate each partial derivative by perturbing  along random directions.  For instance, let  and define the Gaussian‐smoothed function  <br><br>Then under mild regularity  <br><br>so a Monte Carlo gradient estimator is  <br><br>As  this approximates the true gradient, with a bias–variance trade‐off: smaller  reduces bias but increases variance.  A special case with only two function evaluations per direction yields the simultaneous perturbation stochastic approximation (SPSA) estimator, where each coordinate of  is drawn from a Rademacher or other symmetric distribution, and one forms  <br><br>SPSA uses only two evaluations per gradient estimate regardless of dimension, making it popular in high‐dimensional settings.<br><br>We wish to estimate  <br><br>at  using only Monte Carlo samples.<br>For the score‐function estimator we use  <br><br>Draw  samples from  at .  Suppose we obtain  <br><br>Then  <br><br><br>The estimator is  <br><br>Here the true gradient is , so with  our crude SF estimate is .<br>For the Gaussian‐smoothed estimator set  and draw , .  Suppose  <br><br>Then  <br><br>The smoothed estimator is  <br><br>Again the exact gradient is , but with two noisy evaluations we get .<br>With SPSA in one dimension we draw a single Rademacher ; take  and .  We evaluate  (here  exactly, but in practice we would approximate it) at :  <br><br>so  <br><br>recovering the exact gradient  with only two evaluations.<br>These three randomized methods—score‐function, Gaussian smoothing, and SPSA—all trade off bias and variance differently but can approximate  when analytic derivatives are unavailable.<br><br>Suppose  admits a reparameterization through a base random variable  independent of , such that  <br><br>and  under the change of variables .  Then for an expectation  <br><br>we may differentiate under the integral sign (assuming sufficient smoothness and integrability) to obtain the unbiased pathwise derivative:  <br><br>By drawing  and computing  <br><br>we obtain an unbiased Monte Carlo estimator with variance often much lower than the score‐function approach, because it does not multiply by the typically large term .<br>The efficiency of the pathwise estimator hinges on the smoothness of  and : if  or  grow rapidly, the variance can still be large.  In many latent‐variable models one uses the Gaussian reparameterization  <br><br>so that  <br><br>and the estimator becomes  <br><br>Under mild conditions (e.g.\  Lipschitz in ), this estimator achieves  error with a smaller constant than the score‐function method.  When reparameterization is not available—for instance with discrete —one resorts to continuous relaxations or the score‐function gradient with control variates.  <br><br>We estimate  <br>whose true gradient is  <br>Using the pathwise method, write <br>so  <br>Hence each sample contributes  <br><br>At  take  samples from , say <br>Then  <br>and the per‐sample gradients are <br>The Monte Carlo estimate is  <br><br><br>The likelihood‐ratio method, also known as the score‐function estimator, provides a way to compute gradients of expectations even when the integrand is not differentiable in the random variable.  For a parameterized density  and a function , consider  <br><br>Under mild conditions permitting interchange of differentiation and integration,  <br><br>An unbiased Monte Carlo estimator then draws  i.i.d. and computes  <br><br>which converges almost surely to  and whose error scales like  by the Central Limit Theorem.<br>A major drawback is the high variance of .  One classical remedy is to subtract a baseline —any function independent of —yielding  <br><br>Choosing  minimizes the variance in one dimension; in practice, one uses learned or parametric baselines (e.g.\ value‐function estimates) and general control‐variates to further reduce variance.  Rao–Blackwellization over parts of the sampling process is another common technique.<br><br>We estimate  <br><br>so that  and the true gradient is .  The score‐function estimator is  <br><br>Take , , and suppose our samples are  <br><br>Then  <br><br>Multiplying,<br><br>and averaging gives  <br><br>Thus with  we overshoot the true gradient .<br>To reduce variance we introduce the baseline  and use  <br><br>Here , so  <br><br>and averaging yields  <br><br>This is much closer to  and has lower sample variance than the unguided estimator.  <br><br>Suppose we wish to estimate the sensitivity  <br><br>but cannot differentiate under the expectation analytically.  A simple approach is the forward‐difference Monte Carlo estimator: draw  and  independently, then form  <br><br>By Taylor’s theorem, the bias of this estimator is  <br><br>so it is  biased.  One can symmetrize to obtain a central‐difference version <br><br>which reduces the bias to  at the cost of two simulations per sample.<br>The variance of  is  <br><br>so .  Balancing squared bias  against variance  yields the optimal step‐size  <br><br>and a minimal mean squared error  <br><br>which is slower than the  of score‐function or pathwise methods, but avoids analytic gradients.  In practice one selects  by pilot runs or adaptive schemes to approach this  scaling, ensuring a balance between bias and Monte Carlo variance.  <br><br><br>Infinitesimal Perturbation Analysis (IPA) estimates the derivative  <br><br>by differentiating the sample‐path performance function  directly with respect to .  Let  be the collection of all random inputs driving a stochastic system, and assume for almost every  the mapping  is differentiable.  Then under a dominated‐convergence or bounded‐influence condition,  <br><br>so one obtains an unbiased estimator by simulating  i.i.d.\ and computing  <br><br>Key to IPA is that randomness in sample paths does not break differentiability: events such as queue emptiness or barrier crossings must occur on sets of probability zero where the path function is non‐smooth.  Under non‐atomicity and regularity (no simultaneous discontinuities), IPA yields exact gradients at zero bias.<br>IPA’s validity hinges on two main conditions:  <br>
<br>Pathwise differentiability: for almost all sample realizations , the trajectory  is continuously differentiable near .  
<br>Bounded influence: there exists an integrable random variable  such that  
<br><br>   ensuring  so interchange of  and  is justified.<br>Under these,  is unbiased and by the Central Limit Theorem satisfies  <br><br>with  <br><br>Often  is dramatically lower than finite‐difference or score‐function methods because no differencing amplifies noise. <br><br>Consider a discrete‐time system  <br><br>where  is the state at step ,  the input, and  a vector of parameters.  To track the sensitivity  one differentiates through the update:  <br><br>Here  and  are evaluated at the current .  Starting from  (often  if  is fixed), this recursion builds the full Jacobian of the state trajectory with linear‐cost per step.<br>Suppose an output or cost is defined at the final time  by  <br><br>Then its gradient follows by  <br><br>In continuous‐time settings, with  <br><br>the sensitivity  satisfies the variational equation  <br><br>and the gradient of a terminal cost  is  <br><br><br><br>Infinitesimal Perturbation Analysis typically assumes that the system’s evolution is piecewise deterministic: between random event times the state  follows a smooth trajectory governed by ordinary differential equations or difference equations, and randomness enters only through the timing or type of discrete events.  Concretely, if  are the successive event times, then on each interval  the state solves  <br><br>or the corresponding discrete‐time update, with  determined by a reset map at the event.  For IPA to apply, each trajectory segment must be differentiable in , and the jump map must be differentiable at each event.  <br>Equally crucial is the differentiability of the event‐time functions .  Often events are defined by hitting a boundary or zero‐crossing of a smooth function , so that  <br><br>Under a transversality condition—namely that —the implicit‐function theorem guarantees  is continuously differentiable in a neighborhood of the true parameter.  Together, these requirements ensure each sample path  is piecewise smooth with only finitely many differentiable discontinuities, so that  exists almost surely.<br><br>Given these regularity conditions, one invokes dominated‐convergence or Leibniz‐integral theorems to interchange differentiation and expectation:  <br><br>A sufficient condition is the existence of an integrable majorant  such that  <br><br>which holds when the vector‐field derivatives, jump‐map derivatives, and event‐time derivatives are all uniformly bounded in expectation.  Under these assumptions the IPA estimator  <br><br>is unbiased, i.e.\ , and satisfies a central‐limit theorem with variance determined by .  In practice, ensuring transversality (no glancing trajectories), non‐simultaneity of events, and bounded influence of parameter perturbations delivers both correctness and finite variance of the gradient estimate.<br><br>We illustrate IPA on a simple discrete‐time model  <br><br>with random inputs .  Take one sample path  and set .  The performance is  <br><br>Unrolling the recursion gives  <br><br>so analytically  <br><br>With sample‐path differentiation we track sensitivities  <br><br>Since , the update  <br><br>gives  <br><br>Thus the IPA estimator for this sample is  <br><br>which at (for example)  equals , matching the analytic derivative.<br>Because  was arbitrary and the mapping  is smooth for all , we have  <br><br>so simulating many i.i.d.\ copies  and averaging their  gives an unbiased estimator.  <br><br>from __future__ import annotations

import math
from typing import Callable, Tuple, Literal

import numpy as np

ArrayLike = np.ndarray  # shorthand type alias

__all__ = [
    # integration + variance reduction
    "monte_carlo",
    "importance_sampling",
    "control_variate",
    "stratified_sampling",
    "confint",
    # gradient estimators
    "score_function_gradient",
    "pathwise_gradient",
    "gaussian_smoothing_gradient",
    "spsa_gradient",
    "finite_difference_forward",
    "finite_difference_central",
    "ipa_discrete_time",
]

###############################################################################
# Basic Monte‑Carlo integration                                              #
###############################################################################

def monte_carlo(
    f: Callable[[ArrayLike], ArrayLike],
    sampler: Callable[[int], ArrayLike],
    n: int,
    *,
    return_se: bool = False,
) -&gt; Tuple[float, float] | float:
    """Crude Monte‑Carlo estimator (Eq. \hat I_N)."""
    x = sampler(n)
    fx = f(x)
    est = float(np.mean(fx))
    if return_se:
        se = float(np.std(fx, ddof=1) / math.sqrt(n))
        return est, se
    return est

###############################################################################
# Importance sampling                                                        #
###############################################################################

def importance_sampling(
    f: Callable[[ArrayLike], ArrayLike],
    q_sampler: Callable[[int], ArrayLike],
    w: Callable[[ArrayLike], ArrayLike],
    n: int,
    *,
    return_se: bool = False,
) -&gt; Tuple[float, float] | float:
    """Importance‑sampling estimator (Eq. \hat I_N^{IS})."""
    x = q_sampler(n)
    fx = f(x) * w(x)
    est = float(np.mean(fx))
    if return_se:
        se = float(np.std(fx, ddof=1) / math.sqrt(n))
        return est, se
    return est

###############################################################################
# Control variates                                                          #
###############################################################################

def control_variate(
    f: Callable[[ArrayLike], ArrayLike],
    g: Callable[[ArrayLike], ArrayLike],
    g_mean: float,
    sampler: Callable[[int], ArrayLike],
    n: int,
    *,
    c: float | None = None,
    return_se: bool = False,
) -&gt; Tuple[float, float] | float:
    """Control‑variate estimator ``f(X) − c(g(X) − g_mean)``."""
    x = sampler(n)
    f_vals, g_vals = f(x), g(x)
    if c is None:
        cov_fg = np.cov(f_vals, g_vals, ddof=1)[0, 1]
        var_g = np.var(g_vals, ddof=1)
        c = cov_fg / var_g if var_g &gt; 0 else 0.0
    adjusted = f_vals - c * (g_vals - g_mean)
    est = float(np.mean(adjusted))
    if return_se:
        se = float(np.std(adjusted, ddof=1) / math.sqrt(n))
        return est, se
    return est

###############################################################################
# Stratified sampling                                                       #
###############################################################################

def stratified_sampling(
    f: Callable[[ArrayLike], ArrayLike],
    strata_samplers: list[Callable[[int], ArrayLike]],
    weights: list[float] | None = None,
    n: int = 10_000,
    *,
    return_se: bool = False,
) -&gt; Tuple[float, float] | float:
    """One‑dimensional stratified estimator with proportional allocation."""
    k = len(strata_samplers)
    if weights is None:
        weights = [1 / k] * k
    weights = np.asarray(weights, dtype=float)
    if not np.isclose(weights.sum(), 1.0):
        raise ValueError("weights must sum to 1")

    per = np.maximum((weights * n).astype(int), 1)
    ests, vars_ = [], []
    for ns, w_s, sampler in zip(per, weights, strata_samplers):
        x = sampler(int(ns))
        fx = f(x)
        ests.append(w_s * np.mean(fx))
        vars_.append((w_s**2) * np.var(fx, ddof=1) / ns)

    est = float(np.sum(ests))
    if return_se:
        se = float(math.sqrt(np.sum(vars_)))
        return est, se
    return est

###############################################################################
# Confidence interval helper                                                #
###############################################################################

def _z_critical(alpha: float) -&gt; float:
    try:
        from scipy.stats import norm

        return float(norm.ppf(1 - alpha / 2))
    except ModuleNotFoundError:  # Fallback: inverse‑erf approximation
        return float(math.sqrt(2) * math.erfcinv(alpha))

def confint(mean: float, se: float, alpha: float = 0.05) -&gt; tuple[float, float]:
    """Two‑sided (1‑α) confidence interval via the CLT."""
    z = _z_critical(alpha)
    return mean - z * se, mean + z * se

###############################################################################
# Gradient estimators                                                       #
###############################################################################

def score_function_gradient(
    f: Callable[[ArrayLike], ArrayLike],
    log_p_grad: Callable[[ArrayLike], ArrayLike],
    sampler: Callable[[int], ArrayLike],
    n: int,
    *,
    baseline: float | Callable[[ArrayLike], ArrayLike] | None = None,
) -&gt; np.ndarray:
    """Score‑function (likelihood‑ratio) gradient."""
    x = sampler(n)
    fx = f(x)
    if baseline is not None:
        b = baseline(x) if callable(baseline) else baseline
        fx = fx - b
    score = log_p_grad(x)
    return np.mean(fx[:, None] * score, axis=0)

###############################################################################
# Pathwise (re‑parameterisation) gradient                                   #
###############################################################################

def pathwise_gradient(
    df_dx: Callable[[ArrayLike], ArrayLike],
    T: Callable[[ArrayLike, ArrayLike], ArrayLike],
    dT_dtheta: Callable[[ArrayLike, ArrayLike], ArrayLike],
    base_sampler: Callable[[int], ArrayLike],
    theta: ArrayLike,
    *,
    n: int,
) -&gt; np.ndarray:
    """Pathwise (re‑parameterisation) gradient (Eq. \hat g_{PW})."""
    u = base_sampler(n)
    x = T(u, theta)
    df = df_dx(x)
    dT = dT_dtheta(u, theta)
    grad_samples = df[:, None] * dT
    return np.mean(grad_samples, axis=0)

###############################################################################
# Gaussian‑smoothing gradient                                               #
###############################################################################

def gaussian_smoothing_gradient(
    f: Callable[[ArrayLike, ArrayLike], ArrayLike],
    theta: ArrayLike,
    h: float,
    sample_x: Callable[[ArrayLike, int], ArrayLike],
    *,
    n: int,
) -&gt; np.ndarray:
    """Gaussian‑smoothing gradient (randomised finite‑difference)."""
    d = theta.shape[0]
    u = np.random.randn(n, d)
    grads = []
    for ui in u:
        x_i = sample_x(theta + h * ui, 1)
        fi = f(x_i, theta + h * ui)
        grads.append(fi * ui / h)
    return np.mean(grads, axis=0)

###############################################################################
# SPSA gradient                                                             #
###############################################################################

def spsa_gradient(
    f: Callable[[ArrayLike], float],
    theta: ArrayLike,
    h: float,
    *,
    delta_sampler: Callable[[int, int], ArrayLike] | None = None,
    n: int = 1,
) -&gt; np.ndarray:
    """Simultaneous perturbation SPSA gradient averaged over *n* probes."""
    d = theta.shape[0]
    if delta_sampler is None:
        delta_sampler = lambda m, k: np.random.choice([-1.0, 1.0], size=(m, k))
    deltas = delta_sampler(n, d)
    grads = []
    for delta in deltas:
        f_plus = f(theta + h * delta)
        f_minus = f(theta - h * delta)
        grads.append(0.5 * (f_plus - f_minus) / h * delta)
    return np.mean(grads, axis=0)

###############################################################################
# Finite‑difference Monte‑Carlo gradients                                   #
###############################################################################

def _fd_samples(
    sampler: Callable[[ArrayLike, int], ArrayLike],
    theta: ArrayLike,
    h: float,
    n: int,
    scheme: Literal["forward", "central"],
):
    if scheme == "forward":
        x = sampler(theta, n)
        y = sampler(theta + h, n)
        return (x, theta), (y, theta + h)
    elif scheme == "central":
        y_plus = sampler(theta + h, n)
        y_minus = sampler(theta - h, n)
        return (y_minus, theta - h), (y_plus, theta + h)
    else:
        raise ValueError("scheme must be 'forward' or 'central'")

def _finite_difference_core(
    f: Callable[[ArrayLike, ArrayLike], ArrayLike],
    sampler: Callable[[ArrayLike, int], ArrayLike],
    theta: ArrayLike,
    h: float,
    n: int,
    scheme: Literal["forward", "central"],
) -&gt; np.ndarray:
    (x1, th1), (x2, th2) = _fd_samples(sampler, theta, h, n, scheme)
    f1 = f(x1, th1)
    f2 = f(x2, th2)
    diff = f2 - f1
    if scheme == "forward":
        return np.mean(diff, axis=0) / h
    else:  # central
        return np.mean(diff, axis=0) / (2 * h)

def finite_difference_forward(
    f: Callable[[ArrayLike, ArrayLike], ArrayLike],
    sampler: Callable[[ArrayLike, int], ArrayLike],
    theta: ArrayLike,
    h: float,
    *,
    n: int,
) -&gt; np.ndarray:
    """Forward‑difference Monte‑Carlo gradient (bias O(h))."""
    return _finite_difference_core(f, sampler, theta, h, n, "forward")

def finite_difference_central(
    f: Callable[[ArrayLike, ArrayLike], ArrayLike],
    sampler: Callable[[ArrayLike, int], ArrayLike],
    theta: ArrayLike,
    h: float,
    *,
    n: int,
) -&gt; np.ndarray:
    """Central‑difference Monte‑Carlo gradient (bias O(h²))."""
    return _finite_difference_core(f, sampler, theta, h, n, "central")

###############################################################################
# Infinitesimal Perturbation Analysis (IPA) – discrete‑time                 #
###############################################################################

def ipa_discrete_time(
    f: Callable[[float, float, float], float],
    f_x: Callable[[float, float, float], float],
    f_theta: Callable[[float, float, float], float],
    g: Callable[[float, float], float],
    g_x: Callable[[float, float], float],
    g_theta: Callable[[float, float], float],
    input_sampler: Callable[[int], ArrayLike],
    theta: float,
    x0: float,
    n_steps: int,
    *,
    n_paths: int = 1,
    return_se: bool = False,
) -&gt; Tuple[float, float] | float:
    grads = []
    for _ in range(n_paths):
        x, S = x0, 0.0  # state and sensitivity
        u_seq = input_sampler(n_steps)
        for u_k in u_seq:
            S = f_x(x, u_k, theta) * S + f_theta(x, u_k, theta)
            x = f(x, u_k, theta)
        grad_path = g_x(x, theta) * S + g_theta(x, theta)
        grads.append(grad_path)

    grads = np.asarray(grads, dtype=float)
    est = float(np.mean(grads))
    if return_se:
        se = float(np.std(grads, ddof=1) / math.sqrt(n_paths))
        return est, se
    return est

###############################################################################
# Demonstration when executed directly                                      #
###############################################################################
def test():
    np.random.seed(0)

    print("== IPA demo for x_{k+1} = θ x_k + u_k, L = x_2   ==")
    theta = 2.0
    x0 = 1.0
    n_steps = 2

    f  = lambda x, u, th: th * x + u
    f_x      = lambda x, u, th: th          # ∂f/∂x = θ
    f_theta  = lambda x, u, th: x           # ∂f/∂θ = x_k

    g = lambda x, th: x                     # L = x_N
    g_x     = lambda x, th: 1.0             # ∂g/∂x = 1
    g_theta = lambda x, th: 0.0             # ∂g/∂θ = 0

    input_sampler = lambda m: np.random.randint(0, 3, size=m)  # u_k ∈ {0,1,2}

    grad_est, se = ipa_discrete_time(
        f, f_x, f_theta, g, g_x, g_theta,
        input_sampler, theta, x0, n_steps, n_paths=50_000, return_se=True,
    )
    true_grad = 2 * theta + 1
    print(f"IPA estimate ≈ {grad_est:.3f} ± {1.96*se:.3f} (95% CI)")
    print(f"Analytic true value = {true_grad}")

    print("\n== Pathwise derivative demo for F(θ)=E[(θ+U)²] ==")
    df_dx = lambda x: 2 * x
    T = lambda u, th: th + u
    dT_dtheta = lambda u, th: np.ones_like(u)
    base_sampler = lambda n: np.random.randn(n)
    pw_grad = pathwise_gradient(df_dx, T, dT_dtheta, base_sampler, np.array([1.0]), n=10_000)
    print("Pathwise gradient ≈", pw_grad)
<br><br><a class="internal-link" data-href="Appendix-VI##Error-Measurement" href="appendix-vi.html#" target="_self" rel="noopener nofollow">Error Analysis Reference</a>]]></description><link>ch08-numerical-differenciation.html</link><guid isPermaLink="false">CH08-Numerical-Differenciation.md</guid><pubDate>Thu, 17 Jul 2025 19:31:32 GMT</pubDate><enclosure url="assets/pasted-image-20250614195240.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;assets/pasted-image-20250614195240.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[CH09-Numerical-Integration]]></title><description><![CDATA[ 
 <br><br>To approximate  <br><br>one replaces the continuous problem by a discrete sum over  subintervals of width .  In the trapezoidal rule, for example,  <br><br>The difference  <br><br>is the truncation error, which can be shown by the Euler–Maclaurin expansion to satisfy  <br><br>Thus the error decays like  as .  In Simpson’s rule, combining parabolic fits over pairs of intervals yields  <br><br>with truncation error  <br><br>so the convergence is .  In every case the key assumption is sufficient smoothness of  (existence of bounded derivatives up to the order appearing in the error term) and uniform partitioning of .<br>Floating‐point arithmetic introduces round-off errors when each arithmetic operation rounds to machine precision .  If one computes a sum of  terms, the worst‐case accumulation of rounding can be modeled by  <br><br>so that the total round-off error behaves like .  In quadrature this affects both the evaluation of  and the weight summation.  One often writes the total error as  <br><br>where  for some modest constant .  As  grows,  decreases (since  shrinks) but  grows, so there is an optimal  balancing these: solving  <br><br>where  for trapezoidal and  for Simpson.  Ensuring numerical stability thus requires both choosing a rule with suitable order and avoiding excessive subdivision that amplifies round-off.  <br><br><br>The trapezoidal rule is the closed Newton–Cotes formula of degree 1, obtained by interpolating  on each subinterval  by the unique linear polynomial through  and .  Writing  and , the one‐panel rule on  is  <br><br>Summing over  gives the composite trapezoidal rule  <br><br>which exactly integrates all polynomials of degree  and arises from the Newton–Cotes weights ,  for .<br>If , the local error on each panel satisfies by Peano’s kernel theorem  <br><br>Summing gives the global truncation error  <br><br>so .  Round‐off error in floating‐point evaluation accumulates on the order of , leading to an optimal panel count  when balancing  truncation against round‐off growth.  The composite trapezoidal rule also exhibits periodic accuracy: if  is smooth and periodic on , then aliasing errors cancel and convergence can be spectral rather than algebraic.  <br>def trapezoidal(f, a, b, n):
    if n &lt;= 0:
        raise ValueError("Number of panels n must be a positive integer.")
    h = (b - a) / n
    # End‐point contributions
    s = f(a) + f(b)
    # Interior points each counted twice
    for i in range(1, n):
        x = a + i*h
        s += 2 * f(x)
    return (h/2) * s
<br><br>We approximate<br>
by the composite trapezoidal rule with  panels.  Here  and the nodes are  <br>We tabulate  <br><br>The composite rule is  <br><br>Inside the parentheses we have  <br><br>so  <br><br>The exact integral is  <br><br>so the error is  <br><br>Peano’s kernel theorem predicts on each subinterval  a local error  <br><br>and since (f''(x)=2) is constant, this is  <br><br>per panel.  Summing over (n=4) panels gives the global error  <br><br>matching the computed .  Thus the composite trapezoidal rule indeed yields  accuracy with  <br><br><br>Let  be partitioned into  subintervals of equal width , with  even and nodes .  On each pair of subintervals  we interpolate  by the unique quadratic through , , .  A straightforward integration of the Lagrange form shows the two‐panel rule  <br><br>Summing over  yields the composite Simpson’s 1/3 rule:  <br><br>This formula exactly integrates all polynomials of degree  and follows from the closed Newton–Cotes weights  on each quadratic panel.<br>If , then on each two‐panel interval there exists  such that  <br><br>Summing these yields the global error  <br><br>so .  The fourth‐order convergence means that halving  reduces the error by a factor of , allowing high accuracy with relatively coarse partitions.  In floating‐point arithmetic round‐off error accumulates like , so one balances  truncation error against  growth to choose an optimal .  <br>def simpson(f, a, b, n):
    if n &lt;= 0 or n % 2 != 0:
        raise ValueError("Number of panels n must be a positive even integer.")
    h = (b - a) / n

    # End‐point contributions
    total = f(a) + f(b)

    # 4 * sum over odd i
    for i in range(1, n, 2):
        x = a + i * h
        total += 4 * f(x)

    # 2 * sum over even i (excluding endpoints)
    for i in range(2, n, 2):
        x = a + i * h
        total += 2 * f(x)

    return (h / 3) * total
<br><br>We approximate  <br>by Simpson’s 1/3 rule with  panels.  Here  and the nodes are  <br>We tabulate  <br>On the single two‐panel interval  Simpson’s formula gives <br><br>The exact value is  <br><br>so the error is  <br><br>Peano’s kernel theorem predicts on  a local error  <br><br>and the global error formula  <br><br>matches the computed difference.  Thus Simpson’s rule indeed achieves  accuracy, halving  would reduce the error by a factor of .  <br><br>The Simpson’s 3/8 rule extends the closed Newton–Cotes framework by using a cubic interpolant over four equally spaced nodes.  Partition  into  subintervals of width  with  a multiple of 3, and set .  On each block  the unique cubic through the points , , integrates exactly to  <br><br>Summing over  gives the composite rule  <br><br>which exactly integrates all polynomials of degree  and pairs naturally with Simpson’s 1/3 rule when  is not a multiple of 3.<br>Assuming , on each three‐panel segment there is some  for which the local truncation error satisfies  <br><br>Summing yields the global error  <br><br>so that .  In floating‐point implementations round‐off accumulates on the order of , and the divisibility requirement  may necessitate mixing 1/3‐rule panels at the ends.  The 3/8 rule’s uniform fourth‐order accuracy on cubic‐exact functions makes it a valuable tool in composite and adaptive quadrature schemes.  <br>def simpson38(f, a, b, n):
    if n &lt;= 0 or n % 3 != 0:
        raise ValueError("n must be a positive multiple of 3")
    h = (b - a) / n
    s = f(a) + f(b)
    for i in range(1, n):
        x = a + i * h
        s += (3 if i % 3 != 0 else 2) * f(x)
    return (3*h/8) * s
<br><br>We approximate  <br>by the composite Simpson’s 3/8 rule with  (so ).  Here  <br>and  <br><br>On  Simpson’s 3/8 rule gives  <br><br>Inside the parentheses:  <br><br>so  <br><br>The exact integral is  <br><br>hence the error is  <br><br>Peano’s kernel theorem predicts on  a local error  <br><br>Since , this lies between  <br><br>and summing the single block gives the global error  <br><br>with , consistent with the observed .  Thus even for the non‐polynomial , Simpson’s 3/8 rule achieves  accuracy.  <br><br>Boole’s rule is the closed Newton–Cotes formula of degree 4, obtained by interpolating a smooth function  on each block of four equal subintervals  by the unique quartic polynomial through the five equally spaced points  <br><br>where  and  with  a multiple of 4.  Writing the Lagrange basis polynomials  <br><br>one integrates term by term to obtain the local quadrature rule  <br><br>Applying this four‐panel rule on successive blocks  yields the composite Boole’s rule  <br><br>which integrates exactly all polynomials of degree  by virtue of its Newton–Cotes weights .<br>Assuming , the local truncation error on each block can be derived via the Peano kernel or a remainder term in Newton–Cotes theory, yielding for some   <br><br>Since there are  such blocks, the global error satisfies  <br><br>so —halving  reduces the error by .  Equivalently, one may express the leading constant in terms of the <a class="internal-link" data-href="Appendix-V" href="appendix-v.html" target="_self" rel="noopener nofollow">Bernoulli number</a> , since  <br><br>Unlike higher‐degree Newton–Cotes rules (degree ) whose weights can become negative and unstable, Boole’s rule weights remain positive, ensuring good stability for smooth integrands.  The requirement  can be handled in practice by pairing Boole blocks with Simpson’s 1/3 or 3/8 panels at one end.  In floating‐point arithmetic, accumulated round‐off error grows like , so the optimal panel count balances  truncation decay against  growth, typically giving  for double precision.  <br><br><br>In a closed Newton–Cotes rule of degree , one uses the endpoints and equally spaced interior points  <br><br>The quadrature takes the form  <br><br>where the weights  arise from the Lagrange basis  <br><br>In contrast, an open Newton–Cotes rule of degree  excludes the endpoints and uses the interior points <br><br>yielding  <br><br>with weights  <br><br>Common examples include the midpoint rule ( open), which is exact for degree , and the two‐point open rule () exact for degree :<br><br>Both families share an error term given by the Peano kernel for interpolation on  (or ), but the closed rule of degree  has truncation error  <br><br>whereas the open rule of degree  has  <br><br>However, open rules often achieve a higher degree of exactness relative to the number of points: an open rule with  nodes is exact for polynomials up to degree , whereas the closed rule with the same number of interior points (plus endpoints) is exact only to degree .  Open rules avoid endpoint singularities—useful when  is undefined or non‐smooth at  or —but may exhibit larger constants in the error term due to the shifted kernel integrals.  In practice one chooses closed rules when  is smooth on the entire interval and open rules when endpoint behavior degrades accuracy or stability.<br><br>Let  and partition  into  subintervals of equal width .  On each subinterval  one takes the midpoint  <br><br>and approximates  <br><br>The composite midpoint rule is then  <br><br>This rule is the open Newton–Cotes formula of degree 1 (it uses one interior point per panel) and is exact for all polynomials of degree .<br>By Taylor’s theorem, on each panel there exists  such that  <br><br>Summing over  gives the global error  <br><br>so .  Note that the midpoint rule’s error constant  is half that of the trapezoidal rule’s , making it more accurate per panel despite requiring only one function evaluation.  In floating‐point arithmetic, round‐off accumulates like , so to minimize total error one balances  truncation against  growth, typically choosing .  <br>def midpoint(f, a, b, n):
    if n &lt;= 0:
        raise ValueError("n must be a positive integer")
    h = (b - a) / n
    s = 0.0
    for i in range(1, n+1):
        m = a + (i - 0.5) * h
        s += f(m)
    return h * s
<br><br>We approximate  <br>by the composite midpoint rule with .  Here  <br>so the midpoints are  <br><br>We compute  <br><br>Summing these values gives  <br>so the composite midpoint rule yields  <br><br>The true value (to high precision) is  <br>so the error is  <br><br>By Taylor’s theorem on each panel there exists  such that  <br><br>where  <br><br>On , .  Hence the global error satisfies  <br><br>in good agreement with the observed .  <br><br>Divide  into  panels of equal width .  On each panel , let  <br><br>and approximate  <br><br>Since  and  are the two interior nodes of the open Newton–Cotes rule of degree 1, this is called the open trapezoidal or two‐point open rule.  Summing over  gives the composite formula  <br><br>This rule is exact for all polynomials of degree .<br>If , then on each panel there exists  such that  <br><br>Summing over  yields the global truncation error  <br><br>so  and halving  reduces the error by a factor of 4.  Because only interior points are used, this rule avoids evaluating  at  or , which is advantageous when  is singular or noisy at the endpoints.  In floating‐point arithmetic round‐off accumulates like , so one balances the  truncation decay against  growth to choose an optimal panel count .  <br>def open_trapezoidal(f, a, b, n):
    if n &lt;= 0:
        raise ValueError("n must be a positive integer")
    H = (b - a) / n
    s = 0.0
    for i in range(1, n+1):
        s += f(a + (i - 2/3) * H) + f(a + (i - 1/3) * H)
    return H/2 * s
<br><br>We approximate  <br>by the composite open‐trapezoidal rule with .  Here  <br>and for each panel  the interior nodes are  <br><br>Thus  <br><br>We compute  <br><br>Summing  <br><br>The composite rule is<br><br>The true value  <br><br>so the error is  <br><br>By Taylor’s theorem on each panel there exists  such that  <br><br>and summing gives the global error  <br><br>Since  <br><br>we have  and , so  <br><br>which easily contains the observed .  Thus the composite open trapezoidal rule achieves the expected  accuracy even for the challenging integrand , using only interior evaluations and avoiding the endpoints.  <br><br>Composite quadrature rules achieve high accuracy by applying a simple one‐panel rule repeatedly over a uniform (or adaptive) partition of .  Let the interval be split by  <br><br>and let  denote any basic rule (midpoint, trapezoidal, Simpson, etc.) on the single panel .  The composite rule is simply  <br><br>For a uniform mesh , this often collapses to a weighted sum  <br><br>where the weights  assemble the contributions of each panel.  Because each panel exactly integrates polynomials up to degree , the composite rule is exact for all polynomials of degree , and its global error is dictated by how the local error accumulates.<br>If the one‐panel rule has local truncation error  (for degree– exactness), then summing over  panels gives a global error  <br><br>In particular, halving  reduces  by a factor of .  In floating‐point arithmetic one also incurs round‐off error of size , so there is an optimal panel count balancing  <br><br>Adaptive composite schemes refine  where  is large, using local error estimators to control tolerance.  Composite rules are simple to implement, trivially parallelizable over panels, and provide a robust foundation for more sophisticated methods such as Gaussian quadrature or spectral collocation.  <br><br>Let  and partition the interval into  subintervals of equal width  <br><br>On each panel  the trapezoidal approximation  <br><br>is exact for all polynomials of degree .  Summing over  yields the composite trapezoidal rule  <br><br>Implementation requires  function evaluations and  arithmetic operations.  One may view  as a discrete convolution of  with the weights , highlighting its role in filter‐based approximations.<br>If , then by applying the Euler–Maclaurin expansion up to the second term, there exists  such that  <br><br>so that the global error is .  More precisely, the Euler–Maclaurin formula gives for any integer   <br><br>where  are Bernoulli numbers and the remainder .  In the periodic case  for all , all boundary terms vanish, yielding  <br><br>i.e.\ spectral convergence for analytic periodic functions.  <br><br>Let  and partition  into  even subintervals of width  <br><br>On each pair of subintervals , the two-panel Simpson’s 1/3 approximation is  <br><br>Summing over  yields the composite rule  <br><br>which exactly integrates all polynomials of degree  using  function evaluations and  operations.<br>If , then by the remainder term in Newton–Cotes there exists  such that <br><br>so the global error is , and halving  reduces the error by a factor of .  In floating-point arithmetic, round-off accumulates like , so balancing  truncation decay against  growth suggests an optimal panel count .  <br><br>We approximate  <br>by both the composite trapezoidal rule and composite Simpson’s 1/3 rule with  subintervals.  Here  <br><br>and  <br><br>Composite trapezoidal rule  <br><br>Compute the interior sum  <br><br>so  <br><br>hence  <br><br>Composite Simpson’s 1/3 rule  <br><br>The odd‐index sum is  <br><br>so .  The even‐index sum is  <br><br>so .  Including , we get  <br><br>The exact integral is  <br><br>so the errors are  <br><br>Error estimates.  Since  <br><br>the trapezoidal‐rule bound  <br><br>comfortably contains .  And since  <br><br>the Simpson‐rule bound  <br><br>covers the observed .  <br><br>def composite_trapezoidal(f, a, b, n):
    h = (b - a) / n
    s = f(a) + f(b)
    for i in range(1, n):
        s += 2 * f(a + i*h)
    return (h/2) * s

def composite_simpson(f, a, b, n):
    if n % 2 != 0:
        raise ValueError("n must be even")
    h = (b - a) / n
    s = f(a) + f(b)
    for i in range(1, n, 2):
        s += 4 * f(a + i*h)
    for i in range(2, n, 2):
        s += 2 * f(a + i*h)
    return (h/3) * s
<br><br><br>The adaptive trapezoidal rule seeks to concentrate effort where the integrand  varies most, by recursively subdividing intervals until a local error estimate meets a user‐specified tolerance.  Beginning with the whole interval , one computes the coarse trapezoidal approximation  <br><br>and then the “refined’’ estimate on two halves, <br><br>where  <br><br>A simple error indicator is  <br><br>motivated by the fact that the trapezoidal rule’s global error scales like , so halving  reduces the error by roughly a factor of 4.  If  exceeds the local tolerance, one splits  at  and applies the same procedure to each subinterval, accumulating results when each segment meets its tolerance.  This produces a hierarchy of panel widths adapted to the curvature of .<br>On each panel of width , the local truncation error of the trapezoidal rule satisfies  <br><br>so that the estimate  <br><br>behaves like , justifying the division by 3 in the error indicator.  Globally, the adaptive algorithm achieves an overall error  with a number of panels proportional to the integral of  over , rather than uniform refinement’s proportionality to .  In practice this yields substantial savings when  has localized features.  Convergence remains second‐order in the sense that halving the tolerance typically doubles the number of panels, and the total cost scales like  where  is the final panel count. <br><br>Adaptive Simpson’s Rule builds on the composite Simpson’s 1/3 rule by recursively subdividing intervals until a local error criterion is met.  On an interval  let  <br><br>be the Simpson estimate.  Denote  and form the “refined” estimate  <br><br>Since Simpson’s rule has local truncation error  <br><br>halving the width reduces this error by a factor of .  Thus a practical error indicator is  <br><br>motivated by Richardson extrapolation.  If  exceeds the user’s tolerance on , the algorithm splits at  and applies the same procedure to  and , otherwise it accepts  as the interval contribution.<br>Under the assumption , the adaptive scheme guarantees that on each final panel of width ,  <br><br>so the global error is bounded by the prescribed tolerance.  Because panels are refined only where  is large, the total number of intervals grows like  <br><br>rather than  for uniform Simpson.  Convergence remains effectively  locally, and halving  typically increases the panel count by a factor of .  <br>def adaptive_trapezoidal(f, a, b, tol):
    def recurse(a, b, fa, fb, T_ab, tol):
        m = (a + b) / 2
        fm = f(m)
        T_am = (m - a) / 2 * (fa + fm)
        T_mb = (b - m) / 2 * (fm + fb)
        T_ref = T_am + T_mb
        E = (T_ref - T_ab) / 3
        if abs(E) &lt;= tol:
            return T_ref + E
        return (recurse(a, m, fa, fm, T_am, tol/2) +
                recurse(m, b, fm, fb, T_mb, tol/2))

    fa, fb = f(a), f(b)
    T_ab = (b - a) / 2 * (fa + fb)
    return recurse(a, b, fa, fb, T_ab, tol)


def adaptive_simpson(f, a, b, tol):
    def recurse(a, b, fa, fm, fb, S_ab, tol):
        m = (a + b) / 2
        lm = (a + m) / 2
        rm = (m + b) / 2
        flm, frm = f(lm), f(rm)
        S_am = (m - a) / 6 * (fa + 4*flm + fm)
        S_mb = (b - m) / 6 * (fm + 4*frm + fb)
        S_ref = S_am + S_mb
        E = (S_ref - S_ab) / 15
        if abs(E) &lt;= tol:
            return S_ref + E
        return (recurse(a, m, fa, flm, fm, S_am, tol/2) +
                recurse(m, b, fm, frm, fb, S_mb, tol/2))

    fa, fb = f(a), f(b)
    m = (a + b) / 2
    fm = f(m)
    S_ab = (b - a) / 6 * (fa + 4*fm + fb)
    return recurse(a, b, fa, fm, fb, S_ab, tol)
<br><br>We approximate  <br><br>to a tolerance of  using the adaptive trapezoidal rule.  Set  <br><br>and use the error indicator  <br><br>Define .  First on :  <br><br>so  <br><br>At the midpoint ,<br><br>and  <br><br>Thus  <br><br>which exceeds , so we split.<br>On : .  <br><br>Compute  <br><br><br>so accept this panel with contribution  <br><br>On : .  <br><br><br><br><br>so split again at  and .<br>On : .  <br><br><br><br><br>accept with  <br><br>On : .  <br><br><br><br><br>so split again at  and .<br>On : .  <br><br><br><br><br>accept with  <br><br>On : .  <br><br><br><br><br>accept with  <br><br>Summing the accepted contributions on each subinterval gives  <br><br><br><br>Gauss–Legendre quadrature on the standard interval  seeks an -point rule  <br><br>which is exact for all polynomials of degree up to .  The nodes  are chosen as the  simple roots of the Legendre polynomial , defined by the orthogonality condition  <br><br>and the weights follow from requiring exactness on the Lagrange basis, yielding the closed-form  <br><br>Equivalently, one may compute  via the Golub–Welsch algorithm by forming the symmetric tridiagonal Jacobi matrix associated to the three-term recurrence of  and extracting its eigenpairs.  This construction guarantees the maximal algebraic precision and the positivity of all weights, ensuring stability for smooth integrands.<br>The remainder term for  can be written in closed form: there exists  such that  <br><br>This shows exponential convergence as  for analytic .  To apply on a general interval , one uses the affine change of variables  <br><br>so that  <br><br>import numpy as np

def gauss_legendre(n):
    i = np.arange(1, n)
    beta = i / np.sqrt((2*i-1)*(2*i+1))
    J = np.diag(beta, 1) + np.diag(beta, -1)
    x, V = np.linalg.eigh(J)
    w = 2 * V[0, :]**2
    return x, w

def integrate_gauss_legendre(f, a, b, n):
    x, w = gauss_legendre(n)
    t = 0.5*(b - a)*x + 0.5*(a + b)
    return 0.5*(b - a) * np.dot(w, f(t))
<br>Computation of eigenvalues will be detailed in <a class="internal-link" data-href="CH11-Linear-Algebra.md" href="ch11-linear-algebra.html" target="_self" rel="noopener nofollow">numerical linear algebra</a>. <br><br>We wish to approximate  <br><br>using the 3-point Gauss–Legendre rule (exact for polynomials up to degree 5).<br>First, on  the Legendre polynomial  <br><br>has roots given by  <br><br>Its derivative is  <br><br>so at   <br><br>and at   <br><br>The weights on  are  <br><br>Thus for   <br><br>and for   <br><br>To transform to , set  <br><br>Then  <br><br>Define  <br><br>Numerically,  <br><br><br>We now evaluate  <br><br>at these three points:<br>
<br>
At :<br>


<br>
At :<br>


<br>
At :<br>


<br>Finally, the Gauss–Legendre approximation is  <br><br>Thus with only three optimally chosen points we obtain  <br><br><br>Gauss–Chebyshev quadrature is tailored to integrals of the form  <br><br>with respect to the Chebyshev weight .  One seeks nodes  and positive weights  such that  <br><br>for all polynomials  of degree up to .  The nodes are the roots of the Chebyshev polynomial of the first kind , namely  <br><br>and the weights follow from the closed‐form  <br><br>Equivalently, one derives these by exploiting the three‐term recurrence for  and the discrete orthogonality of trigonometric moments.<br>For , the remainder satisfies  <br><br>showing spectral convergence for analytic .  <br>import math

def gauss_chebyshev(n):
    nodes = [math.cos((2*i - 1) * math.pi / (2*n)) for i in range(1, n+1)]
    weights = [math.pi / n] * n
    return nodes, weights

def integrate_chebyshev(f, n):
    nodes, weights = gauss_chebyshev(n)
    total = 0.0
    for x, w in zip(nodes, weights):
        total += w * f(x)
    return total
<br><br>We want to compute  <br><br>exactly and then approximate it by Gauss–Chebyshev quadrature for  and . <br>First, set , so  and .  When , .  Thus  <br><br>We use the beta‐integral or known formula  <br><br>so  <br><br>Gauss–Chebyshev quadrature for  <br><br>uses nodes  <br><br>Case .  Then :<br>
<br>Compute the arguments:


<br>Nodes:


<br>Evaluate :


<br>Weight:  for both .
<br>Quadrature sum:


<br>Error:


<br>Case .  Then :<br>
<br>Arguments:


<br>Nodes:


<br>Evaluate :


<br>Weights:  for each .
<br>Quadrature sum:


<br>Error:


<br><br>Gauss–Laguerre quadrature addresses integrals on  of the form  <br><br>One constructs an ‐point rule  <br><br>exact for all polynomials  of degree up to .  The nodes  are the roots of the th Laguerre polynomial , defined by the orthogonality  <br><br>with .  The weights are given by  <br><br>or more symmetrically  <br><br>For sufficiently smooth  decaying at infinity, the remainder can be expressed via a generalized Rodrigues’ formula, leading to  <br><br>which implies rapid convergence for analytic .  Gauss–Laguerre rules excel in expectation integrals of gamma‐type distributions, in quantum mechanical radial integrals, and in Laplace‐transform inversion where the  weight naturally captures the kernel decay.<br>import numpy as np

def gauss_laguerre(n):
    i = np.arange(1, n)
    a = 2*np.arange(n) + 1
    b = np.sqrt(i)
    # build Jacobi matrix
    J = np.diag(a) + np.diag(b, 1) + np.diag(b, -1)
    # eigen-decomposition
    x, V = np.linalg.eigh(J)
    # weights = first component squared
    w = V[0, :]**2
    return x, w

def integrate_gauss_laguerre(f, n):
    x, w = gauss_laguerre(n)
    return np.dot(w, f(x))
<br><br>We approximate  <br><br>using Gauss–Laguerre quadrature for  to illustrate convergence.<br>For  the Laguerre polynomial is  <br>with root  <br>and weight  <br><br>The one‐point rule gives  <br><br>while the exact value is  <br><br>so the error is .<br>For  the polynomial<br>
has roots  <br><br>The weights follow from  <br><br>so at  we have  and  <br><br>namely  <br><br>The two‐point rule yields  <br><br>recovering the exact value  (Gauss–Laguerre with  is exact for polynomials up to degree ).<br>For , one shows Gauss–Laguerre is exact through degree , so it also integrates  exactly.  Thus in all,  <br>
<br> fails badly (error ),  
<br> and  both give the exact result .  
<br>import math

def gauss_hermite(n, tol=1e-14, maxiter=100):
    nodes = []
    weights = []
    for i in range(1, n+1):
        x = math.sqrt(2*n+1) * math.cos(math.pi*(4*i-1)/(4*n+2))
        for _ in range(maxiter):
            Hm2, Hm1 = 0.0, 1.0
            for k in range(1, n):
                H = 2*x*Hm1 - 2*(k-1)*Hm2
                Hm2, Hm1 = Hm1, H
            Hn = 2*x*Hm1 - 2*(n-1)*Hm2
            dHn = 2*n*Hm1
            dx = Hn/dHn
            x -= dx
            if abs(dx) &lt; tol:
                break
        nodes.append(x)
        weights.append((2**(n-1) * math.factorial(n) * math.sqrt(math.pi)) / (n**2 * Hm1*Hm1))
    return nodes, weights

def integrate_gauss_hermite(f, n):
    xs, ws = gauss_hermite(n)
    s = 0.0
    for x, w in zip(xs, ws):
        s += w * f(x)
    return s
<br><br>Gauss–Hermite quadrature is designed for integrals on  with the Gaussian weight:  <br><br>An ‐point rule  <br><br>is exact for all polynomials  of degree up to .  The nodes  are the roots of the th Hermite polynomial , satisfying  <br><br>and the weights are given by  <br><br>These follow from the three‐term recurrence of Hermite polynomials and normalization of their leading coefficients.<br>For  with sufficient decay, one shows  <br><br>for some , leading to factorial convergence rates for analytic .  <br><br>We approximate  <br><br>using Gauss–Hermite quadrature with  and . <br>Exact value.  One shows by the gamma‐function that  <br><br>For , the Hermite polynomial is  <br><br>with roots  <br><br>The weights are  <br><br>Thus  <br><br>and the approximation is  <br><br>with error  <br><br>For ,  <br><br>has roots  <br><br>The weights are  <br><br>At , , so  <br><br>At , , so  <br><br>Then  <br><br>exactly matching the true value.<br>This illustrates that Gauss–Hermite with  (exact for polynomials up to degree 3) fails on , while  (exact through degree 5) integrates  exactly, demonstrating its high algebraic precision.  <br><br><br>Suppose we have a family of quadrature estimates  for  <br><br>computed with step‐size .  If  admits an asymptotic expansion in even powers of , for example  <br><br>then one can eliminate the leading  error term by combining two estimates at  and  via Richardson extrapolation:  <br><br>More generally, if  <br><br>one can recursively define higher‐order extrapolants <br><br>where , , etc., so that  cancels terms through , yielding an  approximation to .<br>Romberg integration applies Richardson extrapolation to the composite trapezoidal rule.  Define the level‐ trapezoidal estimate  <br><br>Then one builds the Romberg tableau  <br><br>so that  is the  extrapolation of  and  attains  convergence.  In practice one increases  until  <br><br><br>Romberg integration begins with the composite trapezoidal approximations on dyadic refinements. For each integer  set  <br><br>and arrange  in the first column of a tableau indexed by  (the refinement level) and  (the extrapolation order). Higher‐order entries are formed by the Richardson recursion  <br><br>yielding a triangular array  <br><br>If  then each extrapolated value  approximates the integral with error  <br><br>In particular, the diagonal entries  achieve order , so that the bottom‐right of an  Romberg table is the most accurate. <br>def romberg(f, a, b, m):
    R = [[0]*(m+1) for _ in range(m+1)]
    for i in range(m+1):
        n = 2**i
        h = (b - a)/n
        s = 0.5*(f(a) + f(b))
        for k in range(1, n):
            s += f(a + k*h)
        R[i][0] = h*s
        for j in range(1, i+1):
            R[i][j] = (4**j*R[i][j-1] - R[i-1][j-1])/(4**j - 1)
    return R
<br><br>We approximate<br>
by Romberg integration.  The exact value is<br>
<br>First compute composite trapezoidal estimates  at levels  with :<br>
<br>
, :  


<br>
, :  


<br>
, :<br>
evaluating , , , one finds  


<br>Next form the Romberg tableau by Richardson extrapolation:<br><br>
<br>
For :  


<br>
For :  



<br>The entry  cancels  and  errors, achieving  accuracy.  We find  <br>in agreement with  to within .<br><br><br>Suppose we wish to approximate  <br><br>where  is a possibly non‐rectangular region.  If we can sample uniformly from , then letting  we have the unbiased estimator  <br><br><img alt="Pasted image 20250617093857.png" src="assets/pasted-image-20250617093857.png"><br>Here, <br>
<br>We draw  points uniformly in the square .
<br>We keep only those points satisfying , plot them, and overlay the true circle boundary.
<br>The title shows the running Monte Carlo estimate , which converges toward .
<br>since .  Thus one must know (or estimate) , the ‐dimensional Lebesgue measure of .  When  is given implicitly (e.g.\ by inequalities ), one often resorts to rejection sampling from a simple superset  with known volume.  Drawing  and accepting those with  yields uniform draws on  at cost  in expectation.<br><img alt="Pasted image 20250617094249.png" src="assets/pasted-image-20250617094249.png"><br>Transformations can also regularize complex : if there is a bijection  where  is a hypercube, then  <br><br>and one applies standard Monte Carlo on , using weights  to account for local stretching.  In all cases the variance remains  <br><br>so reducing variance via control variates or importance sampling in  proceeds as in the rectangular case.<br>A complementary approach is to embed  in a simple domain  and write  <br><br>where  is the indicator of .  Drawing , one forms  <br><br>This “hit‐or‐miss” estimator is unbiased and has variance  <br><br>which can be large if  is sparse in  or  varies wildly.  A special case is pure volume estimation (), where  <br><br>with  for .  The Central Limit Theorem again guarantees  convergence, and one can embed variance‐reduction strategies—stratification of , control variates using simpler shapes, or importance sampling that concentrates draws near —to tame the indicator‐driven variance explosion.  <br><br>Suppose we wish to compute the expectation  <br><br>but direct sampling from  is difficult or inefficient.  Instead, we draw samples  from an alternative proposal density  whose support covers that of .  Writing  <br><br>we obtain the unbiased importance sampling estimator  <br><br>Its unbiasedness follows immediately:  <br><br>When  is known only up to a normalizing constant, one uses the self‐normalized estimator  <br><br>which remains consistent but introduces a small bias of order .<br>The variance of the basic estimator is  <br><br>Minimizing this variance with respect to  (subject to normalization) leads to the optimal proposal  <br><br>which makes  constant in magnitude and drives the variance to zero.  In practice one chooses  to approximate  while remaining able to sample efficiently.<br>A practical measure of sampling quality is the effective sample size  <br><br>which lies between 1 and  and estimates the number of independent draws from  that the weighted sample is worth.  A low ESS signals a poor proposal choice with high weight variance, suggesting one should adapt  or employ stratification or multiple importance sampling to stabilize the weights.<br><br>Monte Carlo estimators often suffer from high variance, which limits their accuracy for a given sample size .  Variance reduction techniques seek to construct alternative unbiased estimators whose variance is strictly lower than the crude  rate’s constant, thereby improving precision without increasing computational cost.<br>Control variates exploit the known expectation of an auxiliary random variable  that is correlated with the integrand .  If  is known, one considers the adjusted estimator  <br><br>where  is chosen to minimize variance.  Since  <br><br>the optimal coefficient is  <br><br>reducing variance to  <br><br>When  is close to 1, this yields dramatic variance reduction.  <br>Antithetic sampling exploits negative correlation by pairing samples.  For a one‐dimensional , define its antithetic pair .  The antithetic estimator  <br><br>remains unbiased, and  <br><br>so if  is monotonic,  and variance is reduced.<br>Stratified sampling partitions the domain  into  disjoint strata  of probability , and draws  samples from each stratum with .  The stratified estimator  <br><br>is unbiased, and its variance  <br><br>is minimized (for fixed ) by allocating samples proportionally to , i.e.\  <br><br>This ensures that strata with larger variability receive more samples.<br>Conditional Monte Carlo replaces  by its conditional expectation given a coarser random variable , defining  <br><br>where  are sampled from the marginal of .  Since  <br><br>replacing  by  eliminates the second term, yielding strictly lower variance.  Practical implementations rely on analytic or fast numerical evaluation of the conditional expectation.<br><br>We start by estimating the area of the unit disk  <br>via rejection sampling. Draw  points uniformly in the square , keep those with , and form  <br><br>Suppose our samples are  <br><br>Of these,  lie inside, so  <br><br>close to the true .<br>Next, approximate  <br><br>by importance sampling. A crude estimator draws  and uses  <br><br>but variance is large near . Instead choose the Beta proposal  <br><br>so that  <br><br>with weight  <br><br>Then  <br><br>exactly for any , eliminating variance.<br>Finally, consider control variates when estimating  <br><br>by Monte Carlo with  and . Use  with known . For  samples  <br><br>compute  <br><br><br>so the optimal coefficient is  <br><br>The control‐variate estimator  <br><br>remains unbiased, and its variance is reduced by the factor  <br><br>In each case—rejection sampling on , importance sampling, and control variates—we see how unbiased Monte Carlo estimators are constructed and how variance reduction techniques can dramatically improve accuracy without increasing .  <br>import random

def mc_uniform_domain(f, sampler_D, vol_D, N):
    s = 0.0
    for _ in range(N):
        x = sampler_D()
        s += f(x)
    return vol_D * s / N

def mc_hit_or_miss(f, sampler_B, vol_B, indicator_D, N):
    s = 0.0
    for _ in range(N):
        y = sampler_B()
        s += f(y) * (1.0 if indicator_D(y) else 0.0)
    return vol_B * s / N

def importance_sampling(f, sampler_q, p_density, q_density, N):
    s = 0.0
    for _ in range(N):
        x = sampler_q()
        w = p_density(x) / q_density(x)
        s += f(x) * w
    return s / N

def self_normalized_is(f, sampler_q, p_density, q_density, N):
    num = 0.0
    den = 0.0
    for _ in range(N):
        x = sampler_q()
        w = p_density(x) / q_density(x)
        num += f(x) * w
        den += w
    return num / den

def control_variate(f, sampler, Y, mu_Y, beta, N):
    s = 0.0
    for _ in range(N):
        x = sampler()
        s += f(x) - beta * (Y(x) - mu_Y)
    return s / N

def antithetic(f, sampler_u, N):
    s = 0.0
    for _ in range(N):
        u = sampler_u()
        s += 0.5 * (f(u) + f(1 - u))
    return s / N

def stratified(f, strata_samplers, p_k, n_k):
    total = 0.0
    for sampler, p, n in zip(strata_samplers, p_k, n_k):
        s = 0.0
        for _ in range(n):
            s += f(sampler())
        total += p * (s / n)
    return total
<br><br>Monte Carlo methods shine when approximating high‐dimensional integrals  <br><br>where  makes grid‐based or tensor‐product quadrature infeasible.  By drawing independent samples , one forms the estimator  <br><br>which remains unbiased, , and by the multivariate Central Limit Theorem  <br><br>the root‐mean‐square error decays like  regardless of the dimension .  This dimension‐independent rate contrasts sharply with deterministic schemes whose cost typically scales as  for  points per axis.<br>The key to Monte Carlo’s robustness is that the variance  <br><br>does not depend explicitly on .  In practice  may grow with , but the asymptotic  rate holds even in thousands of dimensions.  By contrast, a simple ‐dimensional trapezoidal rule with  points per axis requires  function evaluations to achieve any fixed accuracy, making Monte Carlo the method of choice for integrals in .<br>Although the convergence rate is dimension‐free, the constant  often increases with  due to concentration of measure: typical random points lie near the “corners” of , and if  varies significantly in those regions, variance balloons.  Importance sampling and control variates remain essential: one introduces a proposal density  on  to form  <br><br>so that choosing —the optimal but usually infeasible density—minimizes variance.  In very high dimensions one also leverages dimension‐reduction techniques (e.g.\ principal component analysis on the integrand’s dominant directions) or replaces pure sampling with low‐discrepancy sequences (quasi‐Monte Carlo), which can achieve rates approaching  for smooth integrands.  <br>We can illustrate Monte Carlo on the 3‐dimensional integral  <br><br>Draw  independent samples  and form  <br><br>In a typical run one finds, for example,  <br><br>To assess accuracy, note  <br><br>so the standard error is  <br><br>By the Central Limit Theorem  <br><br>so an approximate 95% confidence interval is  <br><br>which indeed contains the true value .<br>Thus with only  samples in dimension  we achieve an accuracy of order , and the error decays like  independent of .  In higher dimensions (), the same procedure carries over, with variance  potentially larger but the  rate preserved.<br>import random, math

def mc_nd(f, d, N):
    s = 0.0
    s2 = 0.0
    for _ in range(N):
        x = [random.random() for _ in range(d)]
        fx = f(x)
        s += fx
        s2 += fx*fx
    mean = s/N
    var = s2/N - mean*mean
    se = math.sqrt(var/N)
    return mean, se

def f3(x):
    return math.exp(-(x[0]+x[1]+x[2]))
<br><br>When the integration domain is unbounded—e.g.\  <br><br>naïve uniform sampling is impossible.  Monte Carlo methods cope by drawing from a probability density on the infinite domain and reweighting, or by transforming to a finite interval.  Below we outline two principal strategies.<br>Suppose we choose a proposal density  on  that is easy to sample—common choices are multivariate normals for Gaussian‐like tails or exponential families for one‐dimensional integrals.  Writing  <br><br>we form the unbiased estimator  <br><br>To control variance one must ensure  decays sufficiently fast as .  If  itself decays like , one often uses a heavy‐tailed  with  so that  <br><br>A classic example is estimating a tail probability  <br><br>by sampling from the exponential tilt  <br><br>which moves mass into the rare‐event region and yields much lower variance than rejection or direct sampling.<br>Alternatively, one can map an infinite interval to a finite one.  For  the change  <br><br>transforms  <br><br>One then draws  and estimates  <br><br>The Jacobian factor  must be included in the weight; if  decays slowly, this weight can blow up near , so one often combines this with importance sampling on —e.g.\ Beta proposals that concentrate near —to tame the variance.  <br>import random

def mc_importance_infinite(f, sampler_q, q_pdf, N):
    s = 0.0
    for _ in range(N):
        x = sampler_q()
        s += f(x) / q_pdf(x)
    return s / N

def mc_transform_infinite(g, N):
    s = 0.0
    for _ in range(N):
        u = random.random()
        t = u / (1 - u)
        s += g(t) / (1 - u)**2
    return s / N
<br><br>We illustrate Monte Carlo on the unbounded integral  <br><br>1. Naïve exponential sampling ().<br>
We draw  samples  and form the estimator  <br><br>since  and .  Suppose our draws are  <br><br>so  <br><br>which sum to  and give  <br><br>The sample variance is  <br><br>so  <br><br>A 95% confidence interval is  <br><br>which contains the true .  <br>2. Exponential tilt ().<br>
Here  with , so  <br><br>and the estimator is  <br><br>Using the same  gives  <br><br>summing to  and thus  <br><br>Compute variance:  <br><br>so  <br><br>yielding 95% CI  <br><br>again covering  but with lower SE than the naïve method.<br>The effective sample size is  <br><br>indicating mild weight degeneracy.<br>3. Optimal Gamma proposal ().<br>
Take the Gamma density  <br><br>so  is constant.  Every draw yields the exact value  <br><br>with zero variance.<br>In all cases the estimator  <br><br>is unbiased, , and by the CLT  <br><br>so .  However, choosing a proposal  that matches the integrand’s decay (here Gamma) can reduce variance dramatically—even to zero in this ideal case—while tilted exponentials offer intermediate improvements.<br><br><a class="internal-link" data-href="Appendix-VI##Error-Measurement" href="appendix-vi.html#" target="_self" rel="noopener nofollow">Error Analysis Reference</a>]]></description><link>ch09-numerical-integration.html</link><guid isPermaLink="false">CH09-Numerical-Integration.md</guid><pubDate>Thu, 17 Jul 2025 19:32:31 GMT</pubDate><enclosure url="assets/pasted-image-20250617093857.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;assets/pasted-image-20250617093857.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[CH10-Numerical-ODEs]]></title><description><![CDATA[ 
 <br><a class="internal-link" data-href="Appendix-VI##Error-Measurement" href="appendix-vi.html#" target="_self" rel="noopener nofollow">Error Analysis Reference</a><br><br>An ordinary differential equation (ODE) of order  is an equation of the form  <br><br>where  and .  If  is linear in , we call it a linear ODE; otherwise it is nonlinear.  A linear th‐order ODE can be written  <br><br>where the coefficients  and forcing  are given.  Nonlinear examples include the logistic equation  or the van der Pol oscillator .  An ODE is called stiff when it exhibits both slow and fast dynamics, typically requiring specialized implicit solvers to maintain stability for reasonable step‐sizes.<br><br>In an initial value problem (IVP) one prescribes  conditions at a single point ,  <br><br>and seeks  for  (or on some interval around ).  In contrast, a boundary value problem (BVP) imposes conditions at two or more points, for instance  <br><br>for a second‐order ODE.  Unlike IVPs, BVPs may admit multiple solutions or none at all, and typically require shooting or collocation methods for numerical solution.<br><img alt="Pasted image 20250617114327.png" src="assets/pasted-image-20250617114327.png"><br><img alt="Pasted image 20250617114342.png" src="assets/pasted-image-20250617114342.png"><br><br>Theorem (Picard–Lindelöf).<br>
Let  be continuous in  and Lipschitz continuous in  with constant . Then for any  there exists  such that the initial value problem<br><br>has a unique solution on .<br>Proof.<br>
Fix  so large that  whenever  and , for some . Choose  satisfying<br><br>Define the complete metric space<br><br>with the norm .  For  set<br><br>Then  since for  one has<br><br>Moreover, if  then<br><br>whence<br><br>Thus  is a contraction on the complete metric space . By the Banach Fixed Point Theorem there exists a unique  such that .  Differentiating under the integral sign shows that  is continuously differentiable and satisfies<br><br>so  is a solution of , , on . Uniqueness follows from the contraction estimate: if  is any other solution in  then<br><br>implies . <br><br><br>Consider the IVP  <br><br>where  is continuous and Lipschitz in .  Euler’s method approximates the solution on a grid  by the explicit recurrence  <br><br>Starting from the integral form  <br><br>one replaces the integrand by its left‐endpoint value , yielding the one‐step update above.  The local truncation error —the error made in a single step assuming the exact —satisfies  <br><br>for some , since  is continuous.<br>Under a Lipschitz bound , the global error  obeys  <br><br>so that  <br><br>A discrete Grönwall argument then gives  <br><br>showing first‐order convergence: halving  halves the global error.  However, Euler’s method is only conditionally stable: for the linear test equation  with , the iteration reads  and is stable only if  <br><br>so  must lie inside the corresponding stability region in the complex plane.  This restriction motivates higher‐order or implicit methods for stiff problems.<br>def euler(f, t0, y0, h, n):
    ts = [t0]
    ys = [y0]
    t = t0
    y = y0
    for _ in range(n):
        y = y + h * f(t, y)
        t = t + h
        ts.append(t)
        ys.append(y)
    return ts, ys
<br><br>Starting with the IVP <br><br>and step size , we set . At the initial point,  and . We compute the slope at the left endpoint:  <br><br>The first Euler update gives  <br><br>This yields the approximation at , . Next we evaluate the slope <br><br>and substitute into the recurrence:  <br><br>so at , . We then find  <br><br>and compute  <br><br>giving , . Each successive step follows the same pattern: evaluate , multiply by , and add to  to obtain .<br><br>Heun’s method, also known as the improved Euler or explicit trapezoidal rule, is a two-stage Runge–Kutta scheme of order two for the IVP  <br><br>On a uniform grid , one first computes the predictor  <br><br>and then averages the slopes to obtain the corrector  <br><br>Equivalently, it applies the trapezoidal rule to  <br><br>by approximating  at the endpoints with  and .  A local truncation error analysis shows  <br><br>so that the method achieves global accuracy  under standard smoothness and Lipschitz assumptions on .<br>Assuming a Lipschitz bound , a discrete Grönwall argument yields  <br><br>confirming second-order convergence.  For the linear test equation , Heun’s update becomes  <br><br>so stability requires .  Its stability region is larger than that of Euler’s method but still bounded, making Heun’s method conditionally stable. <br>def heun(f, t0, y0, h, n):
    ts = [t0]
    ys = [y0]
    t = t0
    y = y0
    for _ in range(n):
        k1 = f(t, y)
        y_pred = y + h * k1
        t_next = t + h
        k2 = f(t_next, y_pred)
        y = y + (h/2) * (k1 + k2)
        t = t_next
        ts.append(t)
        ys.append(y)
    return ts, ys
<br><br>Starting with the IVP <br><br>and step size , we set .  <br>At ,  <br><br>so the predictor is  <br><br>We then evaluate  <br><br>and apply the corrector:  <br><br>Thus at , we have .  <br>Next, at ,  <br><br>so  <br><br>Then  <br><br>and  <br><br>At , . Each further step repeats: compute , form the predictor , evaluate , then average slopes to get .  <br><br><br>Runge–Kutta (RK) methods form a broad class of one‐step integrators for the IVP  <br><br>characterized by an -stage update of the form  <br><br>followed by  <br><br>The coefficients ,  and  are typically arranged in a Butcher tableau:  <br><br>Consistency requires  and , which ensures the method reproduces constant and linear solutions exactly.<br>The order  of an RK method is determined by a hierarchy of algebraic constraints—often expressed via rooted‐tree (Butcher) theory—on the sums  <br><br>that must match the Taylor expansion of the exact flow up to .  For example, order 2 demands  <br><br>while order 4 involves additional trees of order 3 and 4.  The number of independent conditions grows rapidly, so practical RK methods balance stage count  against attainable .<br>Stability for a linear test equation  is encoded in the stability function  <br><br>where  and .  The region  determines allowable step‐sizes for stable propagation of decaying modes.  <br>def runge_kutta(f, t0, y0, h, n, A, b, c):
    ts = [t0]
    ys = [y0]
    t = t0
    y = y0
    s = len(b)
    for _ in range(n):
        ks = [0]*s
        for i in range(s):
            ti = t + c[i]*h
            yi = y + h*sum(A[i][j]*ks[j] for j in range(s))
            ks[i] = f(ti, yi)
        y = y + h*sum(b[i]*ks[i] for i in range(s))
        t = t + h
        ts.append(t)
        ys.append(y)
    return ts, ys
<br><br>Consider the IVP  <br><br>and a uniform step-size .  The classical RK4 method advances from  to  by computing four stage derivatives  <br><br>and sets  <br><br>In Butcher tableau form, the coefficients are  <br><br>which exactly encodes the convex combination of stage slopes.  The method requires four evaluations of  per step and produces a one-step map of the form<br><br>where  is a weighted average that matches the Taylor expansion of the exact flow up to terms .<br>RK4 satisfies the elementary order conditions for all rooted trees of order , ensuring its local truncation error is  <br><br>and hence its global error is .  The constant  depends on fifth derivatives of  through combinations of , , and higher Lie brackets of the vector field.  <br>Applying RK4 to the linear test equation  yields the amplification factor  <br><br>so the method is stable for those  satisfying .  The stability region is a large region in the left half of the complex plane, bounded by the roots of ; it contains the real interval roughly .  Consequently, RK4 is conditionally stable, with a much larger allowable  for non-stiff problems than Euler or Heun, but still requiring implicit methods when  with large stiffness.  <br>def rk4(f, t0, y0, h, n):
    ts = [t0]
    ys = [y0]
    t = t0
    y = y0
    for _ in range(n):
        k1 = f(t, y)
        k2 = f(t + h/2, y + h/2 * k1)
        k3 = f(t + h/2, y + h/2 * k2)
        k4 = f(t + h, y + h * k3)
        y = y + h/6 * (k1 + 2*k2 + 2*k3 + k4)
        t = t + h
        ts.append(t)
        ys.append(y)
    return ts, ys
<br><br><br>Adams–Bashforth methods are a family of explicit linear multistep integrators for the IVP  <br><br>that advance the solution using a weighted combination of past slope evaluations.  By interpolating  on previous nodes and integrating the interpolant exactly over one step, these methods achieve high order without additional function calls per step beyond storing past values.<br>An -step Adams–Bashforth formula has the form  <br><br>where the coefficients  are chosen so that the method is exact for polynomials of degree .  Equivalently, one constructs the degree- Lagrange interpolant  through the points  for , and sets  <br><br>For example, the two-step () Adams–Bashforth method has  <br><br>giving  <br><br>which is second‐order accurate.  In general, a ‐step Adams–Bashforth method attains order , with local truncation error  <br><br>To start the multistep procedure one typically uses a one‐step method (e.g.\ RK4) for the first  values.<br>As explicit methods, Adams–Bashforth schemes are conditionally stable: when applied to the test equation , the amplification factor  satisfies  <br><br>with  <br><br>The region of absolute stability is the set of  for which .  For higher  this region becomes a bounded region enclosing part of the left half‐plane; beyond  the interval on the negative real axis shrinks, reflecting the Dahlquist barrier for explicit multistep methods.  Consequently, in stiff problems one must choose  small enough to lie within the stability region or switch to implicit schemes (e.g.\ Adams–Moulton or backward differentiation formulas).<br>def adams_bashforth(f, t0, y0, h, n, k):
    coeffs = {
        1: [1],
        2: [3/2, -1/2],
        3: [23/12, -16/12, 5/12],
        4: [55/24, -59/24, 37/24, -9/24]
    }
    ts = [t0]
    ys = [y0]
    t = t0
    y = y0
    def rk4_step(t, y):
        k1 = f(t, y)
        k2 = f(t + h/2, y + h/2*k1)
        k3 = f(t + h/2, y + h/2*k2)
        k4 = f(t + h, y + h*k3)
        return y + h/6*(k1 + 2*k2 + 2*k3 + k4)
    for i in range(1, k):
        y = rk4_step(t, y)
        t += h
        ts.append(t)
        ys.append(y)
    fs = [f(ts[i], ys[i]) for i in range(len(ys))]
    for _ in range(k, n+1):
        t += h
        s = sum(coeffs[k][j] * fs[-1-j] for j in range(k))
        y = y + h * s
        ts.append(t)
        ys.append(y)
        fs.append(f(t, y))
    return ts, ys
<br><br>Starting with the IVP  <br><br>and step size , we assume we have initial values  <br><br>computed previously (e.g.\ via RK4 and Heun’s method).  We set  so that , , .  <br>First compute the slopes at the last three points:  <br><br>For the three‐step Adams–Bashforth method () the update is  <br><br>At  this gives  at :  <br>
<br>Compute weighted slopes:  




<br>Sum the combination:  


<br>Multiply by  and add to :  


<br>Next we need  at :  <br><br>Now to advance to  at , reuse  in the same formula:  <br>
<br>Weighted slopes:  




<br>Sum inside the parentheses:  


<br>Multiply by  and add to :  

Hence by the three‐step Adams–Bashforth method we obtain  
<br><br><br>A -step Adams–Moulton method approximates the IVP <br><br>by fitting the degree- interpolant of  through the points  for  and integrating exactly over .  The resulting implicit update is  <br><br>where  and the weights  satisfy  <br><br>ensuring exactness for all polynomials of degree .  One finds that the -step Adams–Moulton method has order , with local truncation error  <br><br>The simplest case () is the trapezoidal rule  <br><br>which is second‐order and A‐stable.<br>Because  appears implicitly, one must solve  <br><br>(e.g.\ by fixed‐point or Newton iteration).  The linear stability function for the test equation  is  <br><br>and the method’s region  lies substantially larger in the left half‐plane than that of the corresponding explicit Adams–Bashforth.  However, by the Dahlquist barrier no multistep scheme of order greater than two can be A-stable, so only the trapezoidal rule () in this family is A-stable; higher-order Adams–Moulton methods are only conditionally stable.  <br>def adams_moulton(f, t0, y0, h, n, k):
    am_coeffs = {
        1: [0.5, 0.5],
        2: [5/12, 2/3, -1/12],
        3: [3/8, 19/24, -5/24, 1/24],
        4: [251/720, 646/720, -264/720, 106/720, -19/720]
    }
    ab_coeffs = {
        1: [1],
        2: [3/2, -1/2],
        3: [23/12, -16/12, 5/12],
        4: [55/24, -59/24, 37/24, -9/24]
    }
    ts = [t0]
    ys = [y0]
    t = t0
    y = y0
    def rk4_step(t, y):
        k1 = f(t, y)
        k2 = f(t + h/2, y + h/2*k1)
        k3 = f(t + h/2, y + h/2*k2)
        k4 = f(t + h, y + h*k3)
        return y + h/6*(k1 + 2*k2 + 2*k3 + k4)
    for _ in range(1, k):
        y = rk4_step(t, y)
        t += h
        ts.append(t); ys.append(y)
    fs = [f(ts[i], ys[i]) for i in range(len(ys))]
    for _ in range(k, n+1):
        s_ab = sum(ab_coeffs[k][j]*fs[-1-j] for j in range(k))
        y_pred = y + h*s_ab
        t_next = t + h
        f_pred = f(t_next, y_pred)
        s_am = am_coeffs[k][0]*f_pred + sum(am_coeffs[k][j]*fs[-j] for j in range(1, k+1))
        y = y + h*s_am
        t = t_next
        ts.append(t); ys.append(y)
        fs.append(f(t, y))
    return ts, ys
<br><br>Starting with the IVP  <br><br>and step size , assume initial approximations  <br><br>with slopes  <br><br>The two-step Adams–Moulton formula () is  <br><br>which is implicit because .  For , , set  <br><br>so the update reads  <br><br>Distribute and collect the  terms:  <br><br><br><br>To advance to , use  similarly:  <br><br><br><br><br>Thus the two-step Adams–Moulton method yields  <br><br><br>Nyström methods are one‐step integrators for second‐order equations of the form  <br><br>that avoid rewriting as a first‐order system.  By directly incorporating the second derivative, they achieve high order with fewer function evaluations than general Runge–Kutta schemes.<br>An ‐stage explicit Nyström method advances  with step‐size  by computing intermediate positions  <br><br>and then updating  <br><br>The coefficients , ,  and nodes  are chosen to exactly integrate polynomials in  of a given degree.  Consistency requires  <br><br>so that constant and linear solutions in  are reproduced.<br>A Nyström method attains order  if its local truncation error in  is  and in  is .  The order conditions derive from matching the Taylor expansion  <br><br>against the method’s update.  For example, the classical 4th‐order Nyström with  stages uses  <br><br>which yields global error  with three evaluations of  per step.  Because Nyström methods exploit the special structure of second‐order equations, they often outperform equivalent‐order Runge–Kutta when  depends only on , as in mechanical systems and orbital dynamics.  <br><br><br>In the context of a one‐step method applied to the IVP  <br><br>the local truncation error (LTE)  measures the error introduced by a single step, assuming the exact solution is available at .  Formally, if  is the one‐step map of the method, then  <br><br>so that  indicates the method’s local order is .  In contrast, the global error (GE) at step  is  <br><br>where  is the numerical approximation.  Under suitable Lipschitz conditions on , one shows that if  uniformly, then  <br><br>so the global error order is one less than the local.  <br>The relationship between LTE and GE arises through error propagation.  Writing the error recurrence  <br><br>and using a Lipschitz bound , a discrete Grönwall argument yields  <br><br>which telescopes to .  Thus, even though each step errs by , the cumulative effect over  steps degrades the convergence to .  Recognizing this distinction is crucial when designing high‐order integrators and assessing their practical accuracy.  <br><br><br>A numerical method for the IVP  <br><br>is said to be consistent of order  if its local truncation error satisfies  <br><br>where  is the one‐step map (or the multistep update).  Equivalently, consistency means that the discrete scheme reproduces the differential equation in the limit of vanishing step‐size.  For a linear multistep method  <br><br>one checks that  <br><br>so that constant and linear functions are integrated exactly; higher‐order consistency conditions involve matching higher Taylor coefficients.  <br><br>A method is zero‐stable (for multistep) or A‐stable (for one‐step) if small perturbations—due to round‐off or data—do not grow uncontrollably under repeated application of the update.  Concretely, a linear multistep method is zero‐stable if the roots of its characteristic polynomial  <br><br>lie in or on the unit circle, with any on‐circle roots simple.  For one‐step Runge–Kutta methods, A‐stability means the stability function  satisfies  for , so that decaying modes remain bounded.<br>The Dahlquist Equivalence Theorem (for linear multistep) states that consistency plus zero‐stability implies convergence: the global error  <br><br>In other words, reproducing the differential equation at each step (consistency) and preventing error amplification (stability) guarantee that the numerical solution approaches the true solution as .  For one‐step methods the analogous result holds: consistency of order  together with a bounded stability region containing the negative real axis ensures  global convergence.  <br>In practice, making sure both properties guides method selection: high‐order but unstable schemes fail, while stable but low‐order schemes converge slowly.  The interplay of consistency, stability, and convergence underlies the design of integrators for non‐stiff and stiff ODEs alike.  <br>Theorem (Lax Equivalence).<br>
Let a linear initial-value problem be discretized by a consistent finite-difference scheme. Then stability of the scheme is necessary and sufficient for convergence: a consistent linear scheme converges if and only if it is stable.<br>Proof.<br>
Let the continuous problem be  with initial data , and let the difference scheme be<br><br>where  is the amplification operator and  projects the exact initial data into the grid. Consistency means that for the exact solution sampled on the grid, , the local truncation error<br><br>satisfies  as . Stability means there exists  independent of  such that<br><br>(Necessity.) Assume the scheme converges:  uniformly for . Write the error . Then<br><br>Unrolling gives<br><br>Since  and  while , uniform boundedness of  follows by a discrete Grönwall–type argument: if  were unbounded for some , the error could not remain small. Hence the scheme is stable.<br>(Sufficiency.) Assume consistency and stability. Define the global error  as above; then<br><br>Taking norms and using stability,<br><br>Since the scheme is consistent, for each fixed  the sum  tends to zero as . Therefore  uniformly for , proving convergence. <br><br>Absolute stability concerns the behavior of a numerical method when applied to the linear test equation  <br><br>and measures whether the discrete solution decays in time for any step‐size .  If the one‐step update can be written  <br><br>then the method is absolutely stable for a given  exactly when  <br><br>The region of absolute stability is the set  <br><br>and it plays a central role in step‐size selection and stiffness handling.<br>By design, an explicit Euler method has  <br><br>so its stability region is the disk , i.e.\  <br><br>which excludes much of the left half‐plane.  Higher‐order explicit Runge–Kutta methods likewise yield polynomials in  for  whose level contours  define bounded lobes in .  Implicit methods, such as the trapezoidal rule with  <br><br>produce  <br><br>and in fact satisfy  for all , making them A‐stable.<br>A method is A‐stable if its stability region contains the entire left half‐plane:  <br><br>No explicit linear multistep or explicit Runge–Kutta method can be A‐stable beyond first order, and no implicit linear multistep method can be A‐stable beyond second order (Dahlquist barriers).  L‐stability strengthens A‐stability by requiring  <br><br>so that very stiff modes are strongly damped rather than merely bounded.  In practice, one chooses an A‐stable or L‐stable integrator when  for the stiffest components, ensuring stability for arbitrarily large step‐sizes without spurious growth.  <br><br><br>
<br>Stability function  


<br>Region<br>
The disk , i.e.\ a unit circle centered at .
<br>Implications<br>
For real , stability requires  

so you must choose .  Outside this disk the numerical solution grows spuriously, so Euler is conditionally stable.
<br><img alt="Pasted image 20250617215841.png" src="assets/pasted-image-20250617215841.png"><br><br>
<br>Stability function  


<br>Region<br>
A bounded “four-lobed” area extending roughly to  on the real axis.
<br>Implications<br>
RK4 remains stable for much larger step-sizes than Euler, but is still conditionally stable—very stiff modes (large ) force  small enough that  stays inside those lobes.
<br><img alt="Pasted image 20250617215927.png" src="assets/pasted-image-20250617215927.png"><br><br>
<br>Stability function  


<br>Region<br>
The entire left half-plane .
<br>Implications<br>
This method is A-stable: any decaying mode () remains decaying for any .  Moreover,  

so it is also L-stable, strongly damping very stiff modes.
<br><img alt="Pasted image 20250617215948.png" src="assets/pasted-image-20250617215948.png"><br>
<br>For non-stiff problems, explicit methods like Euler or RK4 suffice if you pick  so that all  lie inside the shaded region.  
<br>For stiff problems—when some —only A-stable (and ideally L-stable) methods (e.g.\ implicit trapezoidal) let you take moderate or large  without blow-up.
<br><br><br>An ODE (or system)  <br><br>is called stiff if it exhibits widely separated time scales, so that certain components decay (or evolve) much faster than others.  A quantitative measure for a linear constant‐coefficient system <br><br>is the stiffness ratio  <br><br>where  are the eigenvalues of  with nonzero real parts.  When , explicit methods require prohibitively small step‐sizes to resolve the fastest mode, even if one is only interested in the slow dynamics.  Equivalently, for the Dahlquist test equation  <br><br>stiffness manifests as the necessity to choose  so small that , despite the solution decaying rapidly to zero.<br><br>
<br>Dahlquist Test.  For  with , the exact solution decays on the scale , but one might wish to integrate up to .  An explicit Euler step must satisfy , forcing , whereas an A‐stable implicit method can take  without instability.  
<br>Van der Pol Oscillator.  In the form  

large  creates a fast “relaxation” phase where trajectories rapidly jump between slow manifolds, giving  and rendering explicit schemes inefficient.  
<br>Chemical Kinetics (Robertson Problem).  A three‐species reaction network  

with rate constants differing by orders of magnitude (), leads to eigenvalues spanning many scales and thus a large stiffness ratio.  
<br>Semi‐discretized Parabolic PDEs.  Discretizing the heat equation  

on a spatial grid of spacing  yields  with .  As , , and explicit time stepping becomes impractical without severe step‐size restrictions.
<br>In all these cases stiffness compels the use of implicit or specially tailored integrators—A‐stable, L‐stable, or diagonally implicit Runge–Kutta methods—to efficiently traverse the slow manifold without being hampered by the fast transient modes.  <br><br>Backward Differentiation Formulas (BDF), often called Gear’s methods, are implicit linear multistep integrators especially well suited for stiff IVPs  <br><br>A -step BDF approximates the derivative by a backward finite difference of order  and enforces the ODE at the new time:<br>On a uniform grid , the -step BDF is  <br><br>where the coefficients  satisfy the backward‐difference identity  <br><br>and .  Equivalently, one writes the st-degree interpolant through  in backward time and differentiates at .  For example:  <br>
<br>BDF1 (): the implicit Euler method  

order 1.  
<br>BDF2 ():  

  order 2.<br>
In general, the -step BDF has order  with local truncation error .
<br>BDF methods are A-stable up to ; for  they remain zero‐stable but lose full A-stability, though they retain large stability regions covering much of the left half‐plane.  Their stability polynomials satisfy  <br><br>with  for  over a wide region.  Crucially, BDFs are L-stable for , and for  exhibit strong damping of highly stiff modes.  This makes Gear’s methods a workhorse for stiff systems—chemical kinetics, reactor dynamics, and semi‐discretized parabolic PDEs—where one can take large step‐sizes without sacrificing stability.  <br>import math

def gear_bdf(f, t0, y0, h, n, k, tol=1e-8, maxiter=10):
    alphas = {
        1: [1.0, -1.0],
        2: [1.5, -2.0, 0.5],
        3: [11/6, -3.0, 1.5, -1/3],
        4: [25/12, -4.0, 3.0, -4/3, 0.25]
    }
    alpha = alphas[k]
    beta = alpha[0]
    ts = [t0]
    ys = [y0]
    for step in range(n):
        t_next = ts[-1] + h
        # initial guess: last value
        y = ys[-1]
        # Newton iteration
        for _ in range(maxiter):
            # compute F(y)
            F = alpha[0]*y
            for j in range(1, k+1):
                y_prev = ys[-j]
                F += alpha[j] * y_prev
            F -= h*beta*f(t_next, y)
            # approximate derivative dF/dy
            eps = math.sqrt(tol) * (1 + abs(y))
            f1 = f(t_next, y + eps)
            f0 = f(t_next, y - eps)
            dfdy = (f1 - f0) / (2*eps)
            dFdy = alpha[0] - h*beta*dfdy
            # Newton update
            y_new = y - F/dFdy
            if abs(y_new - y) &lt; tol:
                y = y_new
                break
            y = y_new
        ys.append(y)
        ts.append(t_next)
    return ts, ys
<br><br>Starting with the IVP <br><br>and step size , we assume previous approximations <br><br>and compute the corresponding slopes  <br><br>The two‐step BDF (BDF2) formula is  <br><br>which for  (to find  at ) becomes  <br><br>Substituting  and  gives  <br><br>so that  <br><br><br>Thus <br>To advance to  at , we apply the same formula with :  <br><br>Substituting  and  yields  <br><br><br><br>Hence by BDF2 we obtain  <br><br><br><br>When faced with  coupled first‐order ODEs  <br><br>it is advantageous to bundle them into the single vector equation  <br><br>where  <br><br>This vector form offers several benefits:<br>
<br>
Unified existence/uniqueness.  If  is Lipschitz in  on a region, then the IVP  

has a unique local solution by Picard–Lindelöf.

<br>
Reduction of higher‐order ODEs.  An th‐order scalar ODE  

is converted to a first‐order system of size  by defining  

and setting  


<br>Example vectorization: <br>def rk4_vector(f, t0, y0, h, n):
    ts = [t0]
    ys = [y0[:]]
    t = t0
    y = y0[:]
    for _ in range(n):
        k1 = f(t, y)
        y_temp = [yi + h/2 * k1i for yi, k1i in zip(y, k1)]
        k2 = f(t + h/2, y_temp)
        y_temp = [yi + h/2 * k2i for yi, k2i in zip(y, k2)]
        k3 = f(t + h/2, y_temp)
        y_temp = [yi + h * k3i for yi, k3i in zip(y, k3)]
        k4 = f(t + h, y_temp)
        y = [
            yi + h/6 * (k1i + 2*k2i + 2*k3i + k4i)
            for yi, k1i, k2i, k3i, k4i in zip(y, k1, k2, k3, k4)
        ]
        t += h
        ts.append(t)
        ys.append(y[:])
    return ts, ys
<br><br>In implicit one‐step or multistep schemes—such as backward Euler, implicit Runge–Kutta, or Adams–Moulton—the update at each step requires solving a nonlinear system  <br><br>where  involves  or a combination of stage derivatives.  To apply Newton’s method one linearizes  around the current guess :<br><br>and solves the Jacobian system  <br><br>The key object is the Jacobian matrix of the right‐hand side,<br><br>For backward Euler (), one has  <br><br>In an ‐stage implicit Runge–Kutta with Butcher matrix , the block‐Jacobian is  <br><br>a dense  matrix built from Kronecker products.  In multistep formulas,  combines differences of the identity (from past values) with  (from the new slope).<br><br>Sparse matrices arise when most entries of a large  system matrix  are zero—common in discretized PDEs.  Exploiting sparsity reduces storage from  to  (or ) and accelerates solves from  to near‐linear time, enabling systems with millions of unknowns.<br>A sparse matrix stores only its nonzero entries.  In the Compressed Sparse Row (CSR) format one keeps arrays  of length  for nonzero values,  for column indices, and  of length  giving index ranges:<br><br>The sparsity pattern corresponds to the adjacency graph  with  and an edge  whenever .  Graph algorithms—minimum degree or nested dissection orderings—reorder rows and columns to reduce fill‐in, the extra nonzeros introduced during factorization.<br>Direct methods perform an  or Cholesky factorization<br><br>while controlling fill‐in via chosen pivot order.  On a 2D grid with  nodes, nested dissection yields  storage and  time.  Multifrontal and supernodal algorithms assemble dense frontal matrices corresponding to graph separators to optimize performance.<br>Iterative methods build a sequence  approximating the solution of .  For symmetric positive‐definite , the Conjugate Gradient (CG) method satisfies<br><br>where  is the condition number.  <br>Preconditioning replaces  by  to cluster eigenvalues and reduce .  Common sparse preconditioners include Incomplete LU (ILU) and Algebraic Multigrid (AMG), which approximate  while preserving sparsity, often yielding near-optimal  complexity for elliptic PDEs.<br>Here's an example implementation:<br>class CSRMatrix:
    def __init__(self, n, row_ptr, col_idx, values):
        self.n = n
        self.row_ptr = row_ptr      # length n+1
        self.col_idx = col_idx      # length nnz
        self.values = values        # length nnz

    def matvec(self, x):
        y = [0.0]*self.n
        for i in range(self.n):
            row_start = self.row_ptr[i]
            row_end = self.row_ptr[i+1]
            s = 0.0
            for idx in range(row_start, row_end):
                j = self.col_idx[idx]
                s += self.values[idx] * x[j]
            y[i] = s
        return y

def dot(u, v):
    return sum(ui*vi for ui,vi in zip(u,v))

def axpy(a, x, y):
    return [a*xi + yi for xi, yi in zip(x, y)]

def cg(A: CSRMatrix, b, x0=None, tol=1e-8, maxiter=None):
    n = A.n
    x = x0[:] if x0 is not None else [0.0]*n
    r = [bi - ai for bi, ai in zip(b, A.matvec(x))]
    p = r[:]
    rs_old = dot(r, r)
    maxiter = maxiter or n
    for _ in range(maxiter):
        Ap = A.matvec(p)
        alpha = rs_old / dot(p, Ap)
        x = axpy(alpha, p, x)
        r = axpy(-alpha, Ap, r)
        rs_new = dot(r, r)
        if rs_new &lt; tol*tol:
            break
        beta = rs_new / rs_old
        p = [ri + beta*pi for ri, pi in zip(r, p)]
        rs_old = rs_new
    return x
<br><br>Starting with the SPD system  <br><br>we store it in CSR format with  <br><br>We take the initial guess  <br><br>so the residual  and set the search direction .<br>Compute  by looping over rows via CSR:<br>
for row 0 () we get ,<br>
row 1 () gives ,<br>
row 2 () gives ,<br>
row 3 () gives ,<br>
so  <br><br>The step length is  <br><br>We update  <br><br>Next compute  <br><br>so the new search direction is  <br><br>Thus after one CG iteration we have  <br><br><br><br><br><br>The Laplace transform provides a bridge between time-domain differential equations and algebraic equations in the complex frequency variable .  For a causal function  (i.e.\  for ), the transform is defined by  <br><br>for values of  where the integral converges.  Linearity of the integral immediately gives <br><br>and the key property that turns differentiation into multiplication by  is  <br><br>and so on for higher derivatives.<br>To solve a linear constant-coefficient initial-value problem  <br><br>one takes the Laplace transform of both sides.  The left side becomes a polynomial in  times  minus terms involving the initial data .  <br><br>Since  is known, this reduces the ODE to the algebraic equation  <br><br>where  and  is a polynomial built from the .  One then solves for  <br><br>Recovering  requires the inverse Laplace transform, which can be expressed formally by the Bromwich integral  <br><br>or more practically by partial-fraction expansion and known transform pairs.  For example, if  <br><br>one writes  <br><br>and uses  <br><br>An elegant feature of the Laplace approach is the convolution theorem: if  then  <br><br>where  is the impulse response.  Thus the particular solution to an inhomogeneous ODE can be written as a convolution of the forcing  with the Green’s function , unveiling both the causal structure and the integral‐kernel representation of linear systems.<br><br>Starting with the IVP  <br><br>take Laplace transforms.  Let  and .  Using  <br><br>we get  <br><br>Combine terms:  <br><br>so  <br><br>Since ,  <br><br>We seek a partial‐fraction decomposition  <br><br>Multiply through by :  <br><br>Expand and collect like powers:  <br><br>Hence  <br><br>From  and , one finds , , .  Thus  <br><br>Inverting termwise using  <br><br>gives  <br><br><br>Numerical Laplace transforms seek to approximate either the forward transform  <br><br>or its inverse  <br><br>by replacing these integrals with finite sums.  A common trick for the forward transform is to change variables , yielding  <br><br>and then apply Gauss–Laguerre quadrature.  If  are the Laguerre nodes and weights, one obtains  <br><br>This formula is spectrally accurate when  is smooth and decays sufficiently fast, but care is needed if  has singularities or slow decay.<br>Inverting the Laplace transform numerically often relies on rewriting the Bromwich integral as a Fourier‐type integral.  By shifting the contour to  and setting , one has  <br><br>which can be approximated by the trapezoidal rule on a finite interval :  <br><br>Choosing  to the right of all singularities of  ensures convergence, while  and  control the trade‐off between aliasing errors and truncation error.<br>A more sophisticated contour‐deformation approach is the Talbot method, which parametrizes a bent contour  for  so that  decays rapidly.  One writes  <br><br>and applies a simple trapezoidal rule in :  <br><br>With a well‐chosen  (for example ), this method achieves exponential convergence in  for a wide class of problems.<br>An alternative purely real‐axis inversion is the Gaver–Stehfest algorithm, which uses a finite difference representation of the inverse transform:  <br><br>where the  are precomputed weights depending only on .  Although easy to implement, Gaver–Stehfest can suffer from numerical instability if  is too large or if  is evaluated with insufficient precision.<br>In all these approaches, the accuracy depends critically on the analyticity and growth of , the decay properties of , and the careful selection of quadrature parameters (contour shift , truncation limits, number of nodes).  <br>import math
import numpy as np
from numpy.polynomial.laguerre import laggauss

def laplace_forward_gl(f, s, N):
    x, w = laggauss(N)
    return (1.0/s) * sum(w[k] * f(x[k]/s) for k in range(N))

def laplace_inverse_trap(F, t, gamma, Omega, M):
    dw = Omega / M
    summ = 0+0j
    for k in range(-M, M+1):
        w = k * dw
        summ += math.exp((gamma + 1j*w) * t) * F(gamma + 1j*w)
    return math.exp(gamma*t) / (2*math.pi) * summ * dw

def laplace_inverse_talbot(F, t, N, gamma=0.0):
    dt = 2*math.pi / N
    summ = 0+0j
    for k in range(1, N+1):
        theta = -math.pi + k * dt
        s = gamma + (theta/math.tan(theta) + 1j*theta) / t
        ds = (1 - theta/math.sin(theta)**2 + 1j) / t * dt
        summ += math.exp(s*t) * F(s) * ds
    return summ / (2j*math.pi)

def stehfest_weights(N):
    if N % 2 != 0:
        raise ValueError("N must be even")
    V = [0.0] * N
    for k in range(1, N+1):
        s = 0.0
        for j in range(math.ceil(k/2), min(k, N//2)+1):
            num = j**(N//2) * math.factorial(N//2)
            den = math.factorial(j) * math.factorial(N//2 - j) * math.factorial(j-1) * math.factorial(k-j) * math.factorial(2*j-k)
            s += num / den
        V[k-1] = s * (-1)**(N//2 + k)
    return V

def laplace_inverse_stehfest(F, t, N):
    V = stehfest_weights(N)
    ln2 = math.log(2)
    total = 0.0
    for k in range(1, N+1):
        total += V[k-1] * F(k * ln2 / t)
    return ln2 / t * total
<br><br>First, recall that for the forward transform  <br><br>we make the substitution , so  and , giving  <br><br>Using  Gauss–Laguerre quadrature with nodes and weights for :  <br><br>we approximate  <br><br>Since , we have  <br><br>Thus  <br><br>and similarly  <br><br>Adding gives  <br><br>in exact agreement with the analytic result .<br>Next, to invert via the trapezoidal rule on the Bromwich integral, write  <br><br>Choose , truncate to , and take , so .  Then  <br><br>We have  <br><br>and , .  Since  for , actually ; using the earlier , we compute:<br>At :  <br><br>At :  <br><br>Numerically,  and , so  <br><br>Then the sum in the trapezoidal rule is  <br><br>Finally, multiply by the prefactor:<br><br>so<br><br>which is a reasonable approximation to the exact value  given the coarse truncation and small .  ]]></description><link>ch10-numerical-odes.html</link><guid isPermaLink="false">CH10-Numerical-ODEs.md</guid><pubDate>Fri, 20 Jun 2025 08:10:00 GMT</pubDate><enclosure url="assets/pasted-image-20250617114327.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;assets/pasted-image-20250617114327.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[CH11-Linear-Algebra]]></title><description><![CDATA[ 
 <br><br><br>Gaussian elimination is a systematic procedure for transforming a linear system  <br><br>into an equivalent upper‐triangular form.  Here  and , with  a field.  “Equivalent” means that each step applies one of three types of elementary row operations, which preserve the solution set:  <br>
<br>swapping two rows (),  
<br>scaling a row by a nonzero scalar (, ),  
<br>adding a scalar multiple of one row to another ().  
<br>At the th stage one selects a pivot in column  (an entry  for ) and uses it to eliminate all entries below it.  If , one forms multipliers  <br><br>and updates each lower row via  <br><br>After  such rounds the augmented matrix  is in row‐echolon form, with zeros below the main diagonal.<br>The significance of this process is that it exhibits the rank and solvability of the system in a transparent way.  If at some step the pivot  and no row interchange can produce a nonzero entry, then the rank of  is less than , and one detects either infinitely many solutions or inconsistency.  In fact, by continuing the elimination one arrives at a system  <br><br>where  is upper triangular.  Back‐substitution then shows that a unique solution exists precisely when , since  factors as the product of the pivots (up to the sign changes from any row swaps).<br>Viewed algebraically, Gaussian elimination amounts to writing  <br><br>where  is a permutation matrix encoding row swaps,  is unit lower triangular, and  is upper triangular.  The entries of  record the multipliers .  <br>Existence of an  decomposition without pivoting (so ) is equivalent to all leading principal minors of  being nonzero.  This factorization is fundamental: it links elimination to determinant evaluation () and to the structure of linear operators.<br>From a complexity standpoint, Gaussian elimination performs on the order of  <br><br>arithmetic operations.  Thus it is a cubic‐time algorithm in the size of the system.  More refined analyses consider arithmetic over finite fields or exact arithmetic, where coefficient growth can be an issue; one then studies bounds on the size of intermediate numerators and denominators.<br>def gaussian_elimination(A, b):
    n = len(A)
    for k in range(n):
        max_row = max(range(k, n), key=lambda i: abs(A[i][k]))
        A[k], A[max_row] = A[max_row], A[k]
        b[k], b[max_row] = b[max_row], b[k]
        for i in range(k+1, n):
            factor = A[i][k] / A[k][k]
            for j in range(k, n):
                A[i][j] -= factor * A[k][j]
            b[i] -= factor * b[k]
    x = [0] * n
    for i in range(n-1, -1, -1):
        s = b[i] - sum(A[i][j] * x[j] for j in range(i+1, n))
        x[i] = s / A[i][i]
    return x
<br><br>We solve the system  <br><br>Since the pivot , we swap , yielding  <br><br>Now . To eliminate below, compute  <br><br>and update , giving  <br><br><br>The matrix is now  <br><br>Next pivot is . Compute  <br><br>and update :  <br><br><br>Now the upper‐triangular form is  <br><br>Back‐substitution begins with the last equation  <br><br>Then the second row gives  <br><br>Finally the first row yields  <br><br>Thus the solution is  <br><br><br>Following the elimination process, one arrives naturally at the factorization  <br><br>where  is a permutation matrix capturing any row‐swaps performed,  is a unit lower‐triangular matrix (all diagonal entries equal to 1), and  is an upper‐triangular matrix.  Equivalently, when no pivoting is required, one has simply  <br><br>Conceptually,  records the multipliers used during elimination.  If at step  the multiplier  <br><br>was used to eliminate the entry in row , column , then .  All other entries below the diagonal in column  are zero by construction, and the diagonal entries of  are set to 1.  Meanwhile, the entries of  are exactly the pivot rows as they emerge:  <br><br>Existence of an  factorization (without pivoting) hinges on the nonvanishing of each leading principal minor of .  In fact, one can show by induction that<br><br>for each , ensuring that each pivot  is nonzero.  Should a principal minor vanish, one must introduce partial pivoting (the matrix ) to restore nonsingularity in the current pivot position.<br>Two classical algorithms for computing  and  directly are known as Doolittle’s method (which sets  and computes  first) and Crout’s method (which sets  and computes  first).  They both carry out essentially the same operations as Gaussian elimination but interleave the storage of multipliers and pivot‐row entries in a single pass over the matrix entries, achieving in‐place factorization.<br>Once  (or ) is known, many further tasks become trivial.  Solving  reduces to  <br><br>(if pivoting is used), so one first solves  <br><br>by forward substitution—each  depends only on earlier —and then solves  <br><br>by back substitution.  Similarly, the determinant of  follows immediately from  <br><br>and computing  reduces to solving  right‐hand sides via the same two‐step substitution process.<br> decomposition emphasizes the algebraic structure of linear operators by expressing  as a product of a simple shear (encoded in ) and a triangular scaling (encoded in ), up to permutation.  <br>Computationally, the cost of computing an  factorization is the same order as Gaussian elimination, namely  <br><br>operations.<br>def lu_decomposition(A):
    n = len(A)
    P = list(range(n))
    L = [[0.0]*n for _ in range(n)]
    U = [[0.0]*n for _ in range(n)]
    for i in range(n):
        pivot = max(range(i, n), key=lambda j: abs(A[j][i]))
        A[i], A[pivot] = A[pivot], A[i]
        P[i], P[pivot] = P[pivot], P[i]
        for j in range(i, n):
            U[i][j] = A[i][j]
        L[i][i] = 1.0
        for j in range(i+1, n):
            L[j][i] = A[j][i] / U[i][i]
            for k in range(i+1, n):
                A[j][k] -= L[j][i] * U[i][k]
    return P, L, U
<br><br>Starting with  <br><br>we form  <br><br>At the first elimination step, the pivot is .  We compute the multipliers  <br><br>Applying  gives the new third row  <br><br>Thus after step 1,  <br><br>At the second elimination step, the pivot is  (from the second row of ).  We compute  <br><br>and update :  <br><br>So  <br><br>Collecting the unit diagonal and multipliers, we obtain  <br><br>By construction,  <br><br>with , confirming nonsingularity.  <br><br>The QR decomposition expresses a full‐rank matrix  <br><br>as the product of an orthonormal (or unitary) factor and an upper‐triangular factor:  <br><br>where  satisfies , and  is upper triangular with positive diagonal entries.  In geometric terms, the columns of  form an orthonormal basis for the column space of , and  contains the coordinates of the original column vectors of  in that basis.<br>A direct algebraic route to  and  is the Gram–Schmidt process.  Given the columns  of , one defines inductively  <br><br>Here  are the orthonormal vectors, and  occupy the entries of .  While conceptually simple, classical Gram–Schmidt can suffer from loss of orthogonality in floating‐point arithmetic; a modified version alleviates this by re‐orthogonalizing at each step.<br>A more robust algorithm uses Householder reflectors.  At stage , one constructs a unit vector  such that the reflection  <br><br>annihilates all entries below the diagonal in column .  One applies  <br><br>so that after  steps  <br><br>and  is orthonormal because each  is unitary.  This approach requires roughly  <br><br>operations and enjoys excellent numerical stability.<br>Givens rotations offer yet another perspective, performing elimination one plane‐rotation at a time.  A rotation  <br><br>acts on rows  and  to zero a chosen subdiagonal entry without disturbing previously created zeros.  Although less efficient for dense matrices than Householder methods, Givens rotations are ideal for sparse or structured problems where one wishes to preserve zeros.<br>From the existence perspective,  exists precisely when its columns are linearly independent.  The diagonal entries of  relate to the volumes of successive parallelepipeds spanned by the first  columns:  <br><br>In least‐squares problems, solving  <br><br>reduces to solving the upper‐triangular system  <br><br>bypassing the conditioning issues of normal equations .<br>import math

def qr_decomposition(A):
    m = len(A)
    n = len(A[0])
    Q = [[0.0]*n for _ in range(m)]
    R = [[0.0]*n for _ in range(n)]
    for j in range(n):
        v = [A[i][j] for i in range(m)]
        for i in range(j):
            R[i][j] = sum(Q[k][i]*A[k][j] for k in range(m))
            for k in range(m):
                v[k] -= R[i][j]*Q[k][i]
        R[j][j] = math.sqrt(sum(vk*vk for vk in v))
        for k in range(m):
            Q[k][j] = v[k]/R[j][j]
    return Q, R
<br><br>Starting with  <br><br>we follow the column‐by‐column procedure:<br>For , set  <br><br>There are no previous ‐columns, so  <br><br>For , set  <br><br>compute the projection onto :  <br><br>subtract off that component:  <br><br>Now  <br><br>For , set  <br><br>project onto :  <br><br>update :  <br><br>project onto :  <br><br>update  again:  <br><br>finally  <br><br>Putting it all together,  <br><br>and one verifies that .  <br><br>The Cholesky decomposition applies to a symmetric positive-definite matrix  <br><br>and factors it uniquely as  <br><br>where  is lower-triangular with strictly positive diagonal entries.  This factorization can be viewed as taking “matrix square-roots” in the sense that  encodes the unique positive-definite square-root of  under the triangular constraint.<br>One computes the entries of  in a nested sequence of operations.  For each , the diagonal entry is  <br><br>and for each , the subdiagonal entries satisfy  <br><br>No row or column pivoting is needed thanks to positive definiteness: each leading principal minor  <br><br>remains strictly positive, ensuring the arguments of the square roots are never zero or negative.<br>From a computational perspective, Cholesky requires roughly  <br><br>arithmetic operations, the same cubic scaling as LU but with about half the work and storage since one exploits symmetry and needs only the lower triangle of .  Numerically, it is more stable than unpivoted LU for symmetric positive-definite problems, and rounding-error analysis shows that the factor  remains close to the ideal exact factor for well-conditioned .<br>Cholesky intertwines with quadratic forms: writing  shows immediately that  induces an inner product on .  It also underlies the solution of  via two triangular solves,  (forward substitution) and  (back substitution), and yields .  <br>In probabilistic modeling,  generates correlated Gaussian samples via  for , and in optimization, it appears in sampling and in preconditioning for conjugate-gradient methods.<br>Generalizations include block-Cholesky for partitioned matrices, writing  <br><br>import math

def cholesky(A):
    n = len(A)
    L = [[0.0]*n for _ in range(n)]
    for i in range(n):
        for j in range(i+1):
            s = sum(L[i][k] * L[j][k] for k in range(j))
            if i == j:
                val = A[i][i] - s
                if val &lt;= 0:
                    raise ValueError("Matrix is not positive definite")
                L[i][i] = math.sqrt(val)
            else:
                L[i][j] = (A[i][j] - s) / L[j][j]
    return L
<br><br>Consider the symmetric positive‐definite matrix  <br><br>and seek a lower‐triangular  with positive diagonal such that .<br>We compute entries of  in row‐column order:<br>First, for :<br><br>For  in column 1:<br><br>Next, for :<br><br>For  in column 2:<br><br>Finally, for  on the diagonal:<br><br>Putting it all together gives  <br><br>and one checks directly that .  <br><br><br>Stationary iterative methods form a framework for solving a linear system  <br><br>by rewriting  as a splitting  <br><br>where  is chosen to be easily invertible.  Rather than eliminating variables or factoring , one views the system as a fixed‐point problem for the mapping  <br><br>Starting from an initial guess , the iteration  <br><br>is applied repeatedly.  Because both  and  remain the same at every step, the associated iteration matrix  <br><br>is constant, hence the term “stationary.”  All the action of the method is captured by this single operator  and the vector .<br>Convergence of any stationary method depends entirely on the spectral properties of .  Writing the error  one sees  <br><br>so a necessary and sufficient condition for  is  <br><br>where  denotes the spectral radius of .  In practice one often uses matrix norms to obtain more tangible sufficient conditions, such as  in a chosen norm.<br><br>One begins by splitting  into its diagonal , strictly lower‐triangular part , and strictly upper‐triangular part , so that  <br><br>Rewriting  as  suggests the update  <br><br>Equivalently, in component form, the th coordinate at iteration  is  <br><br>Here each new entry  immediately feeds into subsequent updates within the same sweep, distinguishing Gauss–Seidel from the Jacobi method.<br>The convergence lies in the iteration matrix  <br><br>If the spectral radius satisfies  <br><br>then for any initial guess  the sequence  converges to the unique solution , and the error satisfies  <br><br>Sufficient conditions ensuring  include  being strictly or irreducibly diagonally dominant, or  being symmetric positive‐definite.  In the latter case one can show convergence in the ‐norm:  <br><br>with .<br>import math

def gauss_seidel(A, b, x0=None, tol=1e-10, maxiter=1000):
    n = len(A)
    x = x0[:] if x0 is not None else [0.0]*n
    for _ in range(maxiter):
        x_old = x[:]
        for i in range(n):
            sigma = sum(A[i][j]*x[j] for j in range(n) if j != i)
            x[i] = (b[i] - sigma) / A[i][i]
        diff = max(abs(x[i] - x_old[i]) for i in range(n))
        if diff &lt; tol:
            break
    return x
<br><br>Following the Gauss–Seidel update  <br><br>consider the diagonally‐dominant system  <br><br>with initial guess  <br><br>Iteration 1 ():<br>
For , using :  <br><br>For , using :  <br><br>For , using :  <br><br>Thus  <br><br>Iteration 2 ():<br>
For , using :  <br><br>For , using :  <br><br>For , using :  <br><br>Thus  <br><br>and the process continues, with each new component feeding into subsequent updates to drive the residual to zero.  <br><br>The Successive Over‐Relaxation (SOR) method generalizes Gauss–Seidel by introducing a relaxation parameter  to accelerate convergence.  Splitting  <br><br>with  the diagonal of ,  its strict lower‐triangular part and  its strict upper‐triangular part, the SOR update can be written as the fixed‐point iteration  <br><br>In component form, each coordinate is updated by  <br><br>so that one “over‐relaxes” the Gauss–Seidel step towards the new iterate by a factor .<br>Stationarity of the method follows from writing  <br><br>so that  <br><br>remains constant.  Convergence requires .  When  is symmetric positive‐definite, one can show that SOR converges for all  and that the optimal relaxation parameter  <br><br>minimizes the spectral radius of the iteration matrix, yielding the fastest asymptotic rate.  Here  is the spectral radius of the Gauss–Seidel iteration matrix.<br>def sor(A, b, omega, x0=None, tol=1e-10, maxiter=1000):
    n = len(A)
    x = x0[:] if x0 is not None else [0.0]*n
    for _ in range(maxiter):
        x_old = x[:]
        for i in range(n):
            sigma = sum(A[i][j]*x[j] for j in range(i)) + sum(A[i][j]*x_old[j] for j in range(i+1, n))
            x[i] = (1-omega)*x_old[i] + omega*(b[i] - sigma)/A[i][i]
        if max(abs(x[i] - x_old[i]) for i in range(n)) &lt; tol:
            break
    return x
<br><br>Starting from the system  <br><br>with initial guess  and relaxation parameter , the SOR update is  <br><br>At iteration 1:<br>For , since ,<br><br>For , using  and ,<br><br>For , using , ,<br><br>Thus  <br><br>Iteration 2:<br>For , using ,<br><br>For , using , ,<br><br>For , using ,<br><br>Hence after two SOR sweeps  <br><br>and further iterations proceed in the same fashion.  <br><br>Krylov subspace methods form a powerful class of iterative techniques for solving large linear systems  <br><br>and eigenvalue problems by projecting the problem onto a sequence of growing subspaces. Starting from an initial guess , one defines the residual  <br><br>and builds the th Krylov subspace  <br><br>Rather than eliminating unknowns directly, these methods seek an approximate solution<br><br>by enforcing a suitable orthogonality or minimal‐residual condition on the new residual .<br>The key insight is that each iterate lives in a low‐dimensional invariant subspace of the Krylov sequence, and one can characterize convergence in terms of polynomial approximation.  Indeed, if one writes <br><br>for some degree‐ polynomial  with , then optimizing the choice of  reduces to minimizing  in a given norm.  Different Krylov methods correspond to different strategies for selecting  and enforcing conditions—such as requiring the residual to be orthogonal to  (Galerkin condition) or minimizing its norm (Petrov–Galerkin condition).<br><br>The Conjugate Gradient (CG) method is a Krylov‐subspace algorithm tailored to solve  <br><br>when  is symmetric and positive‐definite.  At its heart, CG finds at step  an approximate solution  <br><br>that minimizes the ‐norm of the error, , over .  Equivalently,  is the unique vector in  whose residual  <br><br>is orthogonal to  in the Euclidean inner product.<br>The algorithm proceeds by building a sequence of search directions , which are ‐conjugate:  <br><br>Starting from  with residual , one sets  and then for  computes  <br><br>To generate the next search direction one uses the recurrence  <br><br>Because of ’s symmetry and positivity, one shows by induction that the directions remain ‐conjugate, and the residuals satisfy the Galerkin condition .<br>A property is that CG converges in at most  steps in exact arithmetic, producing the exact solution.  More usefully, error bounds follow from polynomial approximation: if  and  are the extreme eigenvalues of , then  <br><br>measures the condition number of .  Thus CG rapidly damps error components associated with extreme eigenvalues, with convergence accelerating as  approaches 1.<br>Computationally, each iteration costs one matrix‐vector product , two vector inner products, and a few saxpy updates, all  for sparse .  <br>def conjugate_gradient(A, b, x0=None, tol=1e-10, maxiter=None):
    n = len(b)
    x = x0[:] if x0 is not None else [0.0]*n
    r = [b[i] - sum(A[i][j]*x[j] for j in range(n)) for i in range(n)]
    p = r[:]
    rsold = sum(ri*ri for ri in r)
    maxiter = maxiter or n
    for _ in range(maxiter):
        Ap = [sum(A[i][j]*p[j] for j in range(n)) for i in range(n)]
        alpha = rsold / sum(p[i]*Ap[i] for i in range(n))
        x = [x[i] + alpha*p[i] for i in range(n)]
        r = [r[i] - alpha*Ap[i] for i in range(n)]
        rsnew = sum(ri*ri for ri in r)
        if rsnew &lt; tol*tol:
            break
        beta = rsnew / rsold
        p = [r[i] + beta*p[i] for i in range(n)]
        rsold = rsnew
    return x
<br><br>Consider the SPD system  <br><br>Compute the initial residual and direction:  <br><br>Evaluate  <br><br>so  <br><br>Update solution and residual:  <br><br><br>Compute the next direction:  <br><br><br>Then  <br><br><br>Final update yields the exact solution:  <br><br>Thus CG converges in two steps to .  <br><br>The Bi‐Conjugate Gradient (BiCG) method extends the conjugate‐gradient idea to the general nonsymmetric case.  Given a nonsingular matrix  <br><br>we seek  solving  by simultaneously building two Krylov sequences: one for  and one for its transpose .  Starting from an initial guess , define the primal residual  <br><br>and choose a shadow residual  (often set ).  The method maintains bi‐orthogonality  <br><br>and builds search directions  and  satisfying  <br><br>At each step , one computes the scalar  <br><br>and updates  <br><br><br>then form  <br><br>and set  <br><br>These short recurrences ensure that the two families  and  remain ‐ and ‐conjugate, respectively.<br>In exact arithmetic BiCG produces the exact solution in at most  iterations, since the primal and dual residuals span increasing Krylov subspaces  <br><br>Convergence can be understood via polynomial approximation of  on these spaces, but in practice breakdowns may occur if .  Various safeguards—look‐aheads and switching to transpose‐free variants—have been developed to handle such breakdowns.<br>Each iteration of BiCG requires one matrix–vector product with , one with , and two vector inner products, costing  per step for sparse , and storing only a handful of vectors.  <br>import math

def bicg(A, b, x0=None, tol=1e-10, maxiter=None):
    n = len(b)
    def matvec(M, v):
        return [sum(M[i][j]*v[j] for j in range(n)) for i in range(n)]
    def matvecT(M, v):
        return [sum(M[j][i]*v[j] for j in range(n)) for i in range(n)]
    def dot(u, v):
        return sum(ui*vi for ui, vi in zip(u, v))
    x = x0[:] if x0 is not None else [0.0]*n
    r = [b_i - ai for b_i, ai in zip(b, matvec(A, x))]
    r_t = r[:]
    p = r[:]
    p_t = r_t[:]
    rho = dot(r_t, r)
    maxiter = maxiter or n
    for _ in range(maxiter):
        Ap = matvec(A, p)
        ATpt = matvecT(A, p_t)
        denom = dot(p_t, Ap)
        if denom == 0:
            break
        alpha = rho / denom
        x = [xi + alpha*pi for xi, pi in zip(x, p)]
        r = [ri - alpha*api for ri, api in zip(r, Ap)]
        r_t = [rti - alpha*atpti for rti, atpti in zip(r_t, ATpt)]
        if math.sqrt(dot(r, r)) &lt; tol:
            break
        rho_new = dot(r_t, r)
        beta = rho_new / rho
        p = [ri + beta*pi for ri, pi in zip(r, p)]
        p_t = [rti + beta*pti for rti, pti in zip(r_t, p_t)]
        rho = rho_new
    return x
<br><br>Starting with the nonsymmetric system  <br><br>whose exact solution is , choose  <br><br>Compute  <br><br>so  <br><br>Update solution and residuals:  <br><br><br><br>Form the bi‐orthogonal update:  <br><br><br>Update directions:  <br><br><br>Compute the next step‐length:  <br><br><br>Final update gives the exact solution:  <br><br><br>The Generalized Minimal Residual (GMRES) method seeks an approximate solution  <br><br>by choosing at step  the vector  <br><br>that minimizes the Euclidean norm of the residual  <br><br>Rather than imposing orthogonality of the residual against the entire Krylov subspace (as in Galerkin methods), GMRES enforces  <br><br>which is equivalent to solving a small least‐squares problem at each iteration.<br>Central to GMRES is the Arnoldi process, which builds an orthonormal basis  of the Krylov subspace via the recurrences  <br><br>where the upper‐Hessenberg coefficients  appear in the  matrix .  One then writes  <br><br>with .  The least‐squares problem  <br><br>yields the update , so that  <br><br>Because  has orthonormal columns, the residual norm equals the minimal least‐squares norm.<br>In exact arithmetic GMRES converges in at most  steps, and its residual reduction can be bounded by  <br><br>linking convergence to the ability of degree‐ polynomials to approximate zero on the spectrum of .  Well‐clustered eigenvalues yield rapid decay, while widely scattered spectra may slow progress.<br>import math

def gmres(A, b, x0=None, tol=1e-8, maxiter=None):
    n = len(b)
    if x0 is None:
        x = [0.0]*n
    else:
        x = x0[:]
    r0 = [b[i] - sum(A[i][j]*x[j] for j in range(n)) for i in range(n)]
    beta = math.sqrt(sum(ri*ri for ri in r0))
    if beta &lt; tol:
        return x
    maxiter = maxiter or n
    V = []
    V.append([ri/beta for ri in r0])
    H = [[0.0]*maxiter for _ in range(maxiter+1)]
    cs = [0.0]*maxiter
    sn = [0.0]*maxiter
    g = [0.0]*(maxiter+1)
    g[0] = beta

    for k in range(maxiter):
        # Arnoldi
        w = [sum(A[i][j]*V[k][j] for j in range(n)) for i in range(n)]
        for j in range(k+1):
            H[j][k] = sum(w[i]*V[j][i] for i in range(n))
            for i in range(n):
                w[i] -= H[j][k] * V[j][i]
        H[k+1][k] = math.sqrt(sum(wi*wi for wi in w))
        if H[k+1][k] != 0:
            V.append([wi / H[k+1][k] for wi in w])
        else:
            V.append([0.0]*n)

        # Apply Givens rotations
        for i in range(k):
            temp = cs[i]*H[i][k] + sn[i]*H[i+1][k]
            H[i+1][k] = -sn[i]*H[i][k] + cs[i]*H[i+1][k]
            H[i][k] = temp

        # Compute i-th rotation
        denom = math.hypot(H[k][k], H[k+1][k])
        if denom == 0:
            cs[k], sn[k] = 1, 0
        else:
            cs[k] = H[k][k]/denom
            sn[k] = H[k+1][k]/denom
        H[k][k] = cs[k]*H[k][k] + sn[k]*H[k+1][k]
        H[k+1][k] = 0.0

        # Update g
        gk = g[k]
        g[k]   = cs[k]*gk
        g[k+1] = -sn[k]*gk

        # Check convergence
        if abs(g[k+1]) &lt; tol:
            # Solve least squares
            y = [0.0]*(k+1)
            for i in range(k, -1, -1):
                s = g[i]
                for j in range(i+1, k+1):
                    s -= H[i][j]*y[j]
                y[i] = s/H[i][i]
            # Update solution
            x_new = x[:]
            for j in range(k+1):
                for i in range(n):
                    x_new[i] += V[j][i]*y[j]
            return x_new

    # Fallback after maxiter
    y = [0.0]*maxiter
    for i in range(maxiter-1, -1, -1):
        s = g[i]
        for j in range(i+1, maxiter):
            s -= H[i][j]*y[j]
        y[i] = s/H[i][i]
    x_new = x[:]
    for j in range(maxiter):
        for i in range(n):
            x_new[i] += V[j][i]*y[j]
    return x_new
<br><br>Starting with the nonsymmetric system  <br><br>we carry out GMRES with .<br>Compute the initial residual and its norm:  <br><br>Define  <br><br>Arnoldi process to build  and the Hessenberg matrix :<br>
<br>
  





<br>
  





<br>Thus  <br><br>We now solve the small least‐squares problem  <br><br>Writing , we minimize  <br><br>Setting partial derivatives to zero:<br>
<br>:<br>

<br>:<br>
Substitute  to get , hence .
<br>Finally, the GMRES iterate is  <br><br>and one checks  <br><br>so GMRES converges in two steps to the exact solution.  <br><br>Preconditioning transforms the original system  <br><br>into an equivalent one in which the spectrum of the coefficient matrix is more favorable for iterative solution.  One introduces a matrix  (the preconditioner) that approximates  but is much cheaper to invert, and rewrites the system as  <br><br>or, in split form,  <br><br>depending on whether one applies left, right, or symmetric preconditioning.  Since the exact solution is unchanged, the goal is purely to cluster the eigenvalues of  (or of the symmetrized version) near unity, thereby reducing the condition number  <br><br>and accelerating convergence of Krylov or stationary methods.<br>From a theoretical standpoint, preconditioning can be viewed as choosing a new inner product or norm in which  behaves more like a well-conditioned operator.  For instance, in the symmetric positive‐definite case one often works with the ‐inner product  <br><br>so that the preconditioned matrix  is self‐adjoint in this inner product.  Iterative solvers such as Conjugate Gradient then minimize the error norm relative to , leading to estimates of the form  <br><br>with , highlighting the central role of condition‐number reduction.<br>In the language of polynomial approximation, preconditioning modifies the set of polynomials used to approximate the inverse of .  If an iterative method constructs iterates via  <br><br>then with preconditioning one effectively replaces  by , seeking  <br><br>on the spectrum of .  Good preconditioners make the spectrum tightly clustered or well separated from zero, so low‐degree polynomials achieve high accuracy and the residuals decay rapidly.<br>Though the ideal preconditioner would be , that offers no computational savings.  In practice, one balances quality of approximation against ease of applying .  <br><br>The incomplete LU (ILU) factorization is an approximate variant of the full  decomposition, designed to serve as a preconditioner for iterative solvers.  Given a sparse matrix  <br><br>where  is its diagonal,  its strictly lower‐triangular part and  its strictly upper‐triangular part, one seeks sparse factors  and  such that  <br><br>but with  and  retaining only a prescribed sparsity pattern.  The preconditioner is then , and one solves  <br><br>by an iterative method, exploiting that triangular solves with  and  are cheap.<br>A common strategy is to carry out Gaussian elimination on  row by row, but to “drop” any fill‐in entry whose position lies outside the original sparsity pattern (the zero‐fill ILU(0)), or whose magnitude falls below a tolerance (threshold ILUT).  Concretely, at step  one would compute the exact multipliers  <br><br>for , but only store those  for which  belongs to the chosen pattern (or  exceeds a threshold), discarding the rest.  Analogous drops occur in forming .  The resulting factors satisfy  <br><br>where  is the “remainder” sparsity‐structured error whose size one tries to balance against storage and cost.<br>def ilu0(A):
    n = len(A)
    L = [[0.0]*n for _ in range(n)]
    U = [[0.0]*n for _ in range(n)]
    for i in range(n):
        L[i][i] = 1.0
    for k in range(n):
        for j in range(k, n):
            if A[k][j] != 0.0:
                s = sum(L[k][s]*U[s][j] for s in range(k))
                U[k][j] = A[k][j] - s
        for i in range(k+1, n):
            if A[i][k] != 0.0:
                s = sum(L[i][s]*U[s][k] for s in range(k))
                L[i][k] = (A[i][k] - s) / U[k][k]
    return L, U
<br><br>Starting with the cyclic system  <br><br>we perform ILU(0), retaining only the original nonzero pattern of .<br>At step , the pivot is  <br><br>For  with  we form  <br><br>We update row 2 and row 4 only in columns  where :<br><br>At step , the pivot is  <br><br>For  with  we form  <br><br>Update in columns  where :<br><br>At step , the pivot is  <br><br>For  we form  <br><br>and update<br><br>All other potential fill‐ins (e.g.\  and ) are dropped, giving the incomplete factors  <br><br>The remainder  <br><br>has nonzeros exactly at the dropped positions:<br><br><br>The incomplete Cholesky factorization is a sparse, approximate variant of the full Cholesky decomposition tailored for symmetric positive‐definite matrices  <br><br>that serves as an efficient preconditioner.  One fixes a sparsity pattern —for example the pattern of nonzeros in the lower triangle of  (IC(0))—and seeks a lower‐triangular  with<br><br>Algorithmically, one proceeds row by row as in classical Cholesky, but only retains updates .  Concretely, for  one sets  <br><br>and for each  with   <br><br>Any fill‐in entry outside  is dropped (set to zero), and variants such as threshold IC drop entries whose magnitude falls below a tolerance.<br>The preconditioner is then  <br><br>and one solves the preconditioned system  <br><br>using an iterative solver.  Writing the “error” of the factorization as  <br><br>one sees  <br><br>so clustering of the spectrum of —and hence rapid convergence—hinges on keeping  small while preserving sparsity.<br>Computational cost is roughly half that of an ILU preconditioner of comparable fill, since symmetry halves both storage and arithmetic.  In practice, incomplete Cholesky preconditioners dramatically accelerate Krylov methods (e.g.\ CG), because they capture the dominant quadratic‐form structure of  at low cost. <br>import math

def incomplete_cholesky(A):
    n = len(A)
    L = [[0.0]*n for _ in range(n)]
    for i in range(n):
        s = sum(L[i][k]**2 for k in range(i) if A[i][k] != 0.0)
        val = A[i][i] - s
        if val &lt;= 0:
            raise ValueError("Non-positive pivot encountered")
        L[i][i] = math.sqrt(val)
        for j in range(i+1, n):
            if A[j][i] != 0.0:
                s = sum(L[j][k]*L[i][k] for k in range(i) if A[i][k] != 0.0 and A[j][k] != 0.0)
                L[j][i] = (A[j][i] - s) / L[i][i]
    return L
<br><br>Consider the SPD matrix  <br><br>and fix the IC(0) sparsity pattern—the nonzeros of  in the lower triangle:  <br><br>For  we have  <br><br>Entries below in column 1 at  and  are computed by  <br><br>For , the diagonal is  <br><br>Below at , since no  fill‐in is allowed the sum term vanishes, giving  <br><br>For , the diagonal is  <br><br>At  the update drops any fill‐in outside the pattern, so  <br><br>Finally for , the diagonal uses only the allowed entries in column 1 and 3:  <br><br>Collecting these, the IC(0) factor is  <br><br>with  approximating  and no fill‐in outside the original sparsity pattern.  <br><br>The Jacobi preconditioner is the simplest and most easily implemented of the so‐called diagonal preconditioners.  Given a nonsingular matrix  <br><br>where  is the diagonal part of , and  and  its strict lower‐ and upper‐triangular parts, one chooses the preconditioner  <br><br>This yields the preconditioned system  <br><br>so that one need only apply the cheap diagonal solve  at each iteration of a Krylov or stationary method.<br>From a theoretical standpoint, the effect of the Jacobi preconditioner is to cluster the eigenvalues of  around unity to the extent that  captures the dominant scaling of .  Writing the preconditioned iteration matrix for, say, the Jacobi stationary method gives  <br><br>and convergence requires  <br><br>In practice, one analyzes the spectrum of  or bounds its norm to obtain sufficient conditions, such as strict diagonal dominance of  ensuring that all eigenvalues of  lie in a small disk around 1.  <br>While Jacobi preconditioning performs only  work per application and is trivially parallelizable—each component update  can be done independently—it often yields only modest acceleration of convergence unless the diagonal of  already dominates.  In symmetric positive‐definite settings, the condition number of the preconditioned matrix is  <br><br>and one sees that extreme variation in the diagonal entries limits the clustering of eigenvalues and hence the effectiveness of the preconditioner.<br>A simple enhancement is the weighted Jacobi preconditioner, where one takes  <br><br>with a relaxation weight , thereby scaling the preconditioning step.  This can improve stability and convergence for certain matrices, but the central idea remains the same: approximate  by its diagonal to reduce both storage and computational cost, at the expense of only partial spectral equilibration.<br>def jacobi_preconditioner(A):
    n = len(A)
    M_inv = [0.0] * n
    for i in range(n):
        if A[i][i] == 0:
            raise ValueError("Zero diagonal entry; cannot form Jacobi preconditioner.")
        M_inv[i] = 1.0 / A[i][i]
    return M_inv

def apply_jacobi(M_inv, r):
    return [M_inv[i] * r[i] for i in range(len(r))]

def pcg_jacobi(A, b, x0=None, tol=1e-8, maxiter=None):
    import math
    n = len(b)
    x = x0[:] if x0 is not None else [0.0]*n
    M_inv = jacobi_preconditioner(A)
    r = [b[i] - sum(A[i][j]*x[j] for j in range(n)) for i in range(n)]
    z = apply_jacobi(M_inv, r)
    p = z[:]
    rz_old = sum(r[i]*z[i] for i in range(n))
    maxiter = maxiter or n
    for _ in range(maxiter):
        Ap = [sum(A[i][j]*p[j] for j in range(n)) for i in range(n)]
        alpha = rz_old / sum(p[i]*Ap[i] for i in range(n))
        x = [x[i] + alpha*p[i] for i in range(n)]
        r = [r[i] - alpha*Ap[i] for i in range(n)]
        if math.sqrt(sum(ri*ri for ri in r)) &lt; tol:
            break
        z = apply_jacobi(M_inv, r)
        rz_new = sum(r[i]*z[i] for i in range(n))
        beta = rz_new / rz_old
        p = [z[i] + beta*p[i] for i in range(n)]
        rz_old = rz_new
    return x
<br><br>Starting with the diagonally‐dominant system  <br><br>we split  with  <br><br>The Jacobi preconditioner is , so the stationary update is  <br><br>With initial guess , the first sweep () gives<br>
For :  <br><br>For :  <br><br>For :  <br><br>Thus  <br><br>On the second sweep (), we use the new values immediately:<br>
For :  <br><br>For :  <br><br>For :  <br><br>Hence  <br><br>In matrix‐form the iteration matrix is  <br><br>and convergence occurs if , which here follows from the strict diagonal dominance of .  <br><br><br>The Power Method is a simple iterative algorithm for approximating the dominant eigenvalue and its associated eigenvector of a matrix  <br><br>Starting from an arbitrary nonzero initial vector , one repeatedly applies  and rescales to prevent overflow:  <br><br>Under mild conditions—most importantly that  has a unique eigenvalue  of maximum modulus and that  has a nonzero component along its eigenvector —this process drives  up to sign, and the Rayleigh quotient  <br><br>converges to .<br>To see why, write the spectral decomposition (assuming diagonalizable )  <br><br>with eigenpairs  ordered so .  Then  <br><br>After normalization, the contribution of each  for  is damped by the factor , so  aligns with .  The asymptotic error in the eigenvector satisfies  <br><br>and the eigenvalue estimate error behaves similarly.<br>In practice one often tracks the scalar  <br><br>which converges to .  To recover the sign (or complex phase) of , one can form  <br><br>Though elegant, the basic Power Method only finds the largest‐magnitude eigenpair and can converge slowly when  is close to one.  <br>import math

def power_method(A, x0, tol=1e-8, maxiter=1000):
    n = len(A)
    x = x0[:]
    for _ in range(maxiter):
        y = [sum(A[i][j]*x[j] for j in range(n)) for i in range(n)]
        norm_y = math.sqrt(sum(yi*yi for yi in y))
        x_next = [yi/norm_y for yi in y]
        Ax = [sum(A[i][j]*x_next[j] for j in range(n)) for i in range(n)]
        lambda_next = sum(x_next[i]*Ax[i] for i in range(n))
        if math.sqrt(sum((x_next[i]-x[i])**2 for i in range(n))) &lt; tol:
            return lambda_next, x_next
        x = x_next
    return lambda_next, x
<br><br>Consider the matrix  <br><br>and initial vector  <br><br>Compute  <br><br><br><br>The Rayleigh quotient gives  <br><br>Next,  <br><br><br><br><br>After two iterations,  <br><br>so  approximates the dominant eigenvector and  approximates the dominant eigenvalue .  <br><br>Inverse iteration is a simple yet powerful technique for approximating an eigenvector of a matrix  associated with an eigenvalue near a chosen shift .  One begins with an initial guess  and at each iteration solves the linear system  <br><br>then normalizes  <br><br>If  this reduces to the classic inverse power method, which converges to the eigenvector corresponding to the eigenvalue of  with smallest magnitude.  More generally, by choosing  near an eigenvalue , the factor  becomes dominant in the spectrum of , and the iterates  align with the corresponding eigenvector .<br>To see this algebraically, suppose  is diagonalizable as  with eigenpairs .  Writing the initial vector in that basis,  <br><br>one obtains after one inverse‐iteration step  <br><br>After normalization, the component corresponding to the eigenvalue  closest to  dominates, since  <br><br>Thus the error in the eigenvector approximation decays geometrically at rate  <br><br>In practice, each iteration requires solving one linear system with the shifted matrix , at cost comparable to a single direct solve or preconditioned iterative solve.  If one updates the shift dynamically using the Rayleigh quotient  <br><br>one arrives at the Rayleigh–quotient iteration, which under mild conditions converges cubically.  Rayleigh Quotient Iteration<br>import math

def inverse_iteration(A, x0, sigma, tol=1e-8, maxiter=1000):
    n = len(A)
    x = x0[:]
    for _ in range(maxiter):
        B = [row[:] for row in A]
        for i in range(n):
            B[i][i] -= sigma
        y = gaussian_elimination([row[:] for row in B], x[:])
        normy = math.sqrt(sum(yi*yi for yi in y))
        x_new = [yi/normy for yi in y]
        if math.sqrt(sum((x_new[i]-x[i])**2 for i in range(n))) &lt; tol:
            x = x_new
            break
        x = x_new
    Ax = [sum(A[i][j]*x[j] for j in range(n)) for i in range(n)]
    mu = sum(x[i]*Ax[i] for i in range(n))
    return mu, x
<br><br>Starting with the matrix  <br><br>choose the shift and initial guess  <br><br>Then  <br><br>Solve the first shifted system  <br><br>From the first row,  <br><br>and the second row gives  <br><br><br>Compute the norm  <br><br>and normalize  <br><br>Next, solve  <br><br>From the first row,  <br><br>and the second row gives  <br><br><br>Compute  <br><br>and normalize  <br><br>After two inverse‐iteration steps with shift , the vector  <br><br>already aligns with the eigenvector of  whose eigenvalue is closest to .  <br><br>A real symmetric matrix  <br><br>enjoys a remarkably clean structure: all of its eigenvalues are real, and there exists an orthonormal basis of  consisting of eigenvectors of .  Concretely, one can find an orthogonal matrix  <br><br>and a diagonal matrix  <br><br>with each , such that  <br><br>This is the spectral theorem for real symmetric matrices.<br>The reality of the spectrum follows from the Rayleigh quotient  <br><br>which for any nonzero  takes a value in the convex hull of the eigenvalues of .  By optimizing  over the unit sphere one sees that there must be at least one real eigenvalue, and symmetry then guarantees that all algebraic multiplicities coincide with geometric multiplicities so that  is diagonalizable.<br>Orthonormality of the eigenvectors arises because if  and  with , then  <br><br>so , forcing .  One then normalizes each eigenvector to unit length, assembling them into the orthogonal matrix  above.<br>This decomposition  has many consequences.  It shows immediately that  <br><br>It also gives a functional calculus: for any real‐valued function  defined on the spectrum of ,  <br><br>where  is the diagonal matrix with entries .  In particular, one defines matrix square‐roots, exponentials, and inverses (when no ) in this way.<br>Geometrically, the spectral theorem classifies quadratic forms.  Writing  <br><br>reveals the signature of the form and permits reduction to a sum of squares.  In applications—from principal component analysis in statistics to normal‐mode analysis in mechanics—this orthogonal diagonalization underlies both theoretical insight and computational algorithms.<br><br>Every square matrix over the complex field has a Schur decomposition, which expresses it as a unitarily‐similar upper‐triangular matrix.  For any  <br><br>there exists a unitary matrix  <br><br>and an upper‐triangular matrix  <br><br>such that  <br><br>The diagonal entries of  are exactly the eigenvalues of , listed (with multiplicity) in some order:  <br><br>Uni­tary similarity preserves spectral and norm properties, so the Schur form reveals all eigenvalues at once without leaving the comfortable setting of orthonormal bases.  In particular, for a real matrix one obtains a real Schur form with  and  diagonal blocks when complex pairs occur, ensuring  remains real orthogonal.<br>Algorithmically, the Schur decomposition underlies the QR algorithm: iterated shifts and QR factorizations  <br><br>drive  while accumulating  <br><br>Because each  is unitary, numerical orthogonality is well‐controlled and the computed eigenvalues—lying on the diagonal of —are forward‐stable.<br>Theoretical consequences of the Schur decomposition are manifold.  Any holomorphic function  can be evaluated on  by  <br><br>where  is upper‐triangular with  on the diagonal and appropriate divided‐difference entries above.  Moreover, normal matrices () are precisely those whose Schur form is diagonal, recovering the spectral theorem as a special case.<br>import math

def matmul(A, B):
    m, p = len(A), len(B[0])
    n = len(B)
    C = [[0.0]*p for _ in range(m)]
    for i in range(m):
        for j in range(p):
            s = 0.0
            for k in range(n):
                s += A[i][k]*B[k][j]
            C[i][j] = s
    return C

def qr_decomposition(A):
    m = len(A)
    n = len(A[0])
    Q = [[0.0]*n for _ in range(m)]
    R = [[0.0]*n for _ in range(n)]
    for j in range(n):
        v = [A[i][j] for i in range(m)]
        for i in range(j):
            R[i][j] = sum(Q[k][i]*A[k][j] for k in range(m))
            for k in range(m):
                v[k] -= R[i][j]*Q[k][i]
        R[j][j] = math.sqrt(sum(vk*vk for vk in v))
        for k in range(m):
            Q[k][j] = v[k]/R[j][j]
    return Q, R

def schur(A, tol=1e-10, maxiter=1000):
    n = len(A)
    U = [[1.0 if i==j else 0.0 for j in range(n)] for i in range(n)]
    T = [row[:] for row in A]
    for _ in range(maxiter):
        Q, R = qr_decomposition(T)
        T = matmul(R, Q)
        U = matmul(U, Q)
        # convergence: check subdiagonal small
        if all(abs(T[i][i-1]) &lt;= tol for i in range(1, n)):
            break
    return U, T
<br><br>Consider the matrix  <br><br>We seek a unitary  and upper‐triangular  so that .<br>First find the eigenvalues by solving  <br><br>giving  <br><br>Next compute orthonormal eigenvectors:<br>For , solve  <br><br>Choose .  Its norm is  <br><br>so  <br><br>For , solve  <br><br>Choose .  Its norm is  <br><br>so  <br><br>Form the unitary matrix  <br><br>and compute  <br><br>First  <br><br>Then  <br><br>Hence the Schur decomposition is  <br><br><br>The singular value decomposition (SVD) of a real (or complex) matrix  <br><br>is the factorization  <br><br>where  and  are orthogonal matrices (or unitary if  is complex), and  <br><br>with  and singular values  on the diagonal.  The columns of  are called the left singular vectors, the columns of  the right singular vectors, and the nonzero  are the singular values.<br>Existence of the SVD follows from applying the spectral theorem to the symmetric positive‐semidefinite matrices  and .  One finds an orthonormal basis  of  consisting of eigenvectors of  with eigenvalues , and defines  when .  The orthogonality of  and  then ensures  and , and the relations  <br><br>encode the action of  as stretching along orthogonal directions.<br>The full SVD captures the rank and range‐nullspace structure of : if , then exactly  singular values  are positive, and one may write the “thin” or economic SVD  <br><br>where , , and .  This yields the best‐rank‐ approximation property: for any , the truncated SVD  <br><br>minimizes  (in the spectral or Frobenius norms) over all matrices  of rank at most .<br>Computationally, one typically reduces  to bidiagonal form by orthogonal transformations and then applies the Golub–Kahan iterative procedure to diagonalize the bidiagonal matrix, achieving overall cost  (for ).  <br>The full SVD is more expensive than, say, an  or QR factorization, but its robustness and the richness of the decomposition. revealing both geometry and low‐rank structure, make it indispensable in applications ranging from principal‐component analysis to solving ill‐posed inverse problems via the pseudoinverse  <br><br>import math

def svd(A, tol=1e-10, maxiter=1000):
    m, n = len(A), len(A[0])
    r = min(m, n)
    ATA = [[sum(A[k][i]*A[k][j] for k in range(m)) for j in range(n)] for i in range(n)]
    V = [[0.0]*r for _ in range(n)]
    S = [0.0]*r
    for k in range(r):
        x = [1.0]*n
        for _ in range(maxiter):
            y = [sum(ATA[i][j]*x[j] for j in range(n)) for i in range(n)]
            normy = math.sqrt(sum(yi*yi for yi in y))
            y = [yi/normy for yi in y]
            if math.sqrt(sum((y[i]-x[i])**2 for i in range(n))) &lt; tol:
                break
            x = y
        lam = sum(x[i]*sum(ATA[i][j]*x[j] for j in range(n)) for i in range(n))
        sigma = math.sqrt(max(lam, 0.0))
        S[k] = sigma
        for i in range(n):
            V[i][k] = x[i]
        for i in range(n):
            for j in range(n):
                ATA[i][j] -= lam * x[i] * x[j]
    U = [[0.0]*r for _ in range(m)]
    for k in range(r):
        for i in range(m):
            U[i][k] = sum(A[i][j]*V[j][k] for j in range(n)) / S[k]
    return U, S, V
<br><br>Consider the  matrix  <br><br>
<br>
Form   


<br>
Compute eigenvalues of <br>
Solve  

Hence  


<br>
Singular values  


<br>
Right singular vectors  (eigenvectors of )  

<br>For :  

Normalize:  


<br>For :  

Normalize:  




<br>
Left singular vectors : compute  and divide by .  

<br>For :  


<br>For :  




<br>
Assemble the “thin” SVD  

Thus  


]]></description><link>ch11-linear-algebra.html</link><guid isPermaLink="false">CH11-Linear-Algebra.md</guid><pubDate>Thu, 19 Jun 2025 22:02:17 GMT</pubDate></item><item><title><![CDATA[CH12-Numerical-PDEs]]></title><description><![CDATA[ 
 <br><br>A partial differential equation (PDE) is an equation that relates an unknown function  <br><br>to its partial derivatives.  In general one writes  <br><br>where  and higher‐order derivatives appear as needed. A linear PDE can be written in the form  <br><br>where  is a multi‐index of order .  If  it is homogeneous; otherwise it is inhomogeneous.<br>Second‐order linear PDEs in two variables are classified by examining the principal part  <br><br>One defines the discriminant  <br><br>If  the equation is elliptic, if  it is parabolic, and if  it is hyperbolic.  This reflects geometric properties of the characteristic curves along which information propagates.<br>Classic examples include the heat equation (parabolic)  <br><br>the wave equation (hyperbolic)  <br><br>and Laplace’s equation (elliptic)  <br><br>To single out a unique solution one must impose initial and/or boundary conditions.  On a spatial boundary  one may specify  <br>
<br>Dirichlet:  ,  
<br>Neumann:  ,  
<br>Robin (mixed):  .  
<br>For evolution equations (parabolic or hyperbolic) one also prescribes initial data at time .  For instance, the wave equation requires  <br><br>which together form a Cauchy problem specifying both the solution and its normal (time) derivative on the initial surface.  <br><br><br>Separation of variables is a technique that seeks solutions to a PDE by assuming the dependence on each coordinate “separates” into a product of single‐variable functions.  One writes, for example,  <br><br>and upon substitution into the PDE the variables disentangle, leaving ordinary differential equations (ODEs) for  and  linked by a constant, the separation constant.<br>For the one‐dimensional heat equation  <br><br>with homogeneous Dirichlet boundary conditions , substitution gives  <br><br>or equivalently  <br><br>Here  is chosen so that the spatial problem  <br><br>admits nontrivial solutions, namely  with eigenfunctions .  The temporal ODE  <br><br>yields .  Superposition over  then builds the general solution  <br><br>with coefficients  determined by the initial profile  via a Fourier sine series.<br>Turning to the wave equation  <br><br>one again sets , leading to  <br><br>The same eigenvalue problem ,  picks out , but now the time‐ODE is  <br><br>whose solutions are sinusoidal: .  Thus the general motion is  <br><br>with  fixed by initial displacement and velocity.<br>For Laplace’s equation in a rectangle, say  <br><br>one posits  and finds  <br><br>Boundary conditions (for instance , , ) again force a Sturm–Liouville problem for  with eigenvalues  and , while  (or exponentials) ensures decay or prescribed values in .  Superposition yields  <br><br>with  determined by expanding  in a sine series.<br><br>When one applies separation of variables to a PDE on a bounded domain, the spatial part invariably leads to an eigenvalue problem of the form  <br><br>subject to homogeneous boundary conditions.  Here  is a second‐order self‐adjoint differential operator,  is a weight function (often unity), and  plays the role of the separation constant.<br>For a one‐dimensional rod of length  with Dirichlet boundaries, one finds the Sturm–Liouville problem  <br><br>Requiring nontrivial solutions forces , with eigenfunctions .  More generally, Robin or Neumann conditions  <br><br>produce a transcendental equation for  whose countably infinite roots label the modes.<br>The key theoretical insight is that , when viewed on an appropriate Hilbert space with inner product  <br><br>is symmetric.  This implies real eigenvalues and orthogonality of eigenfunctions:  <br><br>Completeness follows under mild regularity conditions, so that any initial or boundary data can be expanded in the orthonormal basis .<br>In higher dimensions, one encounters analogous spectral problems.  On a domain  with Dirichlet boundary, the Laplacian yields  <br><br>whose eigenfunctions are the spatial modes in the separation series for heat or wave equations.  The spectrum remains discrete and unbounded above, and Weyl’s law describes the asymptotic growth of  in terms of the area or volume of .<br>Physically, each eigenpair  represents a vibration mode or heat‐diffusion mode whose temporal behavior is governed by the associated time‐ODE (exponential decay  for heat, or oscillation at frequency  for waves).  The orthogonality and completeness guarantee that an arbitrary initial profile decomposes uniquely into these natural modes.<br><br>Once the separated modes  have been identified, the next step is to expand the initial or boundary data in the corresponding Fourier series.  For a Dirichlet problem on , the eigenfunctions are , which satisfy  <br><br>Any reasonable function  can then be written as  <br><br>When the boundary conditions are Neumann (), the appropriate basis is , and one writes  <br><br>Mixed (Robin) conditions lead to more involved orthogonality relations but follow the same principle: find  orthogonal under the weight, then project.<br>In time‐dependent problems, one substitutes the Fourier expansion of the initial data into the modal solution.  For the heat equation, for instance,  <br><br>Here each coefficient  carries through unaltered into the time‐factor, ensuring that the initial profile is exactly matched at .<br>The convergence of the Fourier series to  depends on the regularity of .  If  is piecewise smooth, the series converges pointwise away from discontinuities and in the  sense overall.  <br><br>Starting with the heat equation  <br><br>with Neumann boundary conditions  <br><br>and initial profile  <br><br>we seek a separated solution  <br><br>Substitution gives  <br><br>so that dividing by  yields  <br><br>We thus obtain two ODEs:<br>The spatial ODE is  <br><br>with boundary conditions  <br><br>We look first for the  mode: if , then  so  <br><br>and . The conditions  and  force , so .  <br>For , write . The general solution is  <br><br>The derivative is  <br><br>Imposing  gives  <br><br>Hence , and  <br><br>The condition  then yields  <br><br>Thus the nonzero eigenvalues are  <br><br>with corresponding eigenfunctions (choosing )  <br><br>The temporal ODE is  <br><br>so for each  we have  <br><br>By superposition, the general solution is  <br><br>To satisfy the initial condition , we write  <br><br>The constant coefficient is  <br><br>For , the cosine modes are orthogonal under  <br><br>Multiplying both sides of  <br><br>by  and integrating over  gives  <br><br>Therefore  <br><br>We now compute  <br><br>by two successive integrations by parts.  First set  <br><br>Then  <br><br>Evaluate the boundary term:  <br><br>since .  Thus  <br><br>Call the remaining integral  <br><br>Integrate by parts again with  <br><br>Then  <br><br>The boundary term is  <br><br>The remaining integral is  <br><br>Hence  <br><br>Substituting back into  gives  <br><br>Therefore the coefficient is  <br><br>Putting all pieces together, the solution is  <br><br>Explicitly, the first few terms are  <br><br>which indeed satisfies the Neumann conditions, , and evolves according to the heat equation.  <br><br>When a PDE is posed on an unbounded spatial domain, the Fourier transform in space becomes a natural tool to diagonalize constant‐coefficient operators.  For a sufficiently nice function  on  one defines the spatial Fourier transform  <br><br>so that each derivative  turns into multiplication by .  This reduces a PDE in  to a family of ordinary differential equations in , one for each frequency .  When the evolution is governed by a constant‐coefficient operator , the transformed equation reads  <br><br>depending on first‐ or second‐order time derivatives.<br>For the heat equation in ,  <br><br>we get  <br><br>whose solution is  <br><br>Inverting the transform by  <br><br>reveals the convolution with the Gaussian kernel  <br><br>so that  and one sees instantaneous smoothing and infinite‐speed propagation characteristic of parabolic equations.<br>In the wave equation  <br><br>the transform yields  <br><br>with general solution  <br><br>The inverse transform can be evaluated by stationary‐phase arguments or known integral formulas, producing in one dimension d’Alembert’s formula  <br><br>and in higher dimensions the Kirchhoff or Poisson formulas which exhibit finite‐speed propagation along characteristic cones.<br>When evolution depends on both space and time derivatives, one may combine the Laplace transform in  with the Fourier transform in .  Writing  <br><br>turns  into multiplication by  (minus initial terms) and spatial derivatives into .  For example, the advection–diffusion equation  <br><br>becomes  <br><br>so that  <br><br>The inverse Laplace transform is carried out by the Bromwich integral  <br><br>and the subsequent inverse Fourier transform reconstructs  as an explicit space‐time convolution with the fundamental solution of the operator.<br><br>We consider the heat equation on   <br><br>and seek  via the spatial Fourier transform  <br><br>
<br>
Transform the PDE.  Since , we get  

an ODE in  for each .

<br>
Transform the initial data.  

since  with .

<br>
Solve the transformed ODE.  With ,  


<br>
Invert the Fourier transform.  We have  

Use the Gaussian integral  

with .  Hence  


<br>
Simplify the prefactor.  Note  

so  

giving  


<br>
Verify the initial condition.  As ,  

matching .

<br>Therefore the solution is  <br><br>which exhibits the Gaussian smoothing of the initial profile under the heat flow.<br><br><br>Finite‐difference methods approximate derivatives by differences on a discrete grid.  Introduce a uniform mesh in space,  for , and in time,  for .  A spatial derivative such as  at  can be approximated by the centered difference  <br><br>and a second derivative by  <br><br>Time derivatives are replaced by forward or backward differences, yielding schemes of various orders and accuracy characterized by their local truncation error.<br>In an explicit scheme, the new time‐level values are computed directly from known previous values.  For the one‐dimensional heat equation  one obtains the Forward Euler / centered‐space update  <br><br>Each  is an explicit linear combination of the “old” values , making the algorithm simple to implement but often subject to severe time‐step restrictions for stability.<br>By contrast, implicit schemes require solving a linear (or nonlinear) system at each time step, since the update involves unknown future values.  The Backward Euler discretization  <br><br>leads to a tridiagonal system , where  is the discrete Laplacian.  Implicit methods are unconditionally stable for parabolic equations, allowing larger  at the cost of solving a matrix problem at each step.  The Crank–Nicolson scheme, a trapezoidal average of explicit and implicit, is second‐order accurate in time and unconditionally stable, but still requires a linear solve.<br>To study stability rigorously one uses von Neumann analysis.  One substitutes a Fourier mode  into the linearized scheme to find the amplification factor .  For the explicit heat update  <br><br>and the method is stable if and only if  for all wavenumbers , yielding the condition  <br><br>Implicit schemes have an amplification factor with  automatically for all , reflecting their unconditional stability for diffusion problems.<br>For hyperbolic PDEs such as the advection equation , stability is intimately tied to the CFL (Courant–Friedrichs–Lewy) condition, which demands that the numerical domain of dependence includes the true physical domain of dependence.  An explicit upwind scheme  <br><br>has amplification factor , and von Neumann analysis shows stability requires  <br><br>import numpy as np

def explicit_heat(u0, kappa, dx, dt, steps):
    u = np.array(u0, dtype=float)
    N = len(u)
    r = kappa * dt / dx**2
    result = np.zeros((steps+1, N))
    result[0] = u.copy()
    for n in range(steps):
        u_new = u.copy()
        u_new[1:-1] = u[1:-1] + r * (u[2:] - 2*u[1:-1] + u[:-2])
        # assume Dirichlet BCs zero at ends
        u = u_new
        result[n+1] = u
    return result

def thomas_solver(a, b, c, d):
    n = len(b)
    cp = c.copy()
    dp = d.copy()
    # forward elimination
    for i in range(1, n):
        m = a[i-1] / b[i-1]
        b[i] -= m * cp[i-1]
        dp[i] -= m * dp[i-1]
    x = np.zeros(n)
    x[-1] = dp[-1] / b[-1]
    # back substitution
    for i in range(n-2, -1, -1):
        x[i] = (dp[i] - cp[i] * x[i+1]) / b[i]
    return x

def implicit_heat(u0, kappa, dx, dt, steps):
    u = np.array(u0, dtype=float)
    N = len(u)
    r = kappa * dt / dx**2
    # Tridiagonal coefficients for (I - r L):
    a = np.full(N-1, -r)         # sub-diagonal
    b = np.full(N, 1 + 2*r)      # main diagonal
    c = np.full(N-1, -r)         # super-diagonal
    # enforce boundary rows for Dirichlet BCs:
    b[0] = b[-1] = 1.0
    a[0] = c[-1] = 0.0
    sol = np.zeros((steps+1, N))
    sol[0] = u.copy()
    for n in range(steps):
        d = u.copy()
        d[0] = d[-1] = 0.0
        u = thomas_solver(a, b.copy(), c, d)
        sol[n+1] = u
    return sol

def crank_nicolson(u0, kappa, dx, dt, steps):
    u = np.array(u0, dtype=float)
    N = len(u)
    r = kappa * dt / dx**2
    # coefficients for left matrix (I - r/2 L)
    a = np.full(N-1, -r/2)
    b = np.full(N, 1 + r)
    c = np.full(N-1, -r/2)
    b[0] = b[-1] = 1.0
    a[0] = c[-1] = 0.0
    sol = np.zeros((steps+1, N))
    sol[0] = u.copy()
    for n in range(steps):
        # compute RHS (I + r/2 L) u^n
        d = u.copy()
        d[1:-1] += (r/2)*(u[2:] - 2*u[1:-1] + u[:-2])
        d[0] = d[-1] = 0.0
        u = thomas_solver(a, b.copy(), c, d)
        sol[n+1] = u
    return sol

def von_neumann_explicit(kappa, dx, dt, k_vals):
    r = kappa * dt / dx**2
    G = 1 - 4*r * np.sin(np.array(k_vals)*dx/2)**2
    return G
<br><br>We solve the heat equation  <br><br>on the interval  with Dirichlet boundary conditions  <br><br>using a mesh with , , so  <br><br>and  <br><br>Initial condition at :  <br><br>The explicit update is  <br><br>For , , plug in  <br><br>so the bracketed term is  <br><br>Multiply by :  <br><br>Add to :  <br><br>So after one time‐step  <br><br>For , , now  <br><br>so  <br><br><br><br>Thus at   <br><br>For , ,  <br><br>so  <br><br><br><br>Hence  <br><br>Assume a Fourier mode  <br><br>so at the next time level  <br><br>Substitute into the explicit scheme:  <br><br>Divide both sides by  to get  <br><br>Use the identity  <br><br>so  <br><br>Further use  <br><br>with , yielding  <br><br>For stability we require  <br><br>The most restrictive case is the lower bound, but since , the condition reduces to  <br><br>Because , a sufficient condition for all  is  <br><br>With , the explicit scheme is stable.  <br><br>In the finite‐element approach one first rewrites a boundary‐value problem in its weak or variational form.  Instead of seeking a sufficiently smooth solution  of  <br><br>one looks for  in the Sobolev space  such that  <br><br>Here the integration by parts has lowered the regularity demands on , and the boundary condition is built into the choice of trial and test space.<br>Having posed the problem as “find  so that  for all ,” the Galerkin method approximates  by a finite‐dimensional subspace  of piecewise‐polynomial functions.  One then seeks  satisfying  <br><br>This converts the PDE into a linear system  <br><br>where  and  in terms of a chosen basis  for .  The Galerkin orthogonality  <br><br>gives  as the best approximation in the energy norm induced by .<br>To build  one first generates a mesh of the domain , typically a triangulation in two dimensions or a tetrahedralization in three.  The mesh is a collection of non‐overlapping elements  whose union is .  <br>Quality measures such as element shape regularity and size  control both approximation error and conditioning of the resulting system.<br>On each element one selects basis functions that are simple to integrate and that have local support.  <br>A common choice is the “hat” or linear pyramid functions: each basis  equals 1 at its associated node  and vanishes at all other mesh nodes, and is affine on each element touching .  <br>def assemble_1d_linear(a,c,f,N):
    h=1.0/N
    size=N-1
    K=[[0.0]*size for _ in range(size)]
    F=[0.0]*size
    for e in range(N):
        x0=e*h; x1=x0+h; xm=0.5*(x0+x1)
        ae=a(xm); ce=c(xm)
        Ke=[[ae/h+ce*h/3, -ae/h+ce*h/6],[-ae/h+ce*h/6, ae/h+ce*h/3]]
        fe0=(f(x0)+f(x1))*h/2
        Fe=[fe0/2,fe0/2]
        for i_local in range(2):
            I=e+i_local-1
            if 0&lt;=I&lt;size:
                F[I]+=Fe[i_local]
            for j_local in range(2):
                J=e+j_local-1
                if 0&lt;=I&lt;size and 0&lt;=J&lt;size:
                    K[I][J]+=Ke[i_local][j_local]
    return K,F

def solve_fem_1d(a,c,f,N):
    K,F=assemble_1d_linear(a,c,f,N)
    n=len(F)
    A=[row[:] for row in K]; b=F[:]
    for k in range(n):
        m_row=max(range(k,n),key=lambda i:abs(A[i][k]))
        A[k],A[m_row]=A[m_row],A[k]; b[k],b[m_row]=b[m_row],b[k]
        for i in range(k+1,n):
            m=A[i][k]/A[k][k]
            for j in range(k,n):
                A[i][j]-=m*A[k][j]
            b[i]-=m*b[k]
    u=[0.0]*n
    for i in range(n-1,-1,-1):
        s=b[i]-sum(A[i][j]*u[j] for j in range(i+1,n))
        u[i]=s/A[i][i]
    return [i/N for i in range(N+1)],[0.0]+u+[0.0]
<br><br>We solve the boundary‐value problem  <br><br>on  with , , .  The weak form is: find  such that  <br><br>We choose a mesh with  elements of size  <br><br>The trial space  uses “hat” functions  supported on two adjacent elements.  We assemble the element stiffness and mass matrices, then build the global  system for the unknowns  at nodes .<br>On each element  of length  the local stiffness is  <br><br>and the local mass is  <br><br>With , we have  <br><br>Thus for each element  <br><br>We have two unknowns ().  The global stiffness  and mass  are sums over elements:<br>
<br>
Element 1 (connecting nodes 0–1–2) contributes to global rows/cols :



<br>
Element 2 (connecting nodes 1–2–3) similarly contributes:



<br>Summing these gives<br><br>The global system matrix is  <br><br>For , each entry is  <br><br>Thus<br><br>Since , we already removed nodes 0 and 3 from the system.  No further modification is needed.<br>We solve  <br><br>Explicitly,<br><br>The determinant is  <br><br>Using Cramer’s rule,<br><br>and by symmetry .  <br>Including the boundary values , , the finite‐element approximation is<br><br><br>Finite‐volume methods rest on the integral form of a conservation law.  Suppose  satisfies  <br><br>where  is the flux vector and  a source term.  Rather than enforcing this pointwise, one integrates over a control volume  to obtain  <br><br>By invoking the divergence theorem, the spatial derivative turns into a surface integral of the flux over each face of , making conservation manifest at the discrete level.<br>Next one introduces a mesh of non‐overlapping control volumes, each with volume , and defines the cell‐average  <br><br>Differentiating in time and approximating the face integrals by numerical fluxes  at the interface  between volumes  and  yields the semi‐discrete update  <br><br>where  lists neighbors of cell  and  approximates the source average. By using the same  with opposite sign on the two cells sharing , one enforces exact conservation of the discrete total .<br>The choice of numerical flux function  encodes upwinding, stability, and shock‐capturing.  A consistent flux satisfies  and is conservative in that  <br><br>Finally, once the spatial discretization is in place, one integrates the resulting system of ordinary differential equations in time.  Explicit Runge–Kutta schemes are common, but they require a Courant–Friedrichs–Lewy condition  <br><br>where  is the largest wave‐speed entering any interface.  Implicit time stepping can relax this restriction at the cost of solving nonlinear systems each step. <br>def fvm_1d(u0, flux, max_speed, dx, dt, steps):
    N = len(u0)
    sol = [u0[:]]
    u = u0[:]
    for _ in range(steps):
        u_old = u[:]
        F = [0.0]*(N+1)
        for i in range(N+1):
            uL = u_old[(i-1)%N]
            uR = u_old[i%N]
            a = max_speed(uL, uR)
            F[i] = 0.5*(flux(uL) + flux(uR)) - 0.5*a*(uR - uL)
        for i in range(N):
            u[i] = u_old[i] - dt/dx*(F[i+1] - F[i])
        sol.append(u[:])
    return sol

# Linear advection example: u_t + a u_x = 0
a = 1.0
flux = lambda u: a*u
max_speed = lambda uL, uR: abs(a)

N = 100
dx = 1.0/N
dt = 0.5*dx/a
steps = 200
import math
u0 = [math.sin(2*math.pi*(i+0.5)/N) for i in range(N)]
solution = fvm_1d(u0, flux, max_speed, dx, dt, steps)
<br><br>We consider the linear advection equation  <br><br>on the periodic domain  with speed .  We subdivide into  cells of width , whose centers are  <br><br>and advance in time with , so the Courant number is  <br><br>Let  denote the cell‐average in cell  at time level .  We use the Rusanov flux  <br><br>since  and periodicity implies .  The fully explicit update is  <br><br>At  we prescribe  <br><br>and extend periodically so , .  The numerical fluxes at interfaces  are<br><br>Hence for each cell<br><br>giving<br><br>Thus <br><br>At , periodic extension gives , , so the fluxes are<br><br>and the update yields<br><br>Hence<br><br>Since , the CFL condition  <br><br>is satisfied and the explicit finite‐volume scheme remains stable.  ]]></description><link>ch12-numerical-pdes.html</link><guid isPermaLink="false">CH12-Numerical-PDEs.md</guid><pubDate>Fri, 20 Jun 2025 10:22:51 GMT</pubDate></item><item><title><![CDATA[CH13-Problem-Classification]]></title><description><![CDATA[ 
 <br><br>Computational problems often come in two flavors.  A decision problem asks a yes‐or‐no question, such as “Does this graph have a Hamiltonian cycle?”  An optimization problem asks for the best solution according to some cost or value, for example “What is the shortest Hamiltonian cycle in this graph?”  You can turn many optimization questions into decision questions by asking “Is there a solution of cost at most ?”  Although the underlying task is similar, decision problems are the ones we use to define complexity classes like P and NP.<br>The class P consists of those decision problems for which there is an algorithm that always halts in time bounded by a polynomial in the size of its input, and correctly answers yes or no.  More formally, we say a language  <br><br>is in P if there exists a deterministic Turing machine  and a polynomial  such that for any binary string :  <br>
<br> halts in at most  steps,  
<br> accepts  if and only if .  
<br>Problems in P are often called “efficiently solvable,” because, as the size of the input grows, the time needed grows at most like a fixed power of that size.<br>The class NP captures those decision problems where, whenever the correct answer is “yes,” there is a short proof or certificate that can be checked in polynomial time.  In more formal terms,  is in NP if there is a polynomial  and a deterministic polynomial‐time verifier  such that for every input :  <br>
<br>If , then there exists a certificate  of length at most  for which  accepts.  
<br>If , then no certificate  of length  makes  accept.  
<br>Here  is just another algorithm that reads both the original input  and the proposed solution , and runs in time bounded by some polynomial in .<br>An equivalent way to look at NP is through non‐deterministic Turing machines (NDTMs).  Such a machine can, at certain steps, “branch” into many possible next moves.  You can think of each branch as a different guess for what the solution might be.  We say an NDTM accepts  if at least one branch leads to an accepting state.  Then  is in NP exactly when there is an NDTM  that, on every branch, runs in time at most  for some polynomial , and accepts precisely the members of .  <br>On one hand, a nondeterministic run of  corresponds to picking a certificate  ahead of time.  On the other hand, running the verifier  for each possible  is like exploring each nondeterministic branch.  In both cases, we only require that the correct “yes” instances have at least one witness or accepting branch, and that everything can be checked or simulated in polynomial time on a standard (deterministic) machine.<br>
<br>P: problems for which the answer can be found by a single deterministic algorithm in polynomial time.  
<br>NP: problems for which, if the answer is “yes,” there is a short proof verifiable in polynomial time (or equivalently solvable by a polynomial‐time NDTM).  
<br>One final point: every problem in P is trivially in NP, because if you can decide “Does ?” quickly, you can treat the empty string as a “certificate” and just run the decision algorithm.  The big open question — the P vs NP problem — asks whether this inclusion is strict, that is, whether there are problems in NP that no polynomial‐time deterministic algorithm can solve.  <br>An NP-hard problem is one that is “at least as hard” as the hardest problems in NP.  More precisely, a decision problem  is called NP-hard if every problem  in NP can be transformed (“reduced”) to  by a polynomial-time computable function.  That is, there exists a polynomial-time algorithm that maps instances  of  to instances  of  so that  <br><br>Because any NP problem can thus be solved by using a (hypothetical) oracle for , we say  is at least as difficult as all of NP.  Notice that NP-hardness makes no requirement that  itself lie in NP—indeed, many NP-hard problems are optimization tasks or even undecidable questions.<br>One often encounters NP-hardness in optimization problems whose decision versions are NP-complete.  For example, the Traveling Salesman Problem (TSP) asks for a shortest tour visiting each city once.  Its decision variant—“Is there a tour of length at most ?”—is NP-complete, so finding the minimum-length tour (the optimization version) is NP-hard.  No polynomial-time algorithm is known for TSP, and a polynomial-time algorithm for it would imply .<br>Other familiar NP-hard tasks include:<br>
<br>0–1 Knapsack: given weights , values , and capacity , maximize  subject to  with .  Its decision form “Is there a selection of total value at least ?” is NP-complete.  
<br>Partition: given integers , decide if they can be split into two subsets with equal sum.  That decision problem is NP-complete, so the associated optimization (“minimize the difference of subset sums”) is NP-hard.  
<br>Graph Partitioning and Graph Bi-Partitioning: dividing the vertex set into parts of given sizes so as to minimize the number of edges between them; the decision variants are NP-complete.  
<br>Beyond optimization, NP-hardness also arises in counting and enumeration problems.  For instance, counting the number of satisfying assignments of a Boolean formula (the SAT problem) is NP-complete, which is believed to be strictly harder than NP and thus NP-hard as well.  <br>Because NP-hard problems has no known polynomial algorithms, one studies approximations, exponential-time exact methods, or parameterized algorithms that are efficient when some parameter (like the tree-width of a graph or the capacity  in knapsack) is small.  Approximation algorithms aim to produce solutions whose cost is within some factor  of optimal, while fixed-parameter tractable (FPT) algorithms run in time  for parameter  and input size .<br>Formally, a problem  (not necessarily in NP) is NP-hard if every language in NP reduces to it under polynomial-time many-one reductions.  When such a  also lies in NP, we call it NP-complete.  But optimization and counting versions often fall outside NP yet share the same intractability core.  <br><img alt="Pasted image 20250620123723.png" src="assets/pasted-image-20250620123723.png"><br><br><br>A polynomial‐time reduction is a way of translating instances of one decision problem into instances of another, using only a polynomial amount of time.  Concretely, suppose we have two languages (decision problems)  <br><br>A function  <br><br>is called a polynomial‐time reduction from  to  (written ) if:<br><br>Because  runs in polynomial time, if we already have a polynomial‐time algorithm for deciding membership in , we can decide membership in  by first computing  and then running our solver for  on .  The combined procedure still runs in polynomial time, so  cannot be any harder than  under this notion of reducibility.<br>Polynomial‐time reductions are the backbone of NP‐completeness theory.  Once one problem, say 3‐SAT, is known to be NP‐complete, every other NP‐complete problem is shown NP‐hard by giving a polynomial‐time format that transforms any 3‐SAT formula into an instance of the new problem.  <br>For example, to reduce 3‐SAT to 3‐Coloring one builds small graph “gadgets” for each variable and clause so that any valid three‐coloring corresponds exactly to a satisfying assignment of the formula.  The construction guarantees:<br>
<br>A formula has a satisfying assignment if and only if the corresponding graph admits a proper 3‐coloring.
<br>The number of vertices and edges in the graph grows only polynomially with the size of the formula.
<br>Reductions compose neatly.  If  via  and  via , then  via , whose running time is still polynomial.  This transitivity builds the web of NP‐hardness: once one central problem is pinned down, a cascade of reductions shows that many others share the same intractable core.<br>Designing a reduction requires careful attention to two things: making sure that “yes” instances map to “yes” instances (and “no” to “no”), and keeping the size of the transformed instance under control so it doesn’t blow up faster than a polynomial.  In many classic reductions—such as CLIQUE to VERTEX COVER, or SUBSET SUM to PARTITION—this bookkeeping takes the form of simple graph complements or arithmetic constructions whose correctness can be checked in a few lines of reasoning and whose output size is a straightforward function of the input size.<br>Reduction from 3-SAT to 3-Coloring<br>Let the input to 3-SAT be a formula  <br><br>over variables , where each clause  <br><br>is a disjunction of three literals .  We will build in polynomial time a graph  such that  <br><br>Introduce three special vertices  <br><br>and add edges to make a triangle:<br><br>In any proper 3-coloring these three must all receive different colors; we will interpret the color of  as “true,” of  as “false,” and of  as the “base” color.<br>For each variable  add two vertices  <br><br>and connect them and  as follows:<br><br>Since  and  are adjacent, they cannot share a color, and since each is adjacent to , neither can be colored .  Thus in any proper coloring exactly one of  gets the color of  and the other gets the color of , encoding a truth assignment for .<br>For each clause , introduce three new vertices  <br><br>and add edges to form a triangle:<br><br>Then for each , connect  to the vertex representing the negation of the literal :<br>
<br>If , add edge .
<br>If , add edge .
<br>
<br>(⇒) Suppose  has a satisfying assignment.  

<br>Color  with three distinct colors (say red, green, blue).  
<br>For each , if , color ’s color and ’s color; if , swap.  
<br>In each clause , at least one literal  is true.  Then the neighbor of  in the variable gadget has color , so  cannot be  but can be  or .  For the two other  whose literals are false, their neighbors have color , so they cannot be  but can be  or .  Since  form a triangle, they require three distinct colors—exactly the three available—so we can assign them  in some order consistent with the forbidden‐color constraints.  Thus the whole graph is 3-colorable. 


<br>(⇐) Conversely, given a 3-coloring of , the triangle  uses all three colors.  Each variable gadget vertex  is adjacent to  so must be colored with  or , and since  is adjacent to , exactly one is  and the other is .  Define a truth assignment by setting  if ’s color is , otherwise false.  In each clause gadget, the triangle  must again use all three colors.  If all three literals were false under our assignment, then for each , the neighbor of  in the variable gadget would have color , forbidding  from being .  But then the three clause vertices would have only two colors  available between them, making a proper coloring impossible.  Hence each clause has at least one true literal, so the assignment satisfies .
<br>
<br>We create  vertices for the reference triangle,  vertices for variables, and  for clauses: total .  
<br>We add at most  edges, so .  
<br>Constructing  requires scanning the formula once and emitting the appropriate vertices and edges in  time.
<br>Thus the mapping  is computable in time  (even ), and  <br><br><br>A Karp reduction, also known as a polynomial-time many-one reduction, shows that one decision problem is no harder than another.  Suppose we have two languages  <br><br>We say that  reduces to  via a Karp reduction (written  ) if there is a function  <br><br>that can be computed in time polynomial in the length of its input, and which satisfies  <br><br>Because  runs in polynomial time, any polynomial-time solver for  immediately gives a polynomial-time solver for  by first computing  and then asking “is ?”<br>In practice, to prove that a new problem  is NP-hard one starts from a known NP-complete problem  (for example 3-SAT) and describes a polynomial-time construction .  For instance, to reduce 3-SAT to CLIQUE one creates a small gadget of vertices and edges for each clause so that there is a clique of a certain size exactly when the formula is satisfiable.  The resulting graph has size polynomial in the number of variables and clauses, and checking or building each edge takes only polynomial time.<br>Karp reductions compose: if  <br><br>via  and  <br><br>via , then the composition  <br><br>is also a polynomial-time reduction showing  <br><br>This transitivity lets us build a network of NP-complete problems: once one core problem is pinned down, many others follow by chaining these gadget constructions.<br>It’s important to contrast Karp reductions with Turing reductions, where the solver for  may be invoked multiple times in an adaptive way.  <br>Reduction from 3‐SAT to CLIQUE<br>Let the input be a 3‐SAT formula  <br><br>over variables , where each clause  <br><br>has three literals .  We will construct in time polynomial in  a graph  and integer  such that  <br><br>
<br>
For each clause  and each literal  introduce a vertex  in .  Thus  


<br>
Add an edge between every pair of vertices  and  whenever they come from different clauses () and their literals are not complementary.  In other words, for  we include  


<br>
Set the target clique size to  


<br>This completes the definition of the reduction function , which runs in  time to enumerate all pairs of clause‐vertices.<br>Example<br>
Take  <br><br>so  and we create vertices  <br><br>We add edges only between one from  and one from  whenever the corresponding literals are not complementary:<br>
<br> corresponds to ,  to , so no edge .
<br> with  () is allowed, so add .
<br>Continue for each of the  pairs, omitting exactly those with .
<br>We ask if there is a clique of size  in .  One finds that choosing  (for  true) and  (for  true) yields an edge, so  is a 2‐clique.  The formula is satisfiable by setting  arbitrary.  <br>Correctness<br>
<br>
If  is satisfiable, assign each true literal  the color “in the clique.”  In each clause  at least one literal is true, so choose one corresponding vertex .  By construction no two chosen literals are complementary, so all  form a clique of size .

<br>
Conversely, any clique of size  must select exactly one vertex from each clause (since there are no edges within the same clause) and no two selected literals are complementary.  Assign each chosen literal to true; this makes every clause true and yields a satisfying assignment.

<br>Since  and checking each of the  pairs for edge‐creation takes polynomial time, the function  is computable in time  and satisfies  <br><br>hence we have exhibited a Karp reduction .  <br><br>A Turing reduction (or Cook reduction) allows a polynomial-time algorithm for one problem to make multiple, adaptive queries to a solver (an “oracle”) for another problem.  Instead of computing a single transformed instance, the reducing algorithm can interleave ordinary computation with calls of the form “Is  in ?” and use the answers to guide its next steps.<br>Formally, we say a language  is polynomial-time Turing reducible to a language , written  <br><br>if there exists a deterministic Turing machine  with access to a -oracle such that:<br>
<br>On any input ,  runs in time bounded by a polynomial in .
<br>During its computation,  may query the oracle on strings , each of length bounded by some polynomial in .
<br>At the end of its run,  accepts  if and only if .
<br>Each oracle query “Is ?” returns a yes/no answer in one step.  Because  is allowed to choose its next query based on previous answers, Turing reductions capture a more flexible notion of “using  as a subroutine” than Karp (many-one) reductions.<br>One can view  as a polynomial-time algorithm that solves  given black-box access to a solver for .  In symbols,  <br><br>The total time—including all queries and internal work—is  for some fixed .<br>Because Turing reductions allow multiple, adaptive queries, they form a superset of many-one reductions:  <br><br>but the converse need not hold.  For instance, a single Turing reduction can query  on several carefully chosen inputs, combine the answers, and thereby solve problems for which no single instance of  suffices.<br><br>
<br>
SAT<br>


<br>
FIND-SAT-BIT  


<br>An instance of FSB consists of a CNF formula  together with an index . The task is a decision question: does the earliest (00…–ordered) model of  set ?<br>No single formula asks this directly, so a many-one (Karp) reduction is unknown. Yet we will show a polynomial-time Turing reduction<br><br>meaning a polynomial algorithm with adaptive access to an oracle for SAT decides FSB.<br>To discover the first model bit-by-bit we repeatedly fix earlier variables and ask the oracle whether the partially restricted formula is still satisfiable.  Each query shrinks the search space; after at most  oracle calls we know the desired bit.<br>Input: a pair  where  has  variables<br>
Oracle: one-step membership test for SAT<br>
for j ← 1 to i-1 // determine x1 … x_{i-1}  
ask SAT whether φ ∧ (x1= b1) ∧ ... ∧ (x_{j-1}= b_{j-1}) ∧ (x_j=0) is satisfiable  
if oracle says YES set b_j ← 0  
else set b_j ← 1 // 0 impossible, so 1 forced

// now decide bit i  
ask SAT whether φ ∧ (x1=b1) ∧ … ∧ (x_{i-1}=b_{i-1}) ∧ (x_i=0) is satisfiable  
if oracle says YES accept // xi = 0 in first model  
else reject // xi = 1 in first model

<br>Here “” abbreviates the CNF obtained by appending the unit clause , and similarly for .<br>Fix a lexicographically smallest model  <br><br>The outer loop maintains the invariant. <br>Initialization () is trivial.  Assume the invariant before query . If , the query with  is satisfiable, so we set . Else ; putting  contradicts minimality of , hence oracle returns NO and we set . Thus the invariant propagates.  <br>After the loop we know .  The final query asks whether  can be forced to .<br>
If the answer is YES then  is  in , so  and the machine accepts. Otherwise  and the machine rejects.  Therefore<br><br>which is merely a choice of output convention.<br>
<br>Each of the at most  oracle queries enlarges the formula by one unit clause, so its size is .
<br>Writing and copying clauses, plus bookkeeping, costs  per step.
<br>Hence the total running time, excluding oracle steps, is , a polynomial.
<br>The reduction is thus complete:<br>]]></description><link>ch13-problem-classification.html</link><guid isPermaLink="false">CH13-Problem-Classification.md</guid><pubDate>Sun, 06 Jul 2025 20:31:37 GMT</pubDate><enclosure url="assets/pasted-image-20250620123723.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;assets/pasted-image-20250620123723.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[index]]></title><description><![CDATA[ 
 <br>AUTHOR: Anubhav Lamsal;<br>
SUBJECT: General Algorithms;<br>THIS IS NOT AN ACADEMIC OR PUBLISHED SOURCE, AND I AM NOT TRYING TO PRESENT IT AS SUCH. THESE ARE ONLY PERSONAL NOTES TO BE USED AS QUICK REFERENCES. FOR DETAILED EXPLORATION AND ACADEMIC CITING ON THE TOPICS COVERED, RESPECTIVE SOURCES SHOULD BE CONSULTED. ]]></description><link>index.html</link><guid isPermaLink="false">index.md</guid><pubDate>Fri, 18 Jul 2025 10:03:22 GMT</pubDate></item></channel></rss>